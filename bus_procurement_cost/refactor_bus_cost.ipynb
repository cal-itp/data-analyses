{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e50ef668-5812-4b3a-a257-ef0a424b46e3",
   "metadata": {},
   "source": [
    "# Bus Cost Refactor\n",
    "## overall imports and data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2bb63c6-6457-4433-aa9d-0136b2690464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 300)\n",
    "pd.set_option(\"display.max_columns\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "910ee0fa-38ce-44f3-8e18-4cdf740e1fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old script imports\n",
    "from _01_fta_data_cleaner import *\n",
    "from _03_dgs_data_cleaner import *\n",
    "from _02_tircp_data_cleaner import *\n",
    "import _bus_cost_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1fd0b4-14a6-4cad-bb15-0ce0437ed125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated Script imports for bus cost utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3552c45-8b28-4bbe-ae82-f2d726a45937",
   "metadata": {},
   "outputs": [],
   "source": [
    "#immutable GCS path\n",
    "# save to bus cost utils\n",
    "GCS_PATH = \"gs://calitp-analytics-data/data-analyses/bus_procurement_cost/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b1f367-1dac-463f-8790-2e5134b7e79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# links to all Raw Data\n",
    "fta_raw = pd.read_csv(f\"{GCS_PATH}raw_data-analyses_bus_procurement_cost_fta_press_release_data_csv.csv\")\n",
    "tircp_raw = pd.read_excel(f\"{GCS_PATH}raw_TIRCP Tracking Sheets 2_1-10-2024.xlsx\", sheet_name=\"Project Tracking\")\n",
    "dgs17b_raw = pd.read_excel(f\"{GCS_PATH}raw_17b compiled.xlsx\", sheet_name = \"Usage Report Template\")\n",
    "dgs17c_raw = pd.read_excel(f\"{GCS_PATH}raw_17c compiled-Proterra Compiled Contract Usage Report .xlsx\", sheet_name = \"Proterra \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f2ae607-62e7-4d9f-a6c9-9d616b328d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.read_parquet(f'{GCS_PATH}cleaned_cpb_analysis_data_merge.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae787605-f4cc-48d0-9118-1a85a83c72e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['transit_agency', 'project_title', 'prop_type', 'bus_size_type',\n",
       "       'description', 'new_project_type', 'total_cost', 'bus_count', 'source',\n",
       "       'ppno', 'project_description', 'cost_per_bus', 'zscore_cost_per_bus',\n",
       "       'is_cpb_outlier?'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04911c1-e839-41fe-87b3-5065586f2223",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Functions to Save\n",
    "for new `bus_cost_utils.py` script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f25932-dddd-409f-a57f-eef29570a178",
   "metadata": {},
   "source": [
    "## save to bus_cost_utils.py\n",
    "for everything to use from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dacaba-c6f7-4cb0-afef-a84f77de25fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW FUNCTION\n",
    "# moved this to bus_cost_utils\n",
    "def bus_min_max_summary(data:pd.DataFrame, col1:str, col_list=[\"transit_agency\",\n",
    "                                                     \"total_agg_cost\",\n",
    "                                                     \"total_bus_count\",\n",
    "                                                     \"new_cost_per_bus\"]):\n",
    "    \"\"\"\n",
    "    function to display min/max of specific column in aggregated bus df.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return display(\n",
    "        Markdown(f\"**Max {col1}**\"),\n",
    "        data[data[col1] == data[col1].max()][col_list],\n",
    "        Markdown(f\"**Min {col1}**\"),\n",
    "        data[data[col1] == data[col1].min()][col_list]\n",
    "                  )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5513b941-ecdb-405e-bfd6-952df6b8f8b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NEW PROP FINDER\n",
    "def new_prop_finder(description: str) -> str:\n",
    "    \"\"\"\n",
    "    function that matches keywords from each propulsion type list against the item description col, returns a standardized prop type\n",
    "    now includes variable that make description input lowercase.\n",
    "    to be used with .assign()\n",
    "    \"\"\"\n",
    "\n",
    "    BEB_list = [\n",
    "        \"battery electric\",\n",
    "        \"BEBs paratransit buses\"\n",
    "    ]\n",
    "\n",
    "    cng_list = [\n",
    "        \"cng\",\n",
    "        \"compressed natural gas\"    \n",
    "    ]\n",
    "\n",
    "    electric_list = [\n",
    "        \"electric buses\",\n",
    "        \"electric commuter\",\n",
    "        \"electric\",\n",
    "    ]\n",
    "\n",
    "    FCEB_list = [\n",
    "        \"fuel cell\",\n",
    "        \"hydrogen\",\n",
    "        #\"fuel cell electric\",\n",
    "        #\"hydrogen fuel cell\",\n",
    "        #\"fuel cell electric bus\",\n",
    "        #\"hydrogen electric bus\",\n",
    "    ]\n",
    "\n",
    "    # low emission (hybrid)\n",
    "    hybrid_list = [\n",
    "        #\"diesel electric hybrids\",\n",
    "        #\"diesel-electric hybrids\",\n",
    "        #\"hybrid electric\",\n",
    "        #\"hybrid electric buses\",\n",
    "        #\"hybrid electrics\",\n",
    "        \"hybrids\",\n",
    "        \"hybrid\",\n",
    "    ]\n",
    "\n",
    "    # low emission (propane)\n",
    "    propane_list = [\n",
    "        #\"propane buses\",\n",
    "        #\"propaned powered vehicles\",\n",
    "        \"propane\",\n",
    "    ]\n",
    "\n",
    "    mix_beb_list = [\n",
    "        \"2 BEBs and 4 hydrogen fuel cell buses\",\n",
    "    ]\n",
    "\n",
    "    mix_lowe_list = [\n",
    "        \"diesel and gas\",\n",
    "    ]\n",
    "\n",
    "    mix_zero_low_list = [\n",
    "        \"15 electic, 16 hybrid\",\n",
    "        \"4 fuel cell / 3 CNG\",\n",
    "        \"estimated-cutaway vans (PM- award will not fund 68 buses\",\n",
    "        \"1:CNGbus ;2 cutaway CNG buses\",\n",
    "    ]\n",
    "\n",
    "    zero_e_list = [\n",
    "        #\"zero emission buses\",\n",
    "        #\"zero emission electric\",\n",
    "        #\"zero emission vehicles\",\n",
    "        \"zero-emission\",\n",
    "        \"zero emission\",\n",
    "    ]\n",
    "\n",
    "    item_description = description.lower().replace(\"‐\", \" \").strip()\n",
    "\n",
    "    if any(word in item_description for word in BEB_list) and not any(\n",
    "        word in item_description for word in [\"diesel\", \"hybrid\", \"fuel cell\"]\n",
    "    ):\n",
    "        return \"BEB\"\n",
    "\n",
    "    elif any(word in item_description for word in FCEB_list):\n",
    "        return \"FCEB\"\n",
    "\n",
    "    elif any(word in item_description for word in hybrid_list):\n",
    "        return \"low emission (hybrid)\"\n",
    "\n",
    "    elif any(word in item_description for word in mix_beb_list):\n",
    "        return \"mix (BEB and FCEB)\"\n",
    "\n",
    "    elif any(word in item_description for word in mix_lowe_list):\n",
    "        return \"mix (low emission)\"\n",
    "\n",
    "    elif any(word in item_description for word in mix_zero_low_list):\n",
    "        return \"mix (zero and low emission)\"\n",
    "\n",
    "    elif any(word in item_description for word in zero_e_list):\n",
    "        return \"zero-emission bus (not specified)\"\n",
    "\n",
    "    elif any(word in item_description for word in propane_list):\n",
    "        return \"low emission (propane)\"\n",
    "\n",
    "    elif any(word in item_description for word in electric_list):\n",
    "        return \"electric (not specified)\"\n",
    "    \n",
    "    elif any(word in item_description for word in cng_list):\n",
    "        return \"CNG\"\n",
    "\n",
    "    else:\n",
    "        return \"not specified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e18cbe6-bde7-4c30-8a8a-aefd8d619821",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def new_bus_size_finder(description: str) -> str:\n",
    "    \"\"\"\n",
    "    Similar to prop_type_find, matches keywords to item description col and return standardized bus size type.\n",
    "    now includes variable that make description input lowercase.\n",
    "    To be used with .assign()\n",
    "    \"\"\"\n",
    "\n",
    "    articulated_list = [\n",
    "        \"60 foot\",\n",
    "        \"articulated\",\n",
    "    ]\n",
    "\n",
    "    standard_bus_list = [\n",
    "        \"30 foot\",\n",
    "        \"35 foot\",\n",
    "        \"40 foot\",\n",
    "        \"40ft\",\n",
    "        \"45 foot\",\n",
    "        \"standard\",\n",
    "    ]\n",
    "\n",
    "    cutaway_list = [\n",
    "        \"cutaway\",\n",
    "    ]\n",
    "\n",
    "    other_bus_size_list = [\"feeder bus\"]\n",
    "\n",
    "    otr_bus_list = [\n",
    "        \"coach style\",\n",
    "        \"over the road\",\n",
    "    ]\n",
    "\n",
    "    item_description = description.lower().replace(\"-\", \" \").strip()\n",
    "\n",
    "    if any(word in item_description for word in articulated_list):\n",
    "        return \"articulated\"\n",
    "\n",
    "    elif any(word in item_description for word in standard_bus_list):\n",
    "        return \"standard/conventional (30ft-45ft)\"\n",
    "\n",
    "    elif any(word in item_description for word in cutaway_list):\n",
    "        return \"cutaway\"\n",
    "\n",
    "    elif any(word in item_description for word in otr_bus_list):\n",
    "        return \"over-the-road\"\n",
    "\n",
    "    elif any(word in item_description for word in other_bus_size_list):\n",
    "        return \"other\"\n",
    "\n",
    "    else:\n",
    "        return \"not specified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8004cc2d-957f-4e9a-9ca8-2a6f9aba9ffb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def project_type_finder(description: str) -> str:\n",
    "    \"\"\"\n",
    "    function to match keywords to project description col to identify projects that only have bus procurement.\n",
    "    used to identify projects into diffferent categories: bus only, bus + others, no bus procurement.\n",
    "    use with .assign() to get a new col.\n",
    "    \"\"\"\n",
    "    bus_list =[\n",
    "        \"bus\",\n",
    "        \"transit vehicles\",# for fta list\n",
    "        \"cutaway vehicles\",# for fta list\n",
    "        \"zero-emission vehicles\", # for tircp list\n",
    "        \"zero emission vehicles\",\n",
    "        \"zero‐emissions vans\",\n",
    "        \"hybrid-electric vehicles\",\n",
    "        \"battery-electric vehicles\",\n",
    "        \"buy new replacement vehicles\", # specific string for fta list\n",
    "    ]\n",
    "    \n",
    "    exclude_list =[\n",
    "        \"facility\",\n",
    "        #\"station\",\n",
    "        \"stops\",\n",
    "        \"installation\",\n",
    "        \"depot\",\n",
    "        \"construct\",\n",
    "        \"infrastructure\",\n",
    "        \"signal priority\",\n",
    "        \"improvements\",\n",
    "        \"build\",\n",
    "        \"chargers\",\n",
    "        \"charging equipment\",\n",
    "        \"install\",\n",
    "        \"rail\",\n",
    "        \"garage\",\n",
    "        \"facilities\",\n",
    "        \"bus washing system\",\n",
    "        \"build a regional transit hub\" # specific string needed for fta list\n",
    "        #\"associated infrastructure\" may need to look at what is associated infrastructure is for ZEB \n",
    "        \n",
    "    ]\n",
    "    proj_description = description.lower().strip()\n",
    "\n",
    "    if any(word in proj_description for word in bus_list) and not any(\n",
    "        word in proj_description for word in exclude_list\n",
    "    ):\n",
    "        return \"bus only\"\n",
    "    \n",
    "    elif any(word in proj_description for word in exclude_list) and not any(\n",
    "        word in proj_description for word in bus_list\n",
    "    ):\n",
    "        return \"non-bus components\"\n",
    "    \n",
    "    elif any(word in proj_description for word in exclude_list) and any(\n",
    "        word in proj_description for word in bus_list\n",
    "    ):\n",
    "        return \"includes bus and non-bus components\"\n",
    "    \n",
    "    else:\n",
    "        return \"needs review\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ca9254-2983-4cab-845c-f9bfb0229417",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def col_row_updater(df: pd.DataFrame, col1: str, val1, col2: str, new_val):\n",
    "    \"\"\"\n",
    "    function used to update values at specificed columns and row value.\n",
    "    \"\"\"\n",
    "    df.loc[df[col1] == val1, col2] = new_val\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa387f41-c9b3-455a-9829-cfabb3f98c9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Moved to new bus_cost_util\n",
    "\n",
    "def outlier_flag(col):\n",
    "    \"\"\"\n",
    "    function to flag outlier rows. use with .apply()\n",
    "    \"\"\"\n",
    "    \n",
    "    return col <= -3 or col >= 3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46d8747-5d4e-418d-a362-c80a093de4dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## save to analysis notebook\n",
    "chart functions should stay in the analysis notebook since the charts only exist in the analysis notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2be581-f4e9-4f7e-bde5-01f2de183479",
   "metadata": {},
   "outputs": [],
   "source": [
    "## moved to analysis NB 6/25\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shared_utils\n",
    "from cost_per_bus_nb_scripts import *\n",
    "from IPython.display import Markdown, display\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from scipy.stats import zscore\n",
    "\n",
    "def new_cpb_aggregate(df: pd.DataFrame, column=\"transit_agency\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    function to aggregate compiled data by different categories:\n",
    "        \"transit agency\", \n",
    "        \"propulsion type\", \n",
    "        \"bus_size_type\",\n",
    "        \"new_project_type\"\n",
    "    aggregate on columns:\n",
    "        \"project_title\"\n",
    "        \"ppno\"\n",
    "        \"total_cost\"\n",
    "        \"bus_count\"\n",
    "        \n",
    "    Then, cost per bus is calculated AFTER the aggregation.\n",
    "    \"\"\"\n",
    "    df_agg = (\n",
    "        df.groupby(column)\n",
    "        .agg(\n",
    "            total_project_count=(\"project_title\", \"count\"),\n",
    "            total_project_count_ppno=(\"ppno\", \"count\"),\n",
    "            total_agg_cost=(\"total_cost\", \"sum\"),\n",
    "            total_bus_count=(\"bus_count\", \"sum\"),\n",
    "            #new_prop_type=(\"prop_type\",\"max\")\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    df_agg[\"new_cost_per_bus\"] = (df_agg[\"total_agg_cost\"] / df_agg[\"total_bus_count\"]).astype(\"int64\")\n",
    "    \n",
    "    #calculate zscore\n",
    "    df_agg[\"new_zscore_cost_per_bus\"] = zscore(df_agg[\"new_cost_per_bus\"])\n",
    "    \n",
    "    #flag outliers\n",
    "    df_agg[\"new_is_cpb_outlier?\"] = df_agg[\"new_zscore_cost_per_bus\"].apply(outlier_flag)\n",
    "    \n",
    "    return df_agg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1ae513-a8bf-4eb1-9e7b-71f828ebb9ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## moved to analysis NB 6/25\n",
    "def make_chart(y_col: str, title: str, data: pd.DataFrame, x_col: str):\n",
    "    \"\"\"\n",
    "    function to create chart. sorts values by y_col ascending.\"\"\"\n",
    "    \n",
    "    data.sort_values(by=y_col, ascending=False).head(10).plot(\n",
    "        x=x_col, y=y_col, kind=\"bar\", color=\"skyblue\"\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_col)\n",
    "    plt.ylabel(y_col)\n",
    "\n",
    "    plt.ticklabel_format(style=\"plain\", axis=\"y\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5bc209-a660-4c18-86b0-574640391a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## moved to analysis NB 6/25\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "def dist_curve(\n",
    "    df: pd.DataFrame,\n",
    "    mean: str,\n",
    "    std: str,\n",
    "    title: str,\n",
    "    xlabel: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    function to make distribution curve. uses the \"cpb\" column of the df.\n",
    "    \"\"\"\n",
    "    sns.histplot(df[\"cost_per_bus\"], kde=True, color=\"skyblue\", bins=20)\n",
    "    # mean line\n",
    "    plt.axvline(\n",
    "        mean, color=\"red\", linestyle=\"dashed\", linewidth=2, label=f\"Mean: ${mean:,.2f}\"\n",
    "    )\n",
    "    # mean+1std\n",
    "    plt.axvline(\n",
    "        mean + std,\n",
    "        color=\"green\",\n",
    "        linestyle=\"dashed\",\n",
    "        linewidth=2,\n",
    "        label=f\"Standard Deviation: ${std:,.2f}\",\n",
    "    )\n",
    "    plt.axvline(mean - std, color=\"green\", linestyle=\"dashed\", linewidth=2)\n",
    "    plt.axvline(mean + (std * 2), color=\"green\", linestyle=\"dashed\", linewidth=2)\n",
    "    plt.axvline(mean + (std * 3), color=\"green\", linestyle=\"dashed\", linewidth=2)\n",
    "\n",
    "    plt.title(title + \" with Mean and Standard Deviation\")\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "    # Turn off scientific notation on x-axis?\n",
    "    plt.gca().xaxis.set_major_formatter(ScalarFormatter(useMathText=False))\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bdb85b-ecaa-4634-8ea1-02ebc630567f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Chagnes to current grant type scripts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e4d8ed-131b-4a03-a2af-55c2bd4efc66",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## FTA Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9c3269-d53d-4d94-bc22-c6768cb63d91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FTA\n",
    "# copied over 6/25/2024\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shared_utils\n",
    "from calitp_data_analysis.sql import to_snakecase\n",
    "from bus_cost_utils import *\n",
    "# from dgs_data_cleaner import new_bus_size_finder, new_prop_finder, project_type_checker\n",
    "#from tircp_data_cleaner import col_row_updater\n",
    "\n",
    "def col_splitter(\n",
    "    df: pd.DataFrame, \n",
    "    col_to_split: str, \n",
    "    new_col1: str, \n",
    "    new_col2: str, \n",
    "    split_char: str\n",
    ")-> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    function to split a column into 2 columns by specific character.\n",
    "    ex. split 100(beb) to \"100\" & \"(beb)\"\n",
    "    \"\"\"\n",
    "    df[[new_col1, new_col2]] = df[col_to_split].str.split(\n",
    "        pat=split_char, n=1, expand=True\n",
    "    )\n",
    "\n",
    "    df[new_col2] = df[new_col2].str.replace(\")\", \"\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def fta_agg_bus_only(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    filters FTA data to only show projects with bus procurement (bus count > 0).\n",
    "    then filters projects for new_project_type = bus only\n",
    "    then aggregates\n",
    "    \"\"\"\n",
    "    df1 = df[(df[\"bus_count\"] > 0) & (df[\"new_project_type\"] == \"bus only\")]\n",
    "\n",
    "    df2 = (\n",
    "        df1.groupby(\n",
    "            [\n",
    "                \"project_sponsor\",\n",
    "                \"project_title\",\n",
    "                \"new_prop_type_finder\",\n",
    "                \"new_bus_size_type\",\n",
    "                \"description\",\n",
    "                \"new_project_type\"\n",
    "            ]\n",
    "        )\n",
    "        .agg(\n",
    "            {\n",
    "                \"funding\": \"sum\",\n",
    "                \"bus_count\": \"sum\",\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    return df2\n",
    "\n",
    "def clean_fta_columns() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Main function to clean FTA data. Reads in data, changes datatypes, change specific values.\n",
    "    \"\"\"\n",
    "    # params\n",
    "    \n",
    "    file = \"raw_data-analyses_bus_procurement_cost_fta_press_release_data_csv.csv\"\n",
    "\n",
    "    # read in data\n",
    "    df = pd.read_csv(f\"{GCS_PATH}{file}\")\n",
    "\n",
    "    # snakecase df\n",
    "    df = to_snakecase(df)\n",
    "\n",
    "    # clean funding values\n",
    "    df[\"funding\"] = (\n",
    "        df[\"funding\"]\n",
    "        .str.replace(\"$\", \"\")\n",
    "        .str.replace(\",\", \"\")\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "    # rename initial propulsion type col to propulsion category\n",
    "    df = df.rename(columns={\"propulsion_type\": \"prosulsion_category\"})\n",
    "\n",
    "    # splitting `approx_#_of_buses` col to get bus count\n",
    "    df1 = col_splitter(df, \"approx_#_of_buses\", \"bus_count\", \"extract_prop_type\", \"(\")\n",
    "\n",
    "    # assign new columns via new_prop_finder and new_bus_size_finder\n",
    "    df2 = df1.assign(\n",
    "        new_prop_type_finder=df1[\"description\"].apply(new_prop_finder),\n",
    "        new_bus_size_type=df1[\"description\"].apply(new_bus_size_finder),\n",
    "        new_project_type=df1[\"description\"].apply(project_type_finder)\n",
    "    )\n",
    "\n",
    "    # cleaning specific values\n",
    "    col_row_updater(df2, \"funding\", \"7443765\", \"bus_count\", 56)\n",
    "    col_row_updater(df2, \"funding\", \"17532900\", \"bus_count\", 12)\n",
    "    col_row_updater(df2, \"funding\", \"40402548\", \"new_prop_type_finder\", \"CNG\")\n",
    "    col_row_updater(df2, \"funding\", \"30890413\", \"new_prop_type_finder\", \"mix (zero and low emission)\")\n",
    "    col_row_updater(df2, \"funding\", \"29331665\", \"new_prop_type_finder\", \"mix (zero and low emission)\")\n",
    "    col_row_updater(df2, \"funding\", \"7598425\", \"new_prop_type_finder\", \"mix (zero and low emission)\")\n",
    "    col_row_updater(df2, \"funding\", \"7443765\", \"new_prop_type_finder\", \"mix (zero and low emission)\")\n",
    "    col_row_updater(df2, \"funding\", \"3303600\", \"new_prop_type_finder\", \"mix (diesel and gas)\")\n",
    "    col_row_updater(df2, \"funding\", \"2063160\", \"new_prop_type_finder\", \"low emission (hybrid)\")\n",
    "    col_row_updater(df2, \"funding\", \"1760000\", \"new_prop_type_finder\", \"low emission (propane)\")\n",
    "    col_row_updater(df2, \"funding\", \"1006750\", \"new_prop_type_finder\", \"ethanol\")\n",
    "    col_row_updater(df2, \"funding\", \"723171\", \"new_prop_type_finder\", \"low emission (propane)\")\n",
    "    col_row_updater(df2, \"funding\", \"23280546\", \"new_prop_type_finder\", \"BEB\")\n",
    "\n",
    "    # update data types\n",
    "    update_cols = [\"funding\", \"bus_count\"]\n",
    "\n",
    "    df2[update_cols] = df2[update_cols].astype(\"int64\")\n",
    "\n",
    "    return df2\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "\n",
    "    # initial df (all projects)\n",
    "#    all_projects = clean_fta_columns()\n",
    "\n",
    "    # projects with bus count > 0 only.\n",
    "#    just_bus = fta_agg_bus_only(all_projects)\n",
    "\n",
    "    # export both DFs\n",
    "#    all_projects.to_parquet(f\"{GCS_PATH}clean_fta_all_projects.parquet\")\n",
    "#    just_bus.to_parquet(f\"{GCS_PATH}clean_fta_bus_only.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a60d451-7532-4053-b0de-3fc7c5a55792",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## TIRCP script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e16119d-f6f3-478b-a419-7c4989557910",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TIRCP\n",
    "## copied over 6/25/24\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shared_utils\n",
    "from calitp_data_analysis.sql import to_snakecase\n",
    "from bus_cost_utils import *\n",
    "\n",
    "def clean_tircp_columns() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    main function that reads in and cleans TIRCP data.\n",
    "    \"\"\"\n",
    "    \n",
    "    file_name = \"raw_TIRCP Tracking Sheets 2_1-10-2024.xlsx\"\n",
    "    tircp_name = \"Project Tracking\"\n",
    "\n",
    "    # read in data\n",
    "    df = pd.read_excel(f\"{GCS_PATH}{file_name}\", sheet_name=tircp_name)\n",
    "\n",
    "    # keep specific columns\n",
    "    keep_col = [\n",
    "        \"Award Year\",\n",
    "        \"Project #\",\n",
    "        \"Grant Recipient\",\n",
    "        \"Project Title\",\n",
    "        \"PPNO\",\n",
    "        \"District\",\n",
    "        \"County\",\n",
    "        \"Project Description\",\n",
    "        \"bus_count\",\n",
    "        \"Master Agreement Number\",\n",
    "        \"Total Project Cost\",\n",
    "        \"TIRCP Award Amount ($)\",\n",
    "    ]\n",
    "\n",
    "    df1 = df[keep_col]\n",
    "\n",
    "    # snakecase\n",
    "    df2 = to_snakecase(df1)\n",
    "\n",
    "    # dict of replacement values\n",
    "    value_replace_dict = {\n",
    "        \"Antelope Valley Transit Authority \": \"Antelope Valley Transit Authority (AVTA)\",\n",
    "        \"Humboldt Transit Authority\": \"Humboldt Transit Authority (HTA)\",\n",
    "        \"Orange County Transportation Authority\": \"Orange County Transportation Authority (OCTA)\",\n",
    "        \"Capitol Corridor Joint Powers Authority\": \"Capitol Corridor Joint Powers Authority (CCJPA)\",\n",
    "        \"Los Angeles County Metropolitan Transportation Authority\": \"Los Angeles County Metropolitan Transportation Authority (LA Metro)\",\n",
    "        \"Monterey-Salinas Transit\": \"Monterey-Salinas Transit District (MST)\",\n",
    "        \"Sacramento Regional Transit (SacRT)\": \"Sacramento Regional Transit District (SacRT)\",\n",
    "        \"Sacramento Regional Transit District\": \"Sacramento Regional Transit District (SacRT)\",\n",
    "        \"Sacramento Regional Transit District (SacRT) \": \"Sacramento Regional Transit District (SacRT)\",\n",
    "        \"San Diego Association of Governments\": \"San Diego Association of Governments (SANDAG)\",\n",
    "        \"Santa Clara Valley Transportation Authority (SCVTA)\": \"Santa Clara Valley Transportation Authority (VTA)\",\n",
    "        \"Southern California  Regional Rail Authority (SCRRA)\": \"Southern California Regional Rail Authority (SCRRA - Metrolink)\",\n",
    "        \"Southern California Regional Rail Authority\": \"Southern California Regional Rail Authority (SCRRA - Metrolink)\",\n",
    "        \"3, 4\": \"VAR\",\n",
    "    }\n",
    "    \n",
    "    # replacing values in agency & county col\n",
    "    df3 = df2.replace(\n",
    "        {\"grant_recipient\": value_replace_dict}\n",
    "    ).replace(\n",
    "        {\"county\": value_replace_dict}\n",
    "    )\n",
    "    \n",
    "    # using update function to update values at specific columns and rows\n",
    "    col_row_updater(df3, 'ppno', 'CP106', 'bus_count', 42)\n",
    "    col_row_updater(df3, 'ppno', 'CP005', 'bus_count', 29)\n",
    "    col_row_updater(df3, 'ppno', 'CP028', 'bus_count', 12)\n",
    "    col_row_updater(df3, 'ppno', 'CP048', 'bus_count', 5)\n",
    "    col_row_updater(df3, 'ppno', 'CP096', 'bus_count', 6)\n",
    "    col_row_updater(df3, 'ppno', 'CP111', 'bus_count', 5)\n",
    "    col_row_updater(df3, 'ppno', 'CP130', 'bus_count', 7)\n",
    "    col_row_updater(df3, 'total_project_cost', 203651000, 'bus_count', 8)\n",
    "    \n",
    "    # columns to change dtype to str\n",
    "    dtype_update = [\n",
    "        'ppno',\n",
    "        'district'\n",
    "    ]\n",
    "    \n",
    "    df3[dtype_update] = df3[dtype_update].astype('str')\n",
    "    \n",
    "    # assigning new columns using imported functions.\n",
    "    df4 = df3.assign(\n",
    "        prop_type = df3['project_description'].apply(new_prop_finder),\n",
    "        bus_size_type = df3['project_description'].apply(new_bus_size_finder),\n",
    "        new_project_type  = df3['project_description'].apply(project_type_finder)\n",
    "    )\n",
    "\n",
    "    return df4\n",
    "\n",
    "def tircp_agg_bus_only(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    filters df to only include projects with bus procurement and for project type = bus only \n",
    "    does not include engineering, planning or construction only projects.\n",
    "    then, aggregates the df by agency name and ppno. Agencies may have multiple projects that procure different types of buses\n",
    "    \"\"\"\n",
    "    df2 = df[\n",
    "        (df[\"bus_count\"] > 0) & (df[\"new_project_type\"] == \"bus only\")\n",
    "    ]\n",
    "    \n",
    "    df3 = (\n",
    "        df2.groupby(\n",
    "            [\n",
    "                \"grant_recipient\",\n",
    "                \"ppno\",\n",
    "                \"prop_type\",\n",
    "                \"bus_size_type\",\n",
    "                \"project_description\",\n",
    "                \"new_project_type\"\n",
    "            ]\n",
    "        )\n",
    "        .agg({\"total_project_cost\": \"sum\", \"bus_count\": \"sum\"})\n",
    "        .reset_index()\n",
    "    )\n",
    "    return df3\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "    \n",
    "    \n",
    "    \n",
    "    # initial df\n",
    "#    df1 = clean_tircp_columns()\n",
    "    \n",
    "    # aggregate \n",
    "#    df2 = tircp_agg_bus_only(df1)\n",
    "    \n",
    "    # export both df's as parquets to GCS\n",
    "#    df1.to_parquet(f'{GCS_PATH}clean_tircp_all_project.parquet')\n",
    "#    df2.to_parquet(f'{GCS_PATH}clean_tircp_bus_only_clean.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a57f455-8b86-47c4-9cda-2114cac504db",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## DGS Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359f3b7a-d691-446f-9a14-424c47fc0929",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DGS\n",
    "# over wrote 6/25\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shared_utils\n",
    "from calitp_data_analysis.sql import to_snakecase\n",
    "from bus_cost_utils import *\n",
    "\n",
    "def calculate_total_cost(row):\n",
    "    \"\"\"\n",
    "    Calculate new column for total cost by checking if total_with_options_per_unit is present or not.\n",
    "    if not, then calculate using contract_unit_price.\n",
    "    to be used with .assign()\n",
    "    \"\"\"\n",
    "    if row[\"total_with_options_per_unit\"] > 0:\n",
    "        return row[\"total_with_options_per_unit\"] * row[\"quantity\"]\n",
    "    else:\n",
    "        return row[\"contract_unit_price\"] * row[\"quantity\"]\n",
    "    \n",
    "def clean_dgs_columns() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    reads in 2 dgs sheets, adds source column, merges both DFs, snakecase columns, update dtypes for monetary columns.\n",
    "    merged first becaues the snakecase function messes with the dtypes for some reason\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    # params\n",
    "    file_17c = \"raw_17c compiled-Proterra Compiled Contract Usage Report .xlsx\"\n",
    "    file_17b = \"raw_17b compiled.xlsx\"\n",
    "    sheet_17c = \"Proterra \"\n",
    "    sheet_17b = \"Usage Report Template\"\n",
    "\n",
    "    # merge columns for dataframes\n",
    "    merge_col = [\n",
    "        \"Agency Billing Code\",\n",
    "        \"Contract Line Item Number (CLIN)                (RFP ID)\",\n",
    "        \"Contract Unit Price\",\n",
    "        \"Delivery Date\",\n",
    "        \"Extended Contract Price Paid\",\n",
    "        \"Index Date / Catalog Version\",\n",
    "        \"Item Description\",\n",
    "        \"List Price/MSRP\",\n",
    "        \"Manufacturer (OEM)\",\n",
    "        \"Manufacturer Part Number (OEM #)\",\n",
    "        \"Ordering Agency Name\",\n",
    "        \"Purchase Order Date\",\n",
    "        \"Purchase Order Number\",\n",
    "        \"Purchasing Authority Number                    (for State departments)\",\n",
    "        \"Quantity in \\nUnit of Measure\\n\",\n",
    "        \"Quantity\",\n",
    "        \"source\",\n",
    "        \"State (S) or Local (L) agency\",\n",
    "        \"Unit of Measure\",\n",
    "        \"UNSPSC Code\\n(Version 10)\",\n",
    "        \"Supplier Contract Usage ID\",\n",
    "    ]\n",
    "\n",
    "    # columns to change dtype\n",
    "    to_int64 = [\n",
    "        \"contract_unit_price\",\n",
    "        \"extended_contract_price_paid\",\n",
    "        \"total_with_options_per_unit\",\n",
    "        \"grand_total\",\n",
    "    ]\n",
    "    \n",
    "    # read in data\n",
    "    dgs_17c = pd.read_excel(f\"{GCS_PATH}{file_17c}\", sheet_name=sheet_17c)\n",
    "    dgs_17b = pd.read_excel(f\"{GCS_PATH}{file_17b}\", sheet_name=sheet_17b)\n",
    "\n",
    "    # add new column to identify source\n",
    "    dgs_17c[\"source\"] = \"17c\"\n",
    "    dgs_17b[\"source\"] = \"17b\"\n",
    "\n",
    "    # merge\n",
    "    dgs_17bc = pd.merge(dgs_17b, dgs_17c, how=\"outer\", on=merge_col).fillna(0)\n",
    "\n",
    "    # snakecase\n",
    "    dgs_17bc = to_snakecase(dgs_17bc)\n",
    "\n",
    "    # takes list of columns and updates to int64\n",
    "    dgs_17bc[to_int64] = dgs_17bc[to_int64].astype(\"int64\")\n",
    "\n",
    "    # change purchase_order_number col to str\n",
    "    dgs_17bc[\"purchase_order_number\"] = dgs_17bc[\"purchase_order_number\"].astype(\"str\")\n",
    "\n",
    "    # adds 3 new columns from functions\n",
    "    dgs_17bc2 = dgs_17bc.assign(\n",
    "        total_cost=dgs_17bc.apply(calculate_total_cost, axis=1),\n",
    "        new_prop_type=dgs_17bc[\"item_description\"].apply(new_prop_finder),\n",
    "        new_bus_size=dgs_17bc[\"item_description\"].apply(new_bus_size_finder),\n",
    "    )\n",
    "\n",
    "    return dgs_17bc2\n",
    "\n",
    "def dgs_agg_by_agency(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    function that aggregates the DGS data frame by transit agency and purchase order number (PPNO) to get total cost of just buses without options.\n",
    "    first, dataframe is filtered for rows containing buses (does not include rows with 'not specified').\n",
    "    then, group by agency, PPNO, prop type and bus size. and aggregate the quanity and total cost of just buses.\n",
    "    Possible for agencies to have multiple PPNOs for different bus types and sizes.\n",
    "    \"\"\"\n",
    "    # filter for rows containing bus, does not include accessories/warranties/parts/etc.\n",
    "    agg_agency_bus_count = df[~df[\"new_prop_type\"].str.contains(\"not specified\")]\n",
    "\n",
    "    agg_agency_bus_count2 = agg_agency_bus_count[\n",
    "        [\n",
    "            \"ordering_agency_name\",\n",
    "            \"purchase_order_number\",\n",
    "            \"item_description\",\n",
    "            \"quantity\",\n",
    "            \"source\",\n",
    "            \"total_cost\",\n",
    "            \"new_prop_type\",\n",
    "            \"new_bus_size\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    agg_agency_bus_count3 = (\n",
    "        agg_agency_bus_count2.groupby(\n",
    "            [\n",
    "                \"ordering_agency_name\",\n",
    "                \"purchase_order_number\",\n",
    "                \"new_prop_type\",\n",
    "                \"new_bus_size\",\n",
    "            ]\n",
    "        )\n",
    "        .agg(\n",
    "            {\n",
    "                \"quantity\": \"sum\",\n",
    "                \"total_cost\": \"sum\",\n",
    "                \"source\": \"max\",\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    return agg_agency_bus_count3\n",
    "\n",
    "def dgs_agg_by_agency_w_options(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    similar to the previous function, aggregates the DGS dataframe by transit agency to get total cost of buses with options.\n",
    "    agencies may order buses with different configurations, resulting in different total cost.\n",
    "    function creates 1 df of only buses to retain initial proulsion type, size type and quanity of buses.\n",
    "    then, creates 2nd df of aggregated total cost of buses+options, by transit agency.\n",
    "    lastly, both df's are merged together.\n",
    "    \"\"\"\n",
    "    # filter df for rows NOT containing 'not specified'. only returns rows with buses\n",
    "    dfa = df[~df[\"new_prop_type\"].str.contains(\"not specified\")]\n",
    "\n",
    "    # keep specific columns\n",
    "    df2 = dfa[\n",
    "        [\n",
    "            \"ordering_agency_name\",\n",
    "            \"purchase_order_number\",\n",
    "            \"quantity\",\n",
    "            \"new_prop_type\",\n",
    "            \"new_bus_size\",\n",
    "            \"source\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # aggregate by agency and PPNO, get total cost of buses with options\n",
    "    df3 = (\n",
    "        df.groupby([\"ordering_agency_name\", \"purchase_order_number\"])\n",
    "        .agg({\"total_cost\": \"sum\"})\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # merge both dataframes on agency and PPNO to get bus only rows & total cost with options.\n",
    "    merge = pd.merge(\n",
    "        df2, df3, on=[\"ordering_agency_name\", \"purchase_order_number\"], how=\"left\"\n",
    "    )\n",
    "\n",
    "    return merge\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "    \n",
    "\n",
    "    # initial df\n",
    "#    df1 = clean_dgs_columns()\n",
    "    \n",
    "    #df of just bus cost (no options)\n",
    "#    just_bus = dgs_agg_by_agency(df1)\n",
    "    \n",
    "    #df of bus cost+options\n",
    "#    bus_w_options = dgs_agg_by_agency_w_options(df1)\n",
    "    \n",
    "    #export serperate df's as parquet to GCS\n",
    "#    just_bus.to_parquet(f'{GCS_PATH}clean_dgs_all_projects.parquet')\n",
    "#    bus_w_options.to_parquet(f'{GCS_PATH}clean_dgs_bus_only_w_options.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ab982a-afff-4c07-a19a-703ab82d27b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## cost_per_bus_cleaner / all_bus_cost_cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f4bd75-f614-4937-880a-1e1a6ff2eb7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cost per bus cleaner\n",
    "# rename to all_bus_cost_cleaner?\n",
    "# overwrote 6/25/24\n",
    "\n",
    "import pandas as pd\n",
    "from bus_cost_utils import *\n",
    "from scipy.stats import zscore\n",
    "\n",
    "\n",
    "\n",
    "def prepare_all_data() ->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    primary function to read-in, merge data across FTA, TIRCP and DGS data.\n",
    "    standardizes columns names, then exports as parquet.\n",
    "    \"\"\"\n",
    "    # variables for file names\n",
    "\n",
    "\n",
    "    \n",
    "    # dictionary to update columns names \n",
    "    col_dict = {\n",
    "        \"funding\": \"total_cost\",\n",
    "        \"grant_recipient\": \"transit_agency\",\n",
    "        \"new_bus_size\": \"bus_size_type\",\n",
    "        \"new_bus_size_type\": \"bus_size_type\",\n",
    "        \"new_prop_type\": \"prop_type\",\n",
    "        \"new_prop_type_finder\": \"prop_type\",\n",
    "        \"ordering_agency_name\": \"transit_agency\",\n",
    "        \"purchase_order_number\": \"ppno\",\n",
    "        \"quantity\": \"bus_count\",\n",
    "        \"total_project_cost\": \"total_cost\",\n",
    "        \"project_sponsor\": \"transit_agency\",\n",
    "    }\n",
    "\n",
    "    # reading in data\n",
    "    # bus only projects for each datase\n",
    "    fta = pd.read_parquet(f\"{GCS_PATH}clean_fta_bus_only.parquet\")\n",
    "    tircp = pd.read_parquet(f\"{GCS_PATH}clean_tircp_bus_only_clean.parquet\")\n",
    "    dgs = pd.read_parquet(f\"{GCS_PATH}clean_dgs_bus_only_w_options.parquet\")\n",
    "    \n",
    "    # adding new column to identify source\n",
    "    fta[\"source\"] = \"fta\"\n",
    "    tircp[\"source\"] = \"tircp\"\n",
    "    dgs[\"source\"] = \"dgs\"\n",
    "\n",
    "    # using .replace() with dictionary to update column names\n",
    "    fta2 = fta.rename(columns=col_dict)\n",
    "    tircp2 = tircp.rename(columns=col_dict)\n",
    "    dgs2 = dgs.rename(columns=col_dict)\n",
    "    \n",
    "    # merging fta2 and tircp 2\n",
    "    merge1 = pd.merge(fta2,\n",
    "        tircp2,\n",
    "        on=[\n",
    "            \"transit_agency\",\n",
    "            \"prop_type\",\n",
    "            \"bus_size_type\",\n",
    "            \"total_cost\",\n",
    "            \"bus_count\",\n",
    "            \"source\",\n",
    "            \"new_project_type\"\n",
    "        ],\n",
    "        how=\"outer\",\n",
    "    )\n",
    "    \n",
    "    # mergeing merge1 and dgs2\n",
    "    merge2 = pd.merge(merge1,\n",
    "        dgs2,\n",
    "        on=[\n",
    "            \"transit_agency\",\n",
    "            \"prop_type\",\n",
    "            \"bus_size_type\",\n",
    "            \"total_cost\",\n",
    "            \"bus_count\",\n",
    "            \"source\",\n",
    "            \"ppno\",\n",
    "        ],\n",
    "        how=\"outer\",\n",
    "    )\n",
    "    #normalizing data with cost per bus\n",
    "    #calculating cost per bus here\n",
    "    merge2[\"cost_per_bus\"] = (merge2[\"total_cost\"] / merge2[\"bus_count\"]).astype(\"int64\")\n",
    "    \n",
    "    #calculating zscore on cost per bus\n",
    "    merge2[\"zscore_cost_per_bus\"] = zscore(merge2[\"cost_per_bus\"])\n",
    "   \n",
    "    #flag any outliers\n",
    "    merge2[\"is_cpb_outlier?\"] = merge2[\"zscore_cost_per_bus\"].apply(outlier_flag)\n",
    "    return merge2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "    \n",
    "    # initial df\n",
    "#    df1 = prepare_all_data()\n",
    "    #remove outliers based on cost per bus zscore\n",
    "#    df2 = df1[df1[\"is_cpb_outlier?\"]==False]\n",
    "    \n",
    "    # export to gcs\n",
    "    #full data, with outliers\n",
    "#    df1.to_parquet(f'{GCS_PATH}cleaned_cpb_analysis_data_merge.parquet')\n",
    "    # no outliers\n",
    "#    df2.to_parquet(f'{GCS_PATH}cleaned_no_outliers_cpb_analysis_data_merge.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c163a75-eb4b-4a09-b035-7692f9ea68f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# NB Variables rework\n",
    "time to organize, cut down, consolidate variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fc1d6c-85b5-4890-84f1-66e33eb9d97c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Notes Variable Categories\n",
    "- initial DF stuff (all cleaned merged data)\n",
    " - all_bus\n",
    " - all_projecT_counter function\n",
    "\n",
    "lots of total counts\n",
    "**this can be solved by filtering the same df but its different grant type, or using a table of groupby grant type and count of projects**\n",
    "\n",
    " COMPLETE count of all projects\n",
    "- ~~all_project_count~~\n",
    "- ~~total_bus_count~~\n",
    "- ~~total_funding~~\n",
    "- determined that all projects count isnt needed, total bus and funding is caclulated in multiple pivot tables.\n",
    "\n",
    " count of all projects for each grant type\n",
    "- count_all_fta\n",
    "- count_all_tircp\n",
    "- count_all_dgs\n",
    " fix: use all_project_count to create a pivot table with margins of each grant type. margins should also add a grand total col\n",
    " \n",
    " []count of bus only projects\n",
    " - ~~bus_only_project_count~~ (this is in merged data)\n",
    " \n",
    " count of bus only projects for each grant type\n",
    " - ~~bus_only_count_fta~~\n",
    " - ~~bus_only_count_tircp~~\n",
    " - ~~bus_only_count_dgs~~\n",
    " fix: use all_project_count to create a summarized dataframe of each grant type\n",
    "\n",
    " \n",
    " \n",
    "- ZEB only\n",
    "    ~~- zeb_only_df function~~\n",
    "    switched to filtering the dataframe to get ZEB answers\n",
    "\n",
    "- non-ZEB only\n",
    "    ~~- non_zeb_only_df function~~\n",
    "    switched to filtering the dataframe\n",
    "    \n",
    "- means and standard deviations\n",
    "    - switched to using weighted average for chart calculation\n",
    "    - for charts?\n",
    "\n",
    "- other things from the initial analysis to include/re-work?\n",
    "    - \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a718624-5c9e-463d-8de4-1a6f66c9e4d8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Draft/Test cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5224cfe-6b3a-4c68-a7b5-58df0ff8f85e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Testing `new_cpb_aggregate` function against initial `cpb_appregate` function.\n",
    "to make sure the core data matches, and expect the new function to provide zscores and outlier flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ffd5a9-b772-4509-b84c-9a96760b3112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making copy of final \n",
    "# test = final #THIS DOES NOT WORK! this is just assigning a new name to final\n",
    "test = pd.read_parquet(f'{GCS_PATH}old/cpb_analysis_data_merge.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aa3674-78fe-4ba9-8f5e-697d91ff4011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the improved cpb agg function\n",
    "# default grouby column is `transit_agency`\n",
    "\n",
    "agg1 = new_cpb_aggregate(test)\n",
    "\n",
    "# there are some duplicate agencies in the inial DF, these get aggregated together after using the function\n",
    "# the resulting DF is shorter\n",
    "display(\n",
    "    agg1.shape,\n",
    "    agg1.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bca15a-c12c-4cf5-a5a9-d591ee73a359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirming the default cpb_agg is working\n",
    "agg1.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637032e4-d855-4190-a6f5-ff695f77143f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg looks good\n",
    "# double checked it against the old agg function, CPB numbers match between this new function and old one\n",
    "display(\n",
    "\n",
    "    agg1[\"new_is_cpb_outlier?\"].value_counts(),\n",
    "    agg1[\"new_zscore_cost_per_bus\"].min(),\n",
    "    agg1[\"new_zscore_cost_per_bus\"].max(),\n",
    "    agg1[agg1[\"new_is_cpb_outlier?\"] == True]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1f4c86-e85d-41d8-83f6-14aadce48d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test to aggregate by other columns \n",
    "agg_prop_type = new_cpb_aggregate(test,\"prop_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59298193-fc78-4ffb-bfc3-326593c19edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to compare to the agg prop data in the report\n",
    "\n",
    "from cost_per_bus_nb_scripts import cpb_aggregate, no_outliers\n",
    "\n",
    "old_prop_agg = cpb_aggregate(no_outliers, \"prop_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01883fc0-4f6d-4e6a-a88f-97a5914b281b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVERYTHING CHECKS OUT!\n",
    "display(\n",
    "    old_prop_agg.shape,\n",
    "    agg_prop_type.shape,\n",
    "    old_prop_agg.head(),\n",
    "    agg_prop_type.head()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52204752-3932-4ce6-98ac-de8ad3a1f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double checking the bus size agg new vs old\n",
    "#EVERYTHING CHECKS OUT!\n",
    "new_agg_bus_size = new_cpb_aggregate(test, \"bus_size_type\")\n",
    "old_size_agg = cpb_aggregate(no_outliers, \"bus_size_type\")\n",
    "display(\n",
    "    old_size_agg.shape,\n",
    "    new_agg_bus_size.shape,\n",
    "    old_size_agg,\n",
    "    new_agg_bus_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0391dd4d-23e1-49cb-8123-509954c796e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVERYTHING CHECKS OUT!\n",
    "# move forward with `new_cpb_aggregate` function\n",
    "new_agg_agency = new_cpb_aggregate(test)\n",
    "old_agency_agg = cpb_aggregate(no_outliers, \"transit_agency\")\n",
    "display(\n",
    "    old_agency_agg.shape,\n",
    "    new_agg_agency.shape,\n",
    "    old_agency_agg.head(),\n",
    "    new_agg_agency.head()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3428875a-6a64-41bc-8f9c-81902006d7f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing variables rework\n",
    "there are a lot of variables in the initial script. need to cut down the amount of variables or at least make it more efficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21298ee-0efb-4f91-ba63-55fc2645a4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all cleaned project data without outliers\n",
    "# cpb_analysis_data_merge is bus only projects. all DGS rows were Bus only projects anyways\n",
    "\n",
    "merged_data = pd.read_parquet(f'{GCS_PATH}cleaned_no_outliers_cpb_analysis_data_merge.parquet')\n",
    "display(\n",
    "    merged_data.columns,\n",
    "    merged_data.shape,\n",
    "    merged_data.head(),\n",
    "    merged_data[\"zscore_cost_per_bus\"].agg([\"min\",\"max\"])\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece95fb7-cbb8-46bd-a5f9-2b68a47a4817",
   "metadata": {},
   "outputs": [],
   "source": [
    "## moved to final NB\n",
    "\n",
    "# aggregating by big categories\n",
    "agg_agency = new_cpb_aggregate(merged_data)\n",
    "agg_prop = new_cpb_aggregate(merged_data, column=\"prop_type\")\n",
    "agg_bus_size = new_cpb_aggregate(merged_data, column=\"bus_size_type\")\n",
    "agg_source = new_cpb_aggregate(merged_data, column=\"source\")\n",
    "\n",
    "#overall agency info\n",
    "display(\n",
    "    #min max,\n",
    "    agg_agency[\"new_cost_per_bus\"].agg([\"min\",\"max\"]),\n",
    "    agg_agency[\"total_bus_count\"].agg([\"min\",\"max\"]),\n",
    "    agg_agency[\"total_agg_cost\"].agg([\"min\",\"max\"]),\n",
    "    agg_agency[\"new_zscore_cost_per_bus\"].agg([\"min\",\"max\"]),\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03940ccb-d1e6-439d-a930-13dae17537b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    merged_data.shape,\n",
    "    agg_agency.shape,\n",
    "    merged_data.head(),\n",
    "    agg_agency.head()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1696d78f-7018-417b-9847-d82edac3acdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing pivot table on `merged_data`\n",
    "# moved to final NB\n",
    "#pivot table to get totals for each prop type\n",
    "pivot_prop_type = pd.pivot_table(\n",
    "    merged_data,\n",
    "    values = [\"bus_count\", \"total_cost\"],\n",
    "    index = \"prop_type\",\n",
    "    aggfunc = \"sum\",\n",
    "    margins = True,\n",
    "    margins_name = \"Grand Total\"\n",
    ").reset_index()\n",
    "pivot_prop_type[\"cost_per_bus\"] = (pivot_prop_type[\"total_cost\"] / pivot_prop_type[\"bus_count\"]).astype(\"int64\")\n",
    "\n",
    "display(\n",
    "    #from new_cpb_agg\n",
    "    agg_prop[[\"prop_type\",\"total_agg_cost\",\"total_bus_count\",\"new_cost_per_bus\"]],\n",
    "    #pivot\n",
    "    pivot_prop_type\n",
    ")\n",
    "# same data, dont need  the pivot table anymore, but the pivot table does have grand total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca709e43-4947-4a34-970f-216d4b6ab7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#moved to final NB 6/25\n",
    "\n",
    "#pivot table to get grand total for zeb/non-zeb only data\n",
    "\n",
    "# keep this\n",
    "zeb_list =[\n",
    "    \"BEB\",\n",
    "    \"FCEB\",\n",
    "    \"electric (not specified)\",\n",
    "    \"zero-emission bus (not specified)\",\n",
    "]\n",
    "\n",
    "zeb_projects = merged_data[merged_data[\"prop_type\"].isin(zeb_list)]\n",
    "\n",
    "#keep this\n",
    "non_zeb_list =[\n",
    "    \"CNG\",\n",
    "    \"ethanol\",\n",
    "    \"low emission (hybrid)\",\n",
    "    \"low emission (propane)\",\n",
    "    \"mix (zero and low emission)\",\n",
    "]\n",
    "\n",
    "non_zeb_projects = merged_data[merged_data[\"prop_type\"].isin(non_zeb_list)]\n",
    "\n",
    "#keep this\n",
    "pivot_zeb_prop = pd.pivot_table(\n",
    "    #filted incoming DF for zeb prop types\n",
    "    zeb_projects,\n",
    "    values = [\"bus_count\", \"total_cost\"],\n",
    "    index = \"prop_type\",\n",
    "    aggfunc = \"sum\",\n",
    "    margins = True,\n",
    "    margins_name = \"Grand Total\"\n",
    ").reset_index()              \n",
    "\n",
    "pivot_zeb_prop[\"cost_per_bus\"] = (pivot_zeb_prop[\"total_cost\"] / pivot_zeb_prop[\"bus_count\"]).astype(\"int64\")\n",
    "\n",
    "#keep this\n",
    "pivot_non_zeb_prop = pd.pivot_table(\n",
    "    #filted incoming DF for non-zeb prop types\n",
    "    non_zeb_projects,\n",
    "    values = [\"bus_count\", \"total_cost\"],\n",
    "    index = \"prop_type\",\n",
    "    aggfunc = \"sum\",\n",
    "    margins = True,\n",
    "    margins_name = \"Grand Total\"\n",
    ").reset_index()\n",
    "\n",
    "pivot_non_zeb_prop[\"cost_per_bus\"] = (pivot_non_zeb_prop[\"total_cost\"] / pivot_non_zeb_prop[\"bus_count\"]).astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01647d83-8b4f-47a9-ab57-a1db7cd501dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    #zeb data 3 different methods\n",
    "    #1. filtering agg_prop by zeb list, no grand totas\n",
    "    #2. filtering pivot talbe by zeb list, without grand totals\n",
    "    #3. dedicated pivot table for zeb, with grand totals\n",
    "    #agg_prop[agg_prop[\"prop_type\"].isin(zeb_list)],\n",
    "    #pivot_prop_type.loc[zeb_list],\n",
    "    pivot_zeb_prop,\n",
    "    \n",
    "    #non-zeb same 3 methods\n",
    "    #agg_prop[agg_prop[\"prop_type\"].isin(non_zeb_list)],\n",
    "    #pivot_prop_type.loc[non_zeb_list],\n",
    "    pivot_non_zeb_prop\n",
    ")\n",
    "# confirmed all data is the same, but need pivot for grand total rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be3ef4f-0bf3-4770-a8b7-340d372ae1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# answers total buses sizes\n",
    "pivot_size = pd.pivot_table(\n",
    "    merged_data,\n",
    "    values = [\"bus_count\", \"total_cost\"],\n",
    "    index = \"bus_size_type\",\n",
    "    aggfunc = \"sum\",\n",
    "    margins = True,\n",
    "    margins_name = \"Grand Total\"\n",
    ").reset_index()\n",
    "\n",
    "pivot_size[\"cost_per_bus\"] = (pivot_size[\"total_cost\"] / pivot_size[\"bus_count\"]).astype(\"int64\")\n",
    "\n",
    "display(\n",
    "    agg_bus_size[[\"bus_size_type\",\"total_agg_cost\",\"total_bus_count\",\"new_cost_per_bus\"]],\n",
    "    pivot_size,\n",
    "    pivot_prop_type[pivot_prop_type[\"prop_type\"] == \"Grand Total\"]\n",
    ")\n",
    "\n",
    "#same data, dont need pivot for this one because the grand totals will be the same as pivot_prop_type. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c933257-bdc2-4007-9571-58475118073c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moved to final NB 6/25\n",
    "\n",
    "# answers total buses and cost per grant type\n",
    "pivot_source = pd.pivot_table(\n",
    "    merged_data,\n",
    "    values = [\"bus_count\", \"total_cost\"],\n",
    "    index = \"source\",\n",
    "    aggfunc = \"sum\",\n",
    "    margins = True,\n",
    "    margins_name = \"Grand Total\"\n",
    ").reset_index()\n",
    "\n",
    "pivot_source[\"cost_per_bus\"] = (pivot_source[\"total_cost\"] / pivot_source[\"bus_count\"]).astype(\"int64\")\n",
    "\n",
    "display(\n",
    "    agg_source[[\"source\",\"total_agg_cost\",\"total_bus_count\",\"new_cost_per_bus\"]],\n",
    "    pivot_source\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11547020-dd35-4745-98f8-bbd02fccaa23",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing Charts\n",
    "\n",
    "using `merged_data`, now without outliers.\n",
    "charts looking good, similar results to initial charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aace38a4-3f2d-460d-a258-59efa659f852",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4753f3ea-00b6-4d5e-a3f0-73b3d3593acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# means and standard deviations\n",
    "# for graphs\n",
    "cpb_mean = merged_data[\"cost_per_bus\"].mean()\n",
    "cpb_std = merged_data[\"cost_per_bus\"].std()\n",
    "\n",
    "#testing weighted average calculation for sub-set non-zeb and zeb\n",
    "zeb_cpb_wt_avg = (merged_data[merged_data[\"prop_type\"].isin(zeb_list)][\"total_cost\"].sum() / merged_data[merged_data[\"prop_type\"].isin(zeb_list)][\"bus_count\"].sum())\n",
    "non_zeb_cpb_wt_avg = (merged_data[merged_data[\"prop_type\"].isin(non_zeb_list)][\"total_cost\"].sum() / merged_data[merged_data[\"prop_type\"].isin(non_zeb_list)][\"bus_count\"].sum())\n",
    "display(\n",
    "    cpb_mean,\n",
    "    cpb_std,\n",
    "    zeb_cpb_wt_avg,\n",
    "    non_zeb_cpb_wt_avg\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2007be9d-13ec-4d0d-a642-d9a42448b924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# why is the average different when i use .mean() vs. total cost / bus cout\n",
    "\n",
    "display(\n",
    "    #this is the arithmatic mean, sums all the `cost_per_bus` rows, the divide by the number of rows. (row-wise)\n",
    "    zeb_projects[\"cost_per_bus\"].mean(),\n",
    "    \n",
    "    #this is like the accounting method of calculating average (Total Cost and Total Quantity Approach (Weighted Average))\n",
    "    pivot_zeb_prop,\n",
    "    \n",
    "    # calculating mean by weighted average the long way (total cost / total bus count, similar to pivot table)\n",
    "    (zeb_projects[\"total_cost\"].sum() / zeb_projects[\"bus_count\"].sum())\n",
    ")\n",
    "\n",
    "# so the calculated grand total cost_per_bus is equivilent to the weighted average cost per bus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8645cf77-b30a-4c45-b943-ac81e8b5a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chart of all cost per bus in the analysis.\n",
    "# moved to final NB 6/26\n",
    "dist_curve(\n",
    "    df=merged_data,\n",
    "    mean=cpb_mean,\n",
    "    std=cpb_std,\n",
    "    title=\"all buses, cost per bus distribution\",\n",
    "    xlabel=\"cost per bus, $ million(s)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefa6800-df50-4eda-95f8-74363ef942d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZEB cost per bus \n",
    "# moved to final NB 6/26\n",
    "dist_curve(\n",
    "    df=zeb_projects,\n",
    "    #using the accounting, weighted average approach to mean (total cost/total number of buses)\n",
    "    mean=zeb_cpb_wt_avg,\n",
    "    # need to investigate if std needs to be weighted as well?\n",
    "    std=zeb_projects[\"cost_per_bus\"].std(),\n",
    "    title=\"ZEB buses, cost per bus distribution\",\n",
    "    xlabel=\"cost per bus, $ million(s)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563304d2-2d98-44e6-b3a4-fd54f63fc0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-zeb cost per bus\n",
    "# moved to final NB 6/26\n",
    "dist_curve(\n",
    "    df=non_zeb_projects,\n",
    "    mean=non_zeb_cpb_wt_avg,\n",
    "    std=non_zeb_projects[\"cost_per_bus\"].std(),\n",
    "    title=\"non-ZEB costper bus Distribution\",\n",
    "    xlabel='\"cost per bus, $ million(s)\"',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa916127-57d9-4c1c-b5eb-8b7b7e4ac672",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_bus_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f11c857-ddbe-4871-aeca-e27fa00fbde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple bar charts in one cell\n",
    "# moved to final NB 6/26\n",
    "\n",
    "# cpb by prop type\n",
    "make_chart(\"new_cost_per_bus\", \"Cost per bus by propulsion type\", x_col=\"prop_type\", data=agg_prop)\n",
    "\n",
    "# bus count by prop type\n",
    "make_chart(\"total_bus_count\", \"Bus count by propulsion type\", x_col=\"prop_type\", data=agg_prop)\n",
    "\n",
    "#bus size bar chart\n",
    "make_chart(\"total_bus_count\", \"\"\"Amount of buses procured by bus size.\n",
    "excluding 'not specified' responses.\"\"\", x_col=\"bus_size_type\",data=agg_bus_size[agg_bus_size[\"bus_size_type\"]!=\"not specified\"])\n",
    "\n",
    "# pivot table to\n",
    "agg_prop[[\"prop_type\",\"new_cost_per_bus\",\"total_bus_count\"]].sort_values(by=\"new_cost_per_bus\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9270ab8f-25ff-4de3-aca5-7ef4637a4f9c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing summary and conclusion\n",
    "time to rework the summary section.\n",
    "\n",
    "no more long expositions and variables. try to get the same point across using tables instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2472461d-7663-4b66-9bde-4c2a199707a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moved to final NB 6/25\n",
    "\n",
    "new_summary = f\"\"\"\n",
    "\n",
    "# Bus Procurement Cost Analysis\n",
    "\n",
    "## Summary\n",
    "This analysis examines the cost of buses for transit agencies across the county. Specifically, to observe the variation of bus cost for propulsion type and bus sizes.\n",
    "\n",
    "Data was compiled from three data sources:\n",
    "1. FTA Bus and Low- and No-Emission Grant Awards press release (federally funded, nationwide data)\n",
    "2. TIRCP project data (state-funded, California only)\n",
    "3. DGS usage report for all procurements from California agencies purchasing from New Flyer and Portera Inc.. \n",
    "\n",
    "The initial dataset contained close to 300 projects, but was paired down due to projects including components other than buses. Examples include: projects that constructed new facilities, trainings or other non-bus related items like trains and sea farries were excluded.\n",
    "The resulting dataset only contained projects that were solely used to procure buses. \n",
    "\n",
    "{len(merged_data)} projects were determined to contain solely bus purchases. \n",
    "These projects were aggregated against propulsion type and bus size type, and categorized by ZEB and non-ZEB.\n",
    "\n",
    "\n",
    "Breakdown of each data souce:\n",
    "{pivot_source.to_markdown(index=False)}\n",
    "\n",
    "\n",
    "**ZEB buses include:**\n",
    "- zero-emission (not specified) \n",
    "- electric (not specified)\n",
    "- battery electric \n",
    "- fuel cell electric\n",
    "\n",
    "**Non-ZEB buses include:**\n",
    "- CNG \n",
    "- ethanol \n",
    "- ow emission (hybrid, propane) \n",
    "- diesel \n",
    "- gas\n",
    "\n",
    "Below are charts and tables that summarize the findings.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(new_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7472ba04-7def-46ef-814b-bf63c1016f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moved to final NB 6/25\n",
    "display(\n",
    "    Markdown(\"**ZEB Summary**\"),\n",
    "    pivot_zeb_prop,\n",
    "    \n",
    "    Markdown(\"**Non-ZEB Summary**\"),\n",
    "    pivot_non_zeb_prop,\n",
    "    \n",
    "    Markdown(\"The remaining buses did not specify a propulsion type\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d0361d-b165-4607-b22e-66ae4234863d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#min max values for all projects\n",
    "bus_min_max_summary(data=agg_agency,col1=\"new_cost_per_bus\")\n",
    "bus_min_max_summary(data=agg_agency,col1=\"total_bus_count\")\n",
    "bus_min_max_summary(data=agg_agency,col1=\"total_agg_cost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6896d09d-a8e8-4351-bf69-6538d031bf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moved to final NB 6/25\n",
    "## min max values of just ZEB projects\n",
    "# YES I CAN!!\n",
    "new_cols =[\n",
    "    \"transit_agency\",\n",
    "    \"prop_type\",\n",
    "    \"total_cost\",\n",
    "    \"bus_count\",\n",
    "    \"cost_per_bus\"]\n",
    "\n",
    "display(Markdown(\"**Which Agneices had the highest and lowest cost per bus?**\")),\n",
    "bus_min_max_summary(data=zeb_projects, col1=\"cost_per_bus\", col_list=new_cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743b25a2-8693-44f7-98fe-384e910620a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moved to final NB 6/25\n",
    "display(Markdown(\n",
    "    \"**Which agency procured the most and least amount of ZEBs?**\"\n",
    "))\n",
    "bus_min_max_summary(data=zeb_projects, col1=\"bus_count\", col_list=new_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a95018-0ac8-450d-97d2-aa394e94779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moved to final NB 6/25\n",
    "display(Markdown(\n",
    "    \"**Which Agency had the most and least total ZEB cost?**\"\n",
    "))\n",
    "bus_min_max_summary(data=zeb_projects, col1=\"total_cost\", col_list=new_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2f5572-0683-4909-8e2a-deea22c006fb",
   "metadata": {},
   "source": [
    "## conslusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39c89a1-a726-44f9-808b-bcf936c77254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moved to final NB 6/25\n",
    "conclusion = f\"\"\"\n",
    "**Conclusion**\n",
    "\n",
    "Based on these findings, The average cost of a ZEB, throughout the US, is ~$1,000,000, roughly twice the price of a conventional, non-ZEB.\n",
    "The variance in cost depends mainly on the options the Trasnit\n",
    "Agencies chooses. Highly optioned/customized buses contribute to high cost.\n",
    "Unfortunately, analyzing the cost of configuable options is outside the scope of data provided. \n",
    "\"\"\"\n",
    "display(\n",
    "    Markdown(conclusion)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc07a8f6-0108-4cf9-81bd-dbd7f50af21d",
   "metadata": {},
   "source": [
    "# Aditonal function refactor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a65a24-7315-49c3-b321-fca7c92447c9",
   "metadata": {},
   "source": [
    "## Outlier Flag Refactor\n",
    "\n",
    "in my original `outlier_flag` function. it just sets up the conditionals. then i used `df[col].apply(outlier_flag)` to apply the function to each row/col in the dataframe in another step.\n",
    "\n",
    "These steps can be combined together to make a new function that includes:\n",
    "1. stating the dataframe\n",
    "2. stating the column\n",
    "3. using a lambda function to get a true/false values based on the col and conditional\n",
    "4. using the apply method to apply the lambda function to each row in the dataframe\n",
    "\n",
    "So intead of using the initial function like this:\n",
    "* `merge2[\"is_cpb_outlier?\"] = merge2[\"zscore_cost_per_bus\"].apply(outlier_flag)`\n",
    "\n",
    "I can use a new function that works like this:\n",
    "* `df_agg[\"new_is_cpb_outlier\"] = new_outlier_flag(df_agg, \"new_zscore_cost_per_bus\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78de7dd-d075-4c8e-ac4e-a6d97f3f7e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial function\n",
    "def outlier_flag(col):\n",
    "    \"\"\"\n",
    "    function to flag outlier rows. use with .apply()\n",
    "    \"\"\"\n",
    "    \n",
    "    return col <= -3 or col >= 3\n",
    "\n",
    "# how it was used\n",
    "#flag any outliers\n",
    "    # merge2[\"is_cpb_outlier?\"] = merge2[\"zscore_cost_per_bus\"].apply(outlier_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "226d832a-284e-4510-8a62-864eab4e299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suggested change\n",
    "def new_outlier_flag_v1(df:pd.DataFrame, col: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    function to flag outliers based on a given column.\n",
    "    applies lambda function to each row in df to check if column value has an absolute value of > 3.\n",
    "    axis= 1 to indicate row \n",
    "    \"\"\"\n",
    "    return df.apply(lambda x: True if abs(x[col]) > 3\n",
    "             else False, axis=1)\n",
    "\n",
    "# use case\n",
    "# df_agg[\"new_is_cpb_outlier\"] = outlier_flag(df_agg, \"new_zscore_cost_per_bus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8361bb09-7294-41a3-a3e3-35e48d624ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_outlier_flag_v2(df:pd.DataFrame, col: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    function to flag outliers based on a given column.\n",
    "    applies lambda function to each row in df to check if column value has an absolute value of > 3.\n",
    "    no `axis = 1` because this operates on a single series\n",
    "    \"\"\"\n",
    "    return df[col].apply(lambda x: True if abs(x) > 3 else False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af314d18-5ff2-427c-94a6-1c5b65181a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "merged_data['new_outlier_flags_v1'] = new_outlier_flag_v1(merged_data,'zscore_cost_per_bus')\n",
    "merged_data['new_outlier_flags_v2'] = new_outlier_flag_v2(merged_data,'zscore_cost_per_bus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "152632d4-d8ec-4af2-b730-3b5125b413c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_cpb_outlier?  new_outlier_flags_v1  new_outlier_flags_v2\n",
       "False            False                 False                   88\n",
       "True             True                  True                     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirming that im getting the same result with either method\n",
    "merged_data[[\"is_cpb_outlier?\",\t\"new_outlier_flags_v1\",\t\"new_outlier_flags_v2\"]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56380e1-181a-403e-8ca9-9798212e589f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
