{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aa74ab9-57b7-44cf-ab84-4f6514fc0397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/geopandas/_compat.py:111: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "E0330 18:27:56.275328933    2108 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0330 18:27:59.095647821    2108 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CALITP_BQ_MAX_BYTES\"] = str(800_000_000_000)\n",
    "\n",
    "from calitp.tables import tbl\n",
    "from calitp import query_sql\n",
    "import calitp.magics\n",
    "import branca\n",
    "\n",
    "import shared_utils\n",
    "import utils\n",
    "\n",
    "from siuba import *\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "\n",
    "import datetime as dt\n",
    "import time\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "import rt_analysis as rt\n",
    "import importlib\n",
    "\n",
    "import gcsfs\n",
    "fs = gcsfs.GCSFileSystem()\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c20d02bc-3636-4306-ad4c-a99d62011d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'rt_analysis' from '/home/jovyan/data-analyses/rt_delay/rt_analysis.py'>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(utils)\n",
    "importlib.reload(rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3a5bcb4a-6020-4943-840a-584548362563",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_joined = pd.read_parquet('airtable_joined.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2f69aea6-3c0b-405c-95a7-2f85b18adaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ran_operators = [int(filename.split('_')[0]) for filename in os.listdir('speedmaps') if filename[0] != '.']\n",
    "ran_operators = [300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cbadc13a-3f4e-41f2-95e1-999f5d3bb348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebdc518ce48f477e829fe13680094221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pbar = tqdm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea919ed7-d467-4858-82ec-bc11917f0bcc",
   "metadata": {},
   "source": [
    "### debug AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9cbc1186-df21-4cef-ba93-dbc83b669c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "itp_id = 273\n",
    "analysis_date = dt.date(2022, 3, 23) ##wednesday, new tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f8d95d37-7749-4718-8d9f-6883cf6299aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found parquet\n",
      "found parquet\n",
      "cached parquet empty, will try a fresh query\n",
      "found parquet\n",
      "cached parquet empty, will try a fresh query\n",
      "found parquet\n",
      "cached parquet empty, will try a fresh query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/data-analyses/_shared_utils/shared_utils/utils.py:38: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "vehicle positions trip ids not in schedule",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [78]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rt_day \u001b[38;5;241m=\u001b[39m \u001b[43mrt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOperatorDayAnalysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitp_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manalysis_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data-analyses/rt_delay/rt_analysis.py:265\u001b[0m, in \u001b[0;36mOperatorDayAnalysis.__init__\u001b[0;34m(self, itp_id, analysis_date, pbar)\u001b[0m\n\u001b[1;32m    261\u001b[0m positions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvehicle_positions \u001b[38;5;241m>>\u001b[39m select(\u001b[38;5;241m-\u001b[39m_\u001b[38;5;241m.\u001b[39mcalitp_url_number)\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrips_positions_joined \u001b[38;5;241m=\u001b[39m (trips\n\u001b[1;32m    263\u001b[0m                                 \u001b[38;5;241m>>\u001b[39m inner_join(_, positions, on\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrip_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcalitp_itp_id\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    264\u001b[0m                                ) \u001b[38;5;66;03m##TODO check info cols here...\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrips_positions_joined\u001b[38;5;241m.\u001b[39mempty, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvehicle positions trip ids not in schedule\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrips_positions_joined \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoDataFrame(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrips_positions_joined,\n\u001b[1;32m    267\u001b[0m                             geometry\u001b[38;5;241m=\u001b[39mgpd\u001b[38;5;241m.\u001b[39mpoints_from_xy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrips_positions_joined\u001b[38;5;241m.\u001b[39mvehicle_longitude,\n\u001b[1;32m    268\u001b[0m                                                         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrips_positions_joined\u001b[38;5;241m.\u001b[39mvehicle_latitude),\n\u001b[1;32m    269\u001b[0m                             crs\u001b[38;5;241m=\u001b[39mWGS84)\u001b[38;5;241m.\u001b[39mto_crs(CA_NAD83Albers)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroutelines \u001b[38;5;241m=\u001b[39m get_routelines(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalitp_itp_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manalysis_date)\n",
      "\u001b[0;31mAssertionError\u001b[0m: vehicle positions trip ids not in schedule"
     ]
    }
   ],
   "source": [
    "rt_day = rt.OperatorDayAnalysis(itp_id, analysis_date, pbar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c27596fa-e193-4959-8cfb-b8c6402443ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calitp_itp_id</th>\n",
       "      <th>calitp_url_number</th>\n",
       "      <th>header_timestamp</th>\n",
       "      <th>vehicle_timestamp</th>\n",
       "      <th>entity_id</th>\n",
       "      <th>vehicle_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>vehicle_longitude</th>\n",
       "      <th>vehicle_latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>273</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-03-23 20:30:03</td>\n",
       "      <td>2022-03-23 20:29:54</td>\n",
       "      <td>None</td>\n",
       "      <td>1581</td>\n",
       "      <td>1135040</td>\n",
       "      <td>-121.373085</td>\n",
       "      <td>38.554043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>273</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-03-23 20:30:03</td>\n",
       "      <td>2022-03-23 20:29:45</td>\n",
       "      <td>None</td>\n",
       "      <td>1580</td>\n",
       "      <td>218040</td>\n",
       "      <td>-121.427100</td>\n",
       "      <td>38.552593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>273</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-03-23 20:30:03</td>\n",
       "      <td>2022-03-23 20:29:55</td>\n",
       "      <td>None</td>\n",
       "      <td>2821</td>\n",
       "      <td>None</td>\n",
       "      <td>-121.382866</td>\n",
       "      <td>38.603497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>273</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-03-23 20:30:03</td>\n",
       "      <td>2022-03-23 20:29:36</td>\n",
       "      <td>None</td>\n",
       "      <td>1578</td>\n",
       "      <td>None</td>\n",
       "      <td>-121.382740</td>\n",
       "      <td>38.606770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>273</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-03-23 20:30:03</td>\n",
       "      <td>2022-03-23 20:29:56</td>\n",
       "      <td>None</td>\n",
       "      <td>1576</td>\n",
       "      <td>1800040</td>\n",
       "      <td>-121.280960</td>\n",
       "      <td>38.678210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230039</th>\n",
       "      <td>273</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-03-23 15:08:29</td>\n",
       "      <td>2022-03-23 15:08:12</td>\n",
       "      <td>None</td>\n",
       "      <td>2817</td>\n",
       "      <td>1036040</td>\n",
       "      <td>-121.267160</td>\n",
       "      <td>38.679726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230040</th>\n",
       "      <td>273</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-03-23 15:08:29</td>\n",
       "      <td>2022-03-23 15:08:25</td>\n",
       "      <td>None</td>\n",
       "      <td>2816</td>\n",
       "      <td>None</td>\n",
       "      <td>-121.469930</td>\n",
       "      <td>38.567432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230041</th>\n",
       "      <td>273</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-03-23 15:08:29</td>\n",
       "      <td>2022-03-23 15:08:08</td>\n",
       "      <td>None</td>\n",
       "      <td>2815</td>\n",
       "      <td>1825040</td>\n",
       "      <td>-121.306206</td>\n",
       "      <td>38.576920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230042</th>\n",
       "      <td>273</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-03-23 15:08:29</td>\n",
       "      <td>2022-03-23 15:08:08</td>\n",
       "      <td>None</td>\n",
       "      <td>1603</td>\n",
       "      <td>None</td>\n",
       "      <td>-121.383750</td>\n",
       "      <td>38.595890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230043</th>\n",
       "      <td>273</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-03-23 15:08:29</td>\n",
       "      <td>2022-03-23 15:08:16</td>\n",
       "      <td>None</td>\n",
       "      <td>2813</td>\n",
       "      <td>1009040</td>\n",
       "      <td>-121.343124</td>\n",
       "      <td>38.688343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230044 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        calitp_itp_id  calitp_url_number    header_timestamp  \\\n",
       "0                 273                  0 2022-03-23 20:30:03   \n",
       "1                 273                  0 2022-03-23 20:30:03   \n",
       "2                 273                  0 2022-03-23 20:30:03   \n",
       "3                 273                  0 2022-03-23 20:30:03   \n",
       "4                 273                  0 2022-03-23 20:30:03   \n",
       "...               ...                ...                 ...   \n",
       "230039            273                  0 2022-03-23 15:08:29   \n",
       "230040            273                  0 2022-03-23 15:08:29   \n",
       "230041            273                  0 2022-03-23 15:08:29   \n",
       "230042            273                  0 2022-03-23 15:08:29   \n",
       "230043            273                  0 2022-03-23 15:08:29   \n",
       "\n",
       "         vehicle_timestamp entity_id vehicle_id  trip_id  vehicle_longitude  \\\n",
       "0      2022-03-23 20:29:54      None       1581  1135040        -121.373085   \n",
       "1      2022-03-23 20:29:45      None       1580   218040        -121.427100   \n",
       "2      2022-03-23 20:29:55      None       2821     None        -121.382866   \n",
       "3      2022-03-23 20:29:36      None       1578     None        -121.382740   \n",
       "4      2022-03-23 20:29:56      None       1576  1800040        -121.280960   \n",
       "...                    ...       ...        ...      ...                ...   \n",
       "230039 2022-03-23 15:08:12      None       2817  1036040        -121.267160   \n",
       "230040 2022-03-23 15:08:25      None       2816     None        -121.469930   \n",
       "230041 2022-03-23 15:08:08      None       2815  1825040        -121.306206   \n",
       "230042 2022-03-23 15:08:08      None       1603     None        -121.383750   \n",
       "230043 2022-03-23 15:08:16      None       2813  1009040        -121.343124   \n",
       "\n",
       "        vehicle_latitude  \n",
       "0              38.554043  \n",
       "1              38.552593  \n",
       "2              38.603497  \n",
       "3              38.606770  \n",
       "4              38.678210  \n",
       "...                  ...  \n",
       "230039         38.679726  \n",
       "230040         38.567432  \n",
       "230041         38.576920  \n",
       "230042         38.595890  \n",
       "230043         38.688343  \n",
       "\n",
       "[230044 rows x 9 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.get_vehicle_positions(273, analysis_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "28e8118a-5217-4ea0-8c99-33ecce01e011",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_date = dt.date(2022, 3, 23) ##wednesday, new tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7f22c38c-1066-4090-880b-34767a678cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found parquet\n",
      "cached parquet empty, will try a fresh query\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calitp_itp_id</th>\n",
       "      <th>calitp_url_number</th>\n",
       "      <th>service_date</th>\n",
       "      <th>trip_key</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>direction_id</th>\n",
       "      <th>shape_id</th>\n",
       "      <th>calitp_extracted_at</th>\n",
       "      <th>calitp_deleted_at</th>\n",
       "      <th>route_id</th>\n",
       "      <th>route_short_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [calitp_itp_id, calitp_url_number, service_date, trip_key, trip_id, direction_id, shape_id, calitp_extracted_at, calitp_deleted_at, route_id, route_short_name]\n",
       "Index: []"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.get_trips(273, analysis_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a65424cf-5733-4b35-a249-2c5bc219ed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = (tbl.views.gtfs_schedule_fact_daily_trips()\n",
    "# >> filter(_.calitp_extracted_at <= analysis_date, _.calitp_deleted_at >= analysis_date)\n",
    ">> filter(_.calitp_itp_id == itp_id)\n",
    ">> filter(_.service_date == analysis_date)\n",
    ">> filter(_.is_in_service == True)\n",
    ">> select(_.trip_key, _.service_date)\n",
    ">> inner_join(_, tbl.views.gtfs_schedule_dim_trips(), on = 'trip_key')\n",
    ">> select(_.calitp_itp_id, _.calitp_url_number, _.service_date,\n",
    "          _.trip_key, _.trip_id, _.route_id, _.direction_id,\n",
    "          _.shape_id, _.calitp_extracted_at, _.calitp_deleted_at)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "47a5dc03-8f88-4b7f-aab3-f1a1a076ce74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2022, 3, 23)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8a54cd2f-58c3-4912-97af-d2b2a7aa1ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service_date</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>2560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>2560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-02-24</td>\n",
       "      <td>2560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>2560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-03-02</td>\n",
       "      <td>2560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-02-26</td>\n",
       "      <td>1452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-02-27</td>\n",
       "      <td>1158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  service_date     n\n",
       "0   2022-02-28  2560\n",
       "1   2022-03-01  2560\n",
       "2   2022-02-24  2560\n",
       "3   2022-02-25  2560\n",
       "4   2022-03-02  2560\n",
       "5   2022-02-26  1452\n",
       "6   2022-02-27  1158"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips = (tbl.views.gtfs_schedule_fact_daily_trips()\n",
    "    >> filter(_.calitp_itp_id == itp_id)\n",
    "    >> filter(_.service_date > '2022-02-23', _.service_date < '2022-03-31')\n",
    "    >> filter(_.is_in_service == True)\n",
    "    >> count(_.service_date)\n",
    "    >> collect()\n",
    "        )\n",
    "\n",
    "trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f29543-d30b-4d9f-87d2-c5f69a683f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trips(itp_id, analysis_date, force_clear=False):\n",
    "    ''' \n",
    "    itp_id: an itp_id (string or integer)\n",
    "    analysis_date: datetime.date\n",
    "    \n",
    "    Interim function for getting complete trips data for a single operator on a single date of interest.\n",
    "    To be replaced as RT views are implemented...\n",
    "    \n",
    "    Updated to include route_short_name from routes\n",
    "    '''\n",
    "    \n",
    "    date_str = analysis_date.strftime('%Y-%m-%d')\n",
    "    filename = f'trips_{itp_id}_{date_str}.parquet'\n",
    "    path = check_cached(filename)\n",
    "    if path and not force_clear:\n",
    "        print('found parquet')\n",
    "        cached = pd.read_parquet(path)\n",
    "        if not cached.empty:\n",
    "            return cached\n",
    "        else:\n",
    "            print('cached parquet empty, will try a fresh query')\n",
    "    trips = (tbl.views.gtfs_schedule_fact_daily_trips()\n",
    "        >> filter(_.calitp_extracted_at <= analysis_date, _.calitp_deleted_at >= analysis_date)\n",
    "        >> filter(_.calitp_itp_id == itp_id)\n",
    "        >> filter(_.service_date == analysis_date)\n",
    "        >> filter(_.is_in_service == True)\n",
    "        >> select(_.trip_key, _.service_date)\n",
    "        >> inner_join(_, tbl.views.gtfs_schedule_dim_trips(), on = 'trip_key')\n",
    "        >> select(_.calitp_itp_id, _.calitp_url_number, _.service_date,\n",
    "                  _.trip_key, _.trip_id, _.route_id, _.direction_id,\n",
    "                  _.shape_id, _.calitp_extracted_at, _.calitp_deleted_at)\n",
    "        >> collect()\n",
    "        >> distinct(_.trip_id, _keep_all=True)\n",
    "        >> inner_join(_, get_routes(itp_id, analysis_date), on = 'route_id')\n",
    "            )\n",
    "    if not path or force_clear:\n",
    "        trips.to_parquet(f'{GCS_FILE_PATH}cached_views/{filename}')\n",
    "    return trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e75009b5-6dd9-4714-80da-c393825625f7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "view filter: {'start_time': datetime.time(15, 0), 'end_time': datetime.time(19, 0), 'route_names': None, 'shape_ids': None, 'direction_id': None, 'direction': None}\n",
      "60_shp_0_ empty!\n",
      "195_shp_0_ empty!\n",
      "46_shp_0_ empty!\n",
      "231_shp_0_ empty!\n",
      "36_shp_0_ empty!\n",
      "88_shp_1_ empty!\n",
      "26_shp_0_ empty!\n",
      "89_shp_0_ empty!\n",
      "58_shp_1_ empty!\n",
      "33_shp_1_ empty!\n",
      "negative speed for shape 210_shp, dropping\n",
      "210_shp_0_ empty!\n",
      "negative speed for shape 186_shp, dropping\n",
      "186_shp_0_ empty!\n",
      "185_shp_1_ empty!\n",
      "198_shp_1_ empty!\n",
      "speed above 80 for shape 199_shp, dropping\n",
      "199_shp_0_ empty!\n",
      "194_shp_1_ empty!\n",
      "20_shp_0_ empty!\n",
      "19_shp_0_ empty!\n",
      "209_shp_1_ empty!\n",
      "213_shp_1_ empty!\n",
      "43_shp_1_ empty!\n",
      "227_shp_1_ empty!\n",
      "negative speed for shape 227_shp, dropping\n",
      "232_shp_1_ empty!\n",
      "17_shp_1_ empty!\n",
      "speed above 80 for shape 17_shp, dropping\n",
      "50_shp_1_ empty!\n",
      "25_shp_1_ empty!\n",
      "48_shp_0_ empty!\n",
      "233_shp_0_ empty!\n",
      "234_shp_0_ empty!\n",
      "stop_speeds shape: (0, 18), shape_id: 37_shp, direction_id: 1\n",
      "stop speeds gdf is empty!\n",
      "37_shp_0_ empty!\n",
      "38_shp_1_ empty!\n",
      "169_shp_1_ empty!\n",
      "speed above 80 for shape 170_shp, dropping\n",
      "170_shp_0_ empty!\n",
      "41_shp_1_ empty!\n",
      "40_shp_0_ empty!\n",
      "135_shp_1_ empty!\n",
      "225_shp_1_ empty!\n",
      "226_shp_0_ empty!\n",
      "stop_speeds shape: (0, 18), shape_id: 130_shp, direction_id: 1\n",
      "stop speeds gdf is empty!\n",
      "130_shp_0_ empty!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/shapely/ops.py:634: ShapelyDeprecationWarning: GeometryTypeError will derive from ShapelyError and not TypeError or ValueError in Shapely 2.0.\n",
      "/home/jovyan/data-analyses/rt_delay/rt_analysis.py:604: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rt_day.set_filter(start_time='15:00', end_time='19:00')\n",
    "m = rt_day.segment_speed_map(how='low_speeds', size = [1300, 700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0e326210-0de8-45de-84b3-4d8963209986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3b629a-5c50-476b-b7e2-58d07e6163d8",
   "metadata": {},
   "source": [
    "#### Run all operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1b61314c-082f-4008-8821-404faa01443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_list = fs.ls(f'{utils.GCS_FILE_PATH}rt_trips/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "71803f31-26b2-486d-ba0e-3dd335b70f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "ran_operators = [int(path.split('rt_trips/')[1].split('_')[0])\n",
    "                 for path in fs_list\n",
    "                 if path.split('rt_trips/')[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9f55f46f-e297-4a57-ba18-86f855bc3a7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating for agency: 380...\n",
      "found parquet\n",
      "found parquet\n",
      "found parquet\n",
      "found parquet\n",
      "rt failed for agency 380\n",
      "vehicle positions trip ids not in schedule\n",
      "already ran: 300\n",
      "already ran: 182\n",
      "already ran: 243\n",
      "already ran: 295\n",
      "already ran: 170\n",
      "already ran: 45\n",
      "already ran: 75\n",
      "already ran: 4\n",
      "already ran: 310\n",
      "calculating for agency: 314...\n",
      "rt failed for agency 314\n",
      "no vehicle positions data found for 2022-03-23\n",
      "already ran: 247\n",
      "already ran: 315\n",
      "already ran: 301\n",
      "already ran: 290\n",
      "already ran: 167\n",
      "already ran: 294\n",
      "already ran: 336\n",
      "already ran: 194\n",
      "already ran: 246\n",
      "already ran: 218\n",
      "already ran: 282\n",
      "already ran: 350\n",
      "already ran: 127\n",
      "already ran: 110\n",
      "calculating for agency: 203...\n",
      "found parquet\n",
      "found parquet\n",
      "found parquet\n",
      "found parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/pybigquery/sqlalchemy_bigquery.py:879: SAWarning: Did not recognize type 'GEOGRAPHY' of column 'pt_array'\n",
      "/home/jovyan/data-analyses/_shared_utils/shared_utils/utils.py:38: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 scheduled trips out of 1411 have no shape, dropping\n",
      "could not generate delays for trip t17D-sl2-p26-r99\n",
      "Columns must be same length as key\n",
      "could not generate delays for trip t185-sl2-p26-r99\n",
      "Columns must be same length as key\n",
      "could not generate delays for trip t184-sl2-p26-r98\n",
      "Columns must be same length as key\n",
      "could not generate delays for trip t17C-sl2-p26-r98\n",
      "Columns must be same length as key\n",
      "could not generate delays for trip t4EB-sl2-p85-r9C\n",
      "Columns must be same length as key\n",
      "could not generate delays for trip t4EF-sl2-p85-r9C\n",
      "Columns must be same length as key\n",
      "could not generate delays for trip t4ED-sl2-p85-r9C\n",
      "Columns must be same length as key\n",
      "could not generate delays for trip t4EC-sl2-p84-r9C\n",
      "Columns must be same length as key\n",
      "could not generate delays for trip t4EE-sl2-p84-r9C\n",
      "Columns must be same length as key\n",
      "could not generate delays for trip t504-sl2-p89-r9E\n",
      "Columns must be same length as key\n",
      "could not generate delays for trip t791-sl2-p89-r9E\n",
      "Columns must be same length as key\n",
      "could not generate delays for trip t4F2-sl2-p89-r9D\n",
      "Columns must be same length as key\n",
      "could not generate delays for trip t503-sl2-p89-r9E\n",
      "Columns must be same length as key\n",
      "could not generate delays for trip t4F1-sl2-p88-r9E\n",
      "Columns must be same length as key\n",
      "could not generate delays for trip t792-sl2-pD3-r9E\n",
      "Columns must be same length as key\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/data-analyses/_shared_utils/shared_utils/utils.py:38: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "view filter: {'start_time': datetime.time(15, 0), 'end_time': datetime.time(19, 0), 'route_names': None, 'shape_ids': None, 'direction_id': None, 'direction': None}\n",
      "60_shp_0_ empty!\n",
      "195_shp_0_ empty!\n",
      "46_shp_0_ empty!\n",
      "231_shp_0_ empty!\n",
      "36_shp_0_ empty!\n",
      "88_shp_1_ empty!\n",
      "26_shp_0_ empty!\n",
      "89_shp_0_ empty!\n",
      "58_shp_1_ empty!\n",
      "33_shp_1_ empty!\n",
      "negative speed for shape 210_shp, dropping\n",
      "210_shp_0_ empty!\n",
      "negative speed for shape 186_shp, dropping\n",
      "186_shp_0_ empty!\n",
      "185_shp_1_ empty!\n",
      "198_shp_1_ empty!\n",
      "speed above 80 for shape 199_shp, dropping\n",
      "199_shp_0_ empty!\n",
      "194_shp_1_ empty!\n",
      "20_shp_0_ empty!\n",
      "19_shp_0_ empty!\n",
      "209_shp_1_ empty!\n",
      "213_shp_1_ empty!\n",
      "43_shp_1_ empty!\n",
      "227_shp_1_ empty!\n",
      "negative speed for shape 227_shp, dropping\n",
      "232_shp_1_ empty!\n",
      "17_shp_1_ empty!\n",
      "speed above 80 for shape 17_shp, dropping\n",
      "50_shp_1_ empty!\n",
      "25_shp_1_ empty!\n",
      "48_shp_0_ empty!\n",
      "233_shp_0_ empty!\n",
      "234_shp_0_ empty!\n",
      "stop_speeds shape: (0, 18), shape_id: 37_shp, direction_id: 1\n",
      "stop speeds gdf is empty!\n",
      "37_shp_0_ empty!\n",
      "38_shp_1_ empty!\n",
      "169_shp_1_ empty!\n",
      "speed above 80 for shape 170_shp, dropping\n",
      "170_shp_0_ empty!\n",
      "41_shp_1_ empty!\n",
      "40_shp_0_ empty!\n",
      "135_shp_1_ empty!\n",
      "225_shp_1_ empty!\n",
      "226_shp_0_ empty!\n",
      "stop_speeds shape: (0, 18), shape_id: 130_shp, direction_id: 1\n",
      "stop speeds gdf is empty!\n",
      "130_shp_0_ empty!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/shapely/ops.py:634: ShapelyDeprecationWarning: GeometryTypeError will derive from ShapelyError and not TypeError or ValueError in Shapely 2.0.\n",
      "/home/jovyan/data-analyses/rt_delay/rt_analysis.py:604: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "/home/jovyan/data-analyses/_shared_utils/shared_utils/utils.py:38: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
      "/home/jovyan/data-analyses/_shared_utils/shared_utils/utils.py:38: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete for agency: 203\n",
      "calculating for agency: 343...\n",
      "found parquet\n",
      "found parquet\n",
      "found parquet\n",
      "found parquet\n",
      "rt failed for agency 343\n",
      "vehicle positions trip ids not in schedule\n",
      "already ran: 284\n",
      "already ran: 349\n",
      "calculating for agency: 273...\n",
      "found parquet\n",
      "found parquet\n",
      "cached parquet empty, will try a fresh query\n",
      "found parquet\n",
      "cached parquet empty, will try a fresh query\n",
      "found parquet\n",
      "cached parquet empty, will try a fresh query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/data-analyses/_shared_utils/shared_utils/utils.py:38: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rt failed for agency 273\n",
      "vehicle positions trip ids not in schedule\n",
      "already ran: 221\n",
      "calculating for agency: 372...\n",
      "found parquet\n",
      "found parquet\n",
      "found parquet\n",
      "found parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/pybigquery/sqlalchemy_bigquery.py:879: SAWarning: Did not recognize type 'GEOGRAPHY' of column 'pt_array'\n",
      "/home/jovyan/data-analyses/_shared_utils/shared_utils/utils.py:38: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rt failed for agency 372\n",
      "routelines must not be empty\n",
      "already ran: 235\n",
      "calculating for agency: 360...\n",
      "found parquet\n",
      "found parquet\n",
      "found parquet\n",
      "found parquet\n",
      "rt failed for agency 360\n",
      "vehicle positions trip ids not in schedule\n",
      "already ran: 269\n",
      "already ran: 30\n",
      "calculating for agency: 159...\n",
      "found parquet\n",
      "found parquet\n",
      "found parquet\n",
      "found parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/pybigquery/sqlalchemy_bigquery.py:879: SAWarning: Did not recognize type 'GEOGRAPHY' of column 'pt_array'\n",
      "/home/jovyan/data-analyses/_shared_utils/shared_utils/utils.py:38: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not generate delays for trip t_1057260_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1057289_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1439234_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1057374_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1057367_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1057372_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1547393_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1057376_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1057373_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1547394_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1438282_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1057354_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1057353_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1057361_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1057357_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1057297_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1057352_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1547391_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1057359_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1438243_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1057342_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1438240_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1438241_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1437746_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1057318_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1057316_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1057371_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1057322_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1057379_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1057323_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1057309_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1439235_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1547207_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1547204_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1057273_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1057272_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1057277_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1057308_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1439236_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1547209_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1439286_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1439289_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1439288_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1439294_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1439291_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1439292_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1439296_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1439298_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1439304_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1439305_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1547387_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1057279_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1057319_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1057296_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1547367_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n",
      "could not generate delays for trip t_1057269_b_25985_tn_0\n",
      "'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/data-analyses/_shared_utils/shared_utils/utils.py:38: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "view filter: {'start_time': datetime.time(15, 0), 'end_time': datetime.time(19, 0), 'route_names': None, 'shape_ids': None, 'direction_id': None, 'direction': None}\n",
      "rt failed for agency 159\n",
      "'GeoDataFrame' object has no attribute 'trip_id'\n",
      "already ran: 135\n",
      "already ran: 293\n",
      "already ran: 208\n",
      "already ran: 126\n",
      "already ran: 361\n",
      "already ran: 188\n",
      "already ran: 148\n",
      "calculating for agency: 346...\n",
      "rt failed for agency 346\n",
      "no vehicle positions data found for 2022-03-23\n",
      "already ran: 226\n",
      "already ran: 278\n",
      "already ran: 259\n"
     ]
    }
   ],
   "source": [
    "for agency in air_joined.calitp_itp_id.unique():\n",
    "# for agency in [300]:\n",
    "    not_ran_operators = []\n",
    "    if agency in ran_operators:\n",
    "        print(f'already ran: {agency}')\n",
    "        continue\n",
    "    analysis_date = dt.date(2022, 3, 23) ##wednesday, new tables\n",
    "    day = str(analysis_date.day).zfill(2)\n",
    "    month = str(analysis_date.month).zfill(2)\n",
    "    print(f'calculating for agency: {agency}...')\n",
    "    try:\n",
    "        rt_day = rt.OperatorDayAnalysis(agency, analysis_date, pbar)\n",
    "        delay_to_parquet = rt_day.stop_delay_view.copy()\n",
    "        delay_to_parquet['delay_seconds'] = delay_to_parquet.delay.map(lambda x: x.seconds)\n",
    "        delay_to_parquet['arrival_time'] = delay_to_parquet.arrival_time.map(lambda x: x.isoformat())\n",
    "        delay_to_parquet['actual_time'] = delay_to_parquet.actual_time.map(lambda x: x.isoformat())\n",
    "        delay_to_parquet = delay_to_parquet >> select(-_.delay)\n",
    "        shared_utils.utils.geoparquet_gcs_export(delay_to_parquet,\n",
    "                                         f'{utils.GCS_FILE_PATH}stop_delay_views/',\n",
    "                                        f'{agency}_{month}_{day}'\n",
    "                                        )\n",
    "        rt_day.set_filter(start_time='15:00', end_time='19:00')\n",
    "        m = rt_day.segment_speed_map(how='low_speeds', size = [1300, 700])\n",
    "        shared_utils.utils.geoparquet_gcs_export(rt_day.stop_segment_speed_view,\n",
    "                                                 f'{utils.GCS_FILE_PATH}segment_speed_views/',\n",
    "                                                f'{agency}_{month}_{day}_pm_peak'\n",
    "                                                )\n",
    "        rt_day.rt_trips.to_parquet(f'{utils.GCS_FILE_PATH}rt_trips/{agency}_{month}_{day}_pm_peak.parquet') ## early step towards scaling\n",
    "        # m.save(f'./speedmaps/{agency}_02_{day}_pm_peak.html')\n",
    "        # rt_day.stop_segment_speed_view.to_parquet(f'{utils.GCS_FILE_PATH}segment_speed_views/{agency}_02_{day}_pm_peak.parquet') ## early step towards scaling\n",
    "        delay_to_parquet = rt_day.endpoint_delay_view.copy()\n",
    "        delay_to_parquet['delay_seconds'] = delay_to_parquet.delay.map(lambda x: x.seconds)\n",
    "        delay_to_parquet = delay_to_parquet >> select(-_.delay)\n",
    "        shared_utils.utils.geoparquet_gcs_export(delay_to_parquet,\n",
    "                                         f'{utils.GCS_FILE_PATH}endpoint_delay_views/',\n",
    "                                        f'{agency}_{month}_{day}_pm_peak'\n",
    "                                        )\n",
    "        print(f'complete for agency: {agency}')\n",
    "    except Exception as e:\n",
    "        print(f'rt failed for agency {agency}')\n",
    "        not_ran_operators += [agency]\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06af4bc3-016b-4f01-953e-805dc760c771",
   "metadata": {},
   "source": [
    "### Ongoing issues\n",
    "* 358 Union City too many trips without shape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aad356-eb75-43c0-8cd9-9f81b1748aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# air_joined['url'] = air_joined.apply(lambda x:\n",
    "#                     f'http://docs.calitp.org/data-analyses/rt_delay/speedmaps/{x.calitp_itp_id}_02_08_pm_peak.html',\n",
    "#                                     axis = 1)\n",
    "\n",
    "# air_joined.to_csv('linked.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
