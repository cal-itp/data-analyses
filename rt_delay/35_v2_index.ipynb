{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6f20444-5625-4598-95ea-18bc6cea0ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_2478/1968763944.py:7: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CALITP_BQ_MAX_BYTES\"] = str(1_000_000_000_000) ## 1TB?\n",
    "import sys\n",
    "\n",
    "from siuba import *\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import gcsfs\n",
    "import datetime as dt\n",
    "import time\n",
    "import shapely\n",
    "\n",
    "from rt_analysis import rt_parser\n",
    "from rt_analysis import rt_filter_map_plot\n",
    "\n",
    "import shared_utils\n",
    "from calitp_data_analysis.tables import tbls\n",
    "\n",
    "import pyaml\n",
    "import yaml\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea156f26-fc47-44a8-bebc-ff9b87cdb880",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'analysis_date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mshared_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrt_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_intermediate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data-analyses/_shared_utils/shared_utils/rt_utils.py:465\u001b[0m, in \u001b[0;36mcheck_intermediate_data\u001b[0;34m(speedmaps_index_df)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_intermediate_data\u001b[39m(speedmaps_index_df: pd\u001b[38;5;241m.\u001b[39mDataFrame \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m    457\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m    458\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;124;03m    speedmaps_index_df: pd.DataFrame of all agencies to try generating a speedmap\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;124;03m        from rt_delay/build_speedmaps_index.py\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;124;03m    return that to script, otherwise check intermediate data from GCS\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 465\u001b[0m     analysis_date \u001b[38;5;241m=\u001b[39m \u001b[43mspeedmaps_index_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalysis_date\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    466\u001b[0m     progress_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./_rt_progress_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00manalysis_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    467\u001b[0m     already_tried \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(progress_path)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5896\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5897\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5898\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5899\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5900\u001b[0m ):\n\u001b[1;32m   5901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 5902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'analysis_date'"
     ]
    }
   ],
   "source": [
    "shared_utils.rt_utils.check_intermediate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4e2765-eea8-400b-bd71-6f372c8ce1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date for v2 testing\n",
    "analysis_date = dt.date(2023, 3, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10df437b-cace-42ba-9c8b-49bfe513e32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tbls.mart_transit_database.dim_provider_gtfs_data() >> head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71257720-4bca-45d6-992c-05e134c93db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_speedmap_index(analysis_date: dt.date):\n",
    "    '''\n",
    "    An index table for tracking down a given org's schedule/rt feeds\n",
    "    returns LazyTbl\n",
    "    '''\n",
    "    analysis_dt = dt.datetime.combine(analysis_date, dt.time(0, 0))\n",
    "    \n",
    "    dim_orgs = (tbls.mart_transit_database.dim_organizations()\n",
    "                >> filter(_._valid_from <= analysis_dt, _._valid_to > analysis_dt)\n",
    "                >> select(_.source_record_id, _.caltrans_district)\n",
    "               )\n",
    "    \n",
    "    orgs_with_vp = (tbls.mart_transit_database.dim_provider_gtfs_data()\n",
    "    >> filter(_._valid_from <= analysis_dt, _._valid_to > analysis_dt,\n",
    "              _.reports_site_assessed, _.vehicle_positions_gtfs_dataset_key != None)\n",
    "    >> inner_join(_, dim_orgs, on = {'organization_source_record_id': 'source_record_id'})\n",
    "    >> select(_.organization_itp_id, _.organization_name, _.organization_source_record_id,\n",
    "             _.caltrans_district, _._is_current, _.vehicle_positions_gtfs_dataset_key)\n",
    "    >> collect()\n",
    "    )\n",
    "    assert not orgs_with_vp.isnull().values.any()\n",
    "    orgs_with_vp['analysis_date'] = analysis_date\n",
    "    orgs_with_vp = orgs_with_vp >> distinct(_.organization_name,\n",
    "                    _.organization_itp_id, _.organization_source_record_id,\n",
    "                    _.caltrans_district, _._is_current, _.analysis_date\n",
    "                    # ,_.vehicle_positions_gtfs_dataset_key\n",
    "                                           )\n",
    "    return orgs_with_vp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35802601-3670-43e1-9c13-89b48b985f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "speedmap_index = build_speedmap_index(analysis_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfe2c4c7-9a33-424d-936d-6036dd00d18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(speedmap_index.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae71d1ea-8166-49b7-ace9-48fbf94b15eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 >> filter(_.organization_itp_id.isin([315, 246]))\n",
    "# # rail operators..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fae134-6437-4035-b548-ba6cf99f24fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "speedmap_index >> filter(_.organization_itp_id == 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9b3df0-21fd-4c6f-ae8e-2ca074a9abbc",
   "metadata": {},
   "source": [
    "## Check/Run rt_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7491bd5-8ffa-4535-aa7a-980a8aee78a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vp_count = speedmap_index >> count(_.vehicle_positions_gtfs_dataset_key)\n",
    "\n",
    "# multiples = speedmap_index >> inner_join(_, vp_count, on = 'vehicle_positions_gtfs_dataset_key') >> arrange(-_.n)\n",
    "\n",
    "# shared_utils.rt_utils.show_full_df(multiples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "057ce25e-7e4d-4861-8b5f-ae42d763e406",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_intermediate_data\u001b[39m(speedmap_index_df: \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    For speedmap generation scripts in rt_delay.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    Check if intermediate file exists (process partially complete) and \u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m    return that to script, otherwise check intermediate data from GCS\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     analysis_date \u001b[38;5;241m=\u001b[39m speedmap_index_df\u001b[38;5;241m.\u001b[39manalysis_date\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "def check_intermediate_data(speedmap_index_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    For speedmap generation scripts in rt_delay.\n",
    "    Check if intermediate file exists (process partially complete) and \n",
    "    return that to script, otherwise check intermediate data from GCS\n",
    "    '''\n",
    "    analysis_date = speedmap_index_df.analysis_date.iloc[0]\n",
    "    progress_path = f'./_rt_progress_{analysis_date}.parquet'\n",
    "    already_tried = os.path.exists(progress_path)\n",
    "    if already_tried:\n",
    "        print(f'found {progress_path}, resuming')\n",
    "        speedmap_index_joined = pd.read_parquet(progress_path)\n",
    "    else:\n",
    "        operators_ran = shared_utils.rt_utils.get_operators(analysis_date,\n",
    "                            speedmap_index_df.organization_itp_id.to_list())\n",
    "        operators_ran_df = pd.DataFrame.from_dict(\n",
    "                    operators_ran, orient='index', columns = ['status'])\n",
    "        operators_ran_df.index.name = 'itp_id'\n",
    "        speedmap_index_joined = speedmap_index >> inner_join(_,\n",
    "                                                         operators_ran_df, on={'organization_itp_id': 'itp_id'})\n",
    "    return speedmap_index_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae27032-95dc-4734-acc8-5d9161a53119",
   "metadata": {},
   "outputs": [],
   "source": [
    "speedmap_index_joined = check_intermediate_data(speedmap_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a19cd7e-e2e7-4131-b5e2-b5250edd2e1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shared_utils.rt_utils.show_full_df(speedmap_index_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1ac6d4-da1b-4ebb-8e06-20504e737a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "speedmap_index_joined >> count(_.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7da22d-79ea-4422-a2ed-3d0b6a34949d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage_intermediate_data(row, pbar):\n",
    "    \n",
    "    global speedmap_index_joined\n",
    "    analysis_date = row.analysis_date\n",
    "    progress_path = f'./_rt_progress_{analysis_date}.parquet'\n",
    "        \n",
    "    if row.status != 'already_ran':\n",
    "        try:\n",
    "            rt_day = rt_parser.OperatorDayAnalysis(row.organization_itp_id,\n",
    "                                                   analysis_date, pbar)\n",
    "            rt_day.export_views_gcs()\n",
    "            row.status = 'already_ran'\n",
    "        except Exception as e:\n",
    "            print(f'{row.organization_itp_id} parser failed: {e}')\n",
    "            row.status = 'parser_failed'\n",
    "        print(row.name)\n",
    "        speedmap_index_joined.loc[row.name] = row\n",
    "        speedmap_index_joined.to_parquet(progress_path)\n",
    "    \n",
    "    return  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bc60db-58b3-41cb-8053-66cf41742e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b760e67-7c63-448b-bea7-2319755e2ef6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "_ = speedmap_index_joined.apply(stage_intermediate_data, axis = 1, args=[pbar])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13290dbe-d343-4718-a1b5-9bfd7df74458",
   "metadata": {},
   "outputs": [],
   "source": [
    "## iterate over itp_ids, attempt running, if failed change value to failed?\n",
    "## store failures in yml? with error if any??\n",
    "## proceed with build when all already_ran or failed, again print which failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01922240-918b-468a-b41f-fdd706aa8970",
   "metadata": {},
   "outputs": [],
   "source": [
    "speedmap_index_joined = check_intermediate_data(speedmap_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1713a85-f5a8-4f6a-9b7e-adcde01e14ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "speedmap_index_joined >> filter(_.organization_itp_id == 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3322f1-cf0d-496c-9954-c4f412e953ad",
   "metadata": {},
   "source": [
    "## New step: confirm able to generate an all-day map?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b7c7ac-d145-44fa-9971-a392c1304ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_map_gen(row, pbar):\n",
    "    global speedmap_index_joined\n",
    "    analysis_date = row.analysis_date\n",
    "    progress_path = f'./_rt_progress_{analysis_date}.parquet'\n",
    "        \n",
    "    if row.status not in ('parser_failed', 'map_confirmed'):\n",
    "        try:\n",
    "            rt_day = rt_filter_map_plot.from_gcs(row.organization_itp_id,\n",
    "                                                       analysis_date, pbar)\n",
    "            _m = rt_day.segment_speed_map()\n",
    "            row.status = 'map_confirmed'\n",
    "        except Exception as e:\n",
    "            print(f'{row.organization_itp_id} map test failed: {e}')\n",
    "            row.status = 'map_failed'\n",
    "        speedmap_index_joined.loc[row.name] = row\n",
    "        speedmap_index_joined.to_parquet(progress_path)\n",
    "    \n",
    "    return  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79549862-192c-4290-ad1f-d0ed773c7645",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405dea8b-ece8-4a03-8920-9dd16bb45a52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "_ = speedmap_index_joined.apply(check_map_gen, axis = 1, args=[pbar])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b846f797-d26c-4ee5-84cb-1509fe57c491",
   "metadata": {},
   "outputs": [],
   "source": [
    "speedmap_index_joined = check_intermediate_data(speedmap_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df19a5f9-b316-49d7-ae2b-3ee74c24709b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shared_utils.rt_utils.show_full_df(speedmap_index_joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416c08a6-999f-4da9-afe2-e2cae550d584",
   "metadata": {},
   "source": [
    "## Prep portfolio yml for site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eaaa22-16c7-4df1-a1a5-0b8b8550de27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage_rt_portfolio(speedmap_index_joined,\n",
    "                       input_path = '../portfolio/sites/rt.yml',\n",
    "                       output_path = '../portfolio/sites/test_rt.yml'):\n",
    "        \n",
    "    # make sure intermediate data is ran or at least attempted\n",
    "    assert speedmap_index_joined.status.isin(['map_confirmed',\n",
    "                                              'parser_failed', 'map_failed']).all()\n",
    "    \n",
    "    with open(input_path) as rt_site:\n",
    "        rt_site_data = yaml.load(rt_site, yaml.Loader)\n",
    "    \n",
    "    chapters_list = []\n",
    "    speedmap_index_joined = speedmap_index_joined >> arrange(_.caltrans_district)\n",
    "    for district in speedmap_index_joined.caltrans_district.unique():\n",
    "        if type(district) == type(None):\n",
    "            continue\n",
    "        chapter_dict = {}\n",
    "        filtered = (speedmap_index_joined\n",
    "                    >> filter(_.caltrans_district == district,\n",
    "                             -_.status.isin(['parser_failed', 'map_failed']))\n",
    "                    >> arrange(_.organization_name)\n",
    "                   )\n",
    "        chapter_dict['caption'] = f'District {district}'\n",
    "        chapter_dict['params'] = {'district': district}\n",
    "        chapter_dict['sections'] = \\\n",
    "            [{'itp_id': itp_id} for itp_id in filtered.organization_itp_id.to_list()]\n",
    "        chapters_list += [chapter_dict]   \n",
    "        \n",
    "    parts_list = [{'chapters': chapters_list}]\n",
    "    rt_site_data['parts'] = parts_list\n",
    "    \n",
    "    output = pyaml.dump(rt_site_data)\n",
    "    with open(output_path, 'w') as rt_site:\n",
    "        rt_site.write(output)\n",
    "    \n",
    "    print(f'portfolio yml staged to {output_path}')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6bfd5e-7484-45c1-86ee-0fed5d67901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_rt_portfolio(speedmap_index_joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4c8273-2a81-45be-ac4f-43efe82237ad",
   "metadata": {},
   "source": [
    "## run portfolio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1afc9d-af3e-4f99-872c-a23444052079",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shared_utils.rt_utils.show_full_df(speedmap_index_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311ddbdf-46c9-431b-af8d-2aaa84b43262",
   "metadata": {},
   "outputs": [],
   "source": [
    "## os chdir ..\n",
    "## run script"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
