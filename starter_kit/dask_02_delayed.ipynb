{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3da49715-11db-49c0-a7e4-cf1602d75221",
   "metadata": {},
   "source": [
    "# Dask Exercise 2: dask delayed\n",
    "\n",
    "* [dask delayed](https://docs.dask.org/en/stable/delayed.html)\n",
    "* [dask tutorial](https://tutorial.dask.org/03_dask.delayed.html)\n",
    "\n",
    "Skills:\n",
    "* Convert a for loop into a simple dask delayed workflow \n",
    "* Get more familiar with `dask.dataframe` wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdb1f59-70db-4a90-8bf8-20c712a5facd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "\n",
    "from dask import delayed, compute\n",
    "\n",
    "GCS_FILE_PATH = (\"gs://calitp-analytics-data/data-analyses/\"\n",
    "                 \"rt_delay/v2_rt_trips/\"\n",
    "                )\n",
    "\n",
    "analysis_date = \"2023-03-15\"\n",
    "la_metro = 182\n",
    "big_blue_bus = 300\n",
    "muni = 282\n",
    "\n",
    "operators = [la_metro, big_blue_bus, muni]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f965cc4-1a02-413c-bb58-8d497ed9cfb0",
   "metadata": {},
   "source": [
    "## Simple Workflow to Parallelize\n",
    "\n",
    "This is a typical workflow. \n",
    "1. Read in pandas df.\n",
    "2. Apply a certain function.\n",
    "3. Export df.\n",
    "\n",
    "Let's say we have a df corresponding to each operator. We want to apply the same aggregation function and then save out the results.\n",
    "\n",
    "Typically, we would use a loop. A loop is **sequential**. By using `dask delayed` objects, we can run those **simultaneously**. Instead of running operator 1, operator 2, operator 3, ... , operator N, why not let them run at the same time and save out the results?\n",
    "\n",
    "There is nothing inherent in our workflow that specifies that operator 1 must be run before operator 2. We are applying the same function to each operator. To speed it up, let's use dask to run it in parallel and get our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534877e7-fa43-4ed1-bdd1-d99c7f47787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\n",
    "    f\"{GCS_FILE_PATH}{big_blue_bus}_{analysis_date}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5ef01a-b54a-4ab7-b8e3-1751828ae81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a function that counts the number of \n",
    "# unique route_ids and route_type\n",
    "def simple_route_aggregation(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        aggregated = (df.groupby([\"calitp_itp_id\",\n",
    "                                  \"organization_name\"])\n",
    "                      .agg({\"route_id\": \"nunique\", \n",
    "                            \"route_type\": \"nunique\"})\n",
    "                      .reset_index()\n",
    "                     )\n",
    "        \n",
    "        return aggregated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891b9575-5830-46bf-aae8-9ceb3ead49c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = simple_route_aggregation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69884777-467f-4ceb-b74c-6db0c0bf7504",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6760a6-5134-4e52-883c-72d4eac2b2bf",
   "metadata": {},
   "source": [
    "### Move it to delayed\n",
    "\n",
    "We can use the `@delayed` decorator right above our defined function.\n",
    "\n",
    "\n",
    "Alternatively, you can wrap the function, like `delayed(my_function)(args)`. These are equivalent.\n",
    "\n",
    "```\n",
    "@delayed\n",
    "def my_function(df):\n",
    "    df2 = do something\n",
    "    return df2\n",
    "    \n",
    "    \n",
    "or...\n",
    "delayed(my_function)(df)\n",
    "```\n",
    "\n",
    "**Note where the parentheses fall**...it is not a typo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf57ce1-7753-49b1-b32f-07b372bfc0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use a decorator to make it a delayed function\n",
    "@delayed\n",
    "def import_data(itp_id: int):\n",
    "    return pd.read_parquet(\n",
    "        f\"{GCS_FILE_PATH}{itp_id}_{analysis_date}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5023dc9e-a1db-460e-aa74-c80c8a1dc844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have a list of 3 operators we would have looped over\n",
    "operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b9544e-f83e-4e7e-b42e-0f1f6b4628f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's read in our data using list comprehension\n",
    "dfs = [import_data(x) for x in operators]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c38175c-bef7-417f-a723-6e5bc111952d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have a list of delayed objects\n",
    "# these dfs are not materialized / read into memory\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834bde7a-6d61-4dd3-9fca-f93147e5ddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set  up a list to store our results\n",
    "results = [delayed(simple_route_aggregation)(df) for df in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297dfad0-fa0b-4cda-9ef4-0a7c2f696ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The results are also delayed objects\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d0644e-40df-42cb-b3e9-512f4d11c455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap compute around each of the items in the results list \n",
    "# and see what's inside\n",
    "results_computed = [compute(i) for i in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0f6686-fc51-484a-9eb7-96af1d45cdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a list of tuples...that's not what we want\n",
    "results_computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d5c4d5-46be-4f11-b45f-679c2913226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(results_computed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbdfcc0-d488-4d3b-abc4-2edf54ef45db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need the first item of the tuple...that's our df\n",
    "type(results_computed[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b069616a-3896-4d1f-ba46-195ea006cf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_computed_correct = [compute(i)[0] for i in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a04de61-83a8-4ec2-8af8-1404dbed986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_computed_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688b9092-af5a-42dc-86d0-02b969ac2c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(results_computed_correct[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2bb03a-405e-490d-9a52-45a01ceac235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, the code can be written like a loop, \n",
    "# but it won't run like a loop. It will run it simultaneously \n",
    "# for the three operators\n",
    "\n",
    "results2 = []\n",
    "\n",
    "for itp_id in operators:\n",
    "    operator_df = import_data(itp_id)\n",
    "    print(f\"type for operator_df: {type(operator_df)}\")\n",
    "    \n",
    "    aggregated_df = delayed(simple_route_aggregation)(operator_df)\n",
    "    print(f\"type for aggregated_df: {type(aggregated_df)}\")\n",
    "    \n",
    "    results2.append(aggregated_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f77abfe-23cf-4d03-972a-a47f0d9310ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_computed2 = [compute(i)[0] for i in results2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04567df-fa86-4dfe-bb22-ea6a63626c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_computed2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcf9bbb-d898-4447-9b9c-4f1cb2b9b1b0",
   "metadata": {},
   "source": [
    "At this point, you can either write a function to export each individual aggregated pandas df result to be its standalone parquet, or combine it all. \n",
    "\n",
    "We will not export and overwrite the file in the GCS bucket right now.\n",
    "\n",
    "Since our results are just pandas dfs, we could also concatenate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80944910-0c82-434f-8f06-96c483dd8156",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(results_computed2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15585b5c-80e0-4a14-8525-03df6df8996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is rather pointless for such a small df, but for larger\n",
    "# ones, we may want to concatenate and export it as a partitioned parquet\n",
    "dd.multi.concat(results_computed2, axis=0).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf911179-92cd-41ad-9c15-d7217177dc7b",
   "metadata": {},
   "source": [
    "## To Do\n",
    "\n",
    "* For the same 3 operators, use delayed functions throughout, from importing the parquet, applying a function, and saving the results to a list.\n",
    "* Your function should group each trip into a category based on its `mean_speed_mph`. \n",
    "   * < 10 mph\n",
    "   * 10-15 mph\n",
    "   * 15-20 mph\n",
    "   * 20+ mph\n",
    "* For each operator, get the count of trips by category and its proportion\n",
    "* Save the results in a list, compute the results for all the operators at once\n",
    "* Concatenate the aggregated results for all the operators into one dask df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc8f7c4-05f0-44c9-86e7-8d059a59b6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
