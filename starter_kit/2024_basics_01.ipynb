{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "247e773f-0e29-4ed6-ab4d-5856325611b4",
   "metadata": {},
   "source": [
    "# Exercise 1: Familiarize yourself with `pandas` and `python`\n",
    "If you are new to Python, there are many resources!\n",
    "* There are introductory Python courses available through [Caltrans's LinkedIn Learning Library](https://www.linkedin.com/learning/search?keywords=python&u=36029164).\n",
    "* If videos aren't for you, [Practical Python for Data Science](https://www.practicalpythonfordatascience.com/00_python_crash_course) is an incredibly helpful book.\n",
    "\n",
    "## Skills \n",
    "* `pandas` is one of the base Python packages for working with tabular data.\n",
    "* F-strings\n",
    "* Export to Google Cloud Storage\n",
    "* Practice committing on GitHub\n",
    "\n",
    "## How to use the tutorials\n",
    "* The tutorials are divided by skills/concepts we are going to learn.\n",
    "* There are hints and instructions on the top.\n",
    "* There are links to references and it is highly recommended to read through them and practice them in this notebook, in addition to these exercises. \n",
    "\n",
    "## What are we working with today? \n",
    "* Today we will be working on Caltrans System Investment Strategy (CSIS) today. Per this [description](https://dot.ca.gov/programs/transportation-planning/division-of-transportation-planning/corridor-and-system-planning/csis)\n",
    "> <i>The California Department of Transportation (Caltrans) is committed to leading climate action and advancing social equity in the transportation sector set forth by the California State Transportation Agency (CalSTA) Climate Action Plan for Transportation Infrastructure (CAPTI, 2021)...Caltrans is in a significant leadership role to carry out meaningful measures that advance state’s goals and priorities through the development and implementation of the Caltrans System Investment Strategy (CSIS). The CSIS, which implements one of CAPTI’s key actions, is envisioned to be an investment framework through a data and performance-driven approach that guides transportation investments and decisions.</i>\n",
    "* DDS is working on CSIS is by automating the scoring of projects using Python. We score each project based on how well they do in various categories, aka metrics such as Zero Emmission Vehicles, Vehicle Miles Traveled, and more. \n",
    "* While the values in we are working with today are all <i>fake</i>, the exercise is based on actual datasets and assignments. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd32eed-55a4-4fd1-874b-02f9b4bd94a7",
   "metadata": {},
   "source": [
    "## Import Pandas\n",
    "* You are importing the package `pandas` that is the backbone of all data analysis work. \n",
    "* You can import countless packages. `numpy` and `geopandas` are also popular. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50199af7-04a8-43c5-ba1b-4127940749bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e18d8d7-2cce-4854-b6c4-56a7e7bdf636",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff74b143-6ff2-46e9-ae88-4a208155e990",
   "metadata": {},
   "source": [
    "## Jupyter Notebook\n",
    "* You're using a Jupyter Notebook right now.\n",
    "* Take some time to get used to this interface. \n",
    "* AMANDA TO DO: find a tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc30cb7d-77d3-465b-9831-8810096af9b1",
   "metadata": {},
   "source": [
    "## Check out the data \n",
    "* Download the Excel workbook containing all the CSIS data from Google Cloud Storage [here](https://console.cloud.google.com/storage/browser/_details/calitp-analytics-data/data-analyses/starter_kit/starter_kit_csis_scoring_workbook.xlsx;tab=live_object?project=cal-itp-data-infra). \n",
    "    * Open it up in Excel and take a look.\n",
    "### Read in the data\n",
    "* We are reading our Excel Workbook into a Pandas dataframe.\n",
    "* While there is a very [technical definition](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) of what a dataframe is, you can think of it as an Excel sheet that holds your data. \n",
    "* <b> Resource</b>: [This page of the Practical Python for Data Science](https://www.practicalpythonfordatascience.com/02_loading_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5950cb87-75ab-4871-ab4b-a8f1c41f0a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"gs://calitp-analytics-data/data-analyses/starter_kit/starter_kit_csis_scoring_workbook.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e09456e0-dfd2-4388-85de-eb9e95f983fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179960a3-6c9b-42af-a8f1-d6156c4be2d2",
   "metadata": {},
   "source": [
    "### Previewing Data \n",
    "* Often, you want to get a sneak preview of your data. \n",
    "* Thankfully, Python provides many methods for you to do so. \n",
    "* Below are a couple of very common methods we use. \n",
    "    * `.head()` shows the first five rows, while `.tail()` shows the last five.\n",
    "    * `.sample()` shows you a random row.\n",
    "    * Want to see or less than five? Specify it in the parantheses: `.head(10)` allows you to see the first 10 rows and `.head(2)` allows you to see the first 2.\n",
    "* Try everything yourself below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3386e9d8-15cd-48bc-8b1f-cf6f95512ad5",
   "metadata": {},
   "source": [
    "### More Methods!\n",
    "* `df.shape` gives you the number of rows and columns in your dataset.\n",
    "* `df.columns` returns all of the column names.\n",
    "* `df.info()` per the [pandas docs](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html#pandas.DataFrame.info) <i>prints information about a DataFrame including the index dtype and columns, non-null values and memory usage.</i>\n",
    "* Experiment below. \n",
    "* More food for thought:\n",
    "    * `Dtype` is critical. There are integers, objects, booleans, floats...\n",
    "    * Does the `dtype` of each column below make sense to you? \n",
    "    * The `dtype` of object is a catchall term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f55b33e-d402-473b-815a-92ad935d35d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44 entries, 0 to 43\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   ct_district    44 non-null     int64 \n",
      " 1   project_name   44 non-null     object\n",
      " 2   Scope of Work  44 non-null     object\n",
      " 3   Project Cost   44 non-null     int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 1.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d117908f-af05-4e95-8042-39a3e0557d6f",
   "metadata": {},
   "source": [
    "### Deeper Dive\n",
    "* We now know a good amount about our dataset, but the # of rows and columns are not always so thrilling. \n",
    "* Let's take a look at each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cece73-c3d5-4cd7-8896-f97d43fc1114",
   "metadata": {},
   "source": [
    "* `.value_counts()` helps you see how many times the same value appears. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63f21ab5-0920-4310-afce-2ea657556912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     7\n",
       "2     6\n",
       "6     6\n",
       "11    6\n",
       "7     5\n",
       "9     3\n",
       "12    3\n",
       "1     2\n",
       "4     2\n",
       "8     2\n",
       "10    1\n",
       "5     1\n",
       "Name: ct_district, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ct_district.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55baf38e-3776-4448-b375-9e124030bae2",
   "metadata": {},
   "source": [
    "* `.nunique()` displays the number of distinct values in your column\n",
    "    * This is  useful because there are many occassions when the number of unique values of a column should match the number of rows of your dataset <b>exactly</b>.\n",
    "    * In our case, our dataframe has 44 rows and we should have 44 unique project names and scope of work descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d832308-a425-404d-83a0-53ce8bfae279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.project_name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55d2140f-feab-496b-b9b1-90bbe5701a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0c499e-fa7b-4f01-a357-db7b0ec41416",
   "metadata": {},
   "source": [
    "* Notice that when you have spaces in between each string of your column name, you need to refer the column using brackets []. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e232324-f75f-46a0-962d-76ed9273dac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Scope of Work\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ee15f6-ee2e-4e3e-91b2-115875292042",
   "metadata": {},
   "source": [
    "## Something missing? \n",
    "* Open up our dataset using Excel. \n",
    "* Take a look at the bottom: how many sheets are there in the Excel worbook? \n",
    "* Which sheet is loaded into `df` above? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5302dd99-acb2-40d7-b00d-4f0493ee5e09",
   "metadata": {},
   "source": [
    "### Lists: An Introduction\n",
    "* We can load in all of the sheets in an Excel workbook using a <b>list</b>\n",
    "* Per [Practical Python for Data Science](https://www.practicalpythonfordatascience.com/00_python_crash_course_datatypes.html?highlight=dictionary#list): <i>\"lists represent a collection of objects and are constructed with square brackets, separating items with commas. A list can contain a collection of one datatype...It can also contain a collection of mixed datatypes</i>\".\"\n",
    "    * Play around with some of the examples in the link above in this notebook.\n",
    "* Notice that the items in this list are <i>strings</i>. Read about strings [here](https://www.practicalpythonfordatascience.com/00_python_crash_course_datatypes.html?highlight=dictionary#string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02380fb6-c55b-477f-acfb-8b483e83beac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "my_sheets = [\"projects_auto\",\n",
    "            \"overall_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a9a1a3e-e10d-4447-96dd-92ecb2fe6357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_sheets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a32ab4-bfb2-4e7a-b90a-6fa05b7ceb89",
   "metadata": {},
   "source": [
    "* You can access each element of the list using an index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3be037d-b21b-4192-9099-25bfcb660f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects_auto'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index\n",
    "my_sheets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebf91535-a466-446a-9f7a-606503d78b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'overall_score'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sheets[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75df89d0-92fb-4e4e-aaa3-54f4944c55c3",
   "metadata": {},
   "source": [
    "* Read the in the Excel workbook into a dataframe.\n",
    "* Using the argument `sheet_name` you can open up a specific sheet in an Excel workbook or multiple sheets that is held in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e2578bc-db1f-41f5-bc07-3cb82998420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_excel(\n",
    "    url,\n",
    "    sheet_name=my_sheets,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6059f491-3966-4343-b000-0830fa3559d6",
   "metadata": {},
   "source": [
    "### Specificity is beautiful.\n",
    "* Grab out each individual sheet into its own dataframe using `df2.get(my_sheets[enter in the index number])`. \n",
    "* Make sure your `dataframe` is titled descriptively.\n",
    "* `df` is not exactly very telling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c6f8fdb-33d3-4c44-bb00-6d1447d49feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_df = df2.get(my_sheets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "167af2f1-b09d-476d-87b4-b9374ad445c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = df2.get(my_sheets[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0d51ea-b7da-41d0-bb03-5432b4de1a1b",
   "metadata": {},
   "source": [
    "## Add a new column\n",
    "* Oops! Us analysts were so wrapped up in scoring, we forgot to to total up all the metrics to find the overall_score for the project. \n",
    "* Place your results in a column called `overall_score`\n",
    "* There are a couple of ways to do this: expeirment!\n",
    "* Food for thought:\n",
    "    * What does `axis = 1` mean?\n",
    "    * What happens if you do `.sum(axis=0)`?\n",
    "    * You don't always have to save everything into a dataframe. You can do something like `df.sum(axis=0)` just to see what happens. \n",
    "        * Just make sure your dataframe isn't too large or else you will run out of memory!\n",
    "    * What happens when you create a new column with `scores_df.overall_score` instead of `scores_df[\"overall_score\"]`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9321f90-8c99-46fb-9d50-8571f3d94fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df[\"overall_score\"] = scores_df.select_dtypes(include=['int64', 'float64']).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246437eb-f284-49b8-960d-d601a66f6362",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Subsetting\n",
    "* Your manager asks for the `overall_score` for each project. They do not want to see the other metrics, only the project's name and its total score.\n",
    "* Subset the dataframe and <b>save</b> it into a new dataframe.\n",
    "* Again, there are many ways to do the same thing in Python. \n",
    "* <b>Method 1:</b> Enter in all the columns you want to keep in a list and place the list in another set of brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e6d8e70-ae57-46c5-a5aa-9972be77f415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter in the columns you want to keep\n",
    "columns_to_keep = [\"project_name\",\"overall_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48ee899b-3db9-464f-802f-d431189176b7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "subsetted_df1 = scores_df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56865911-994c-4fb5-afe4-1fdc1d752d8b",
   "metadata": {},
   "source": [
    "* <b>Method 2</b>: You can enter in all the columns in a list you want to drop and use `.drop()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c64cdcf-9598-4f4a-b077-5caec0cfe264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter in the columns you want to drop\n",
    "columns_to_drop = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47a96b86-e5d1-4fcd-ba73-7db5badae28b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'columns_to_drop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m scores_df\u001b[38;5;241m.\u001b[39mdrop(columns \u001b[38;5;241m=\u001b[39m \u001b[43mcolumns_to_drop\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'columns_to_drop' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "subsetted_df2 = scores_df.drop(columns = columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e641185d-295d-4c42-ace1-16d33f2da0fa",
   "metadata": {},
   "source": [
    "## Export to Google Cloud Storage (GCS)\n",
    "* Save your <b>subsetted dataframe</b> from above back into the `starter_kit` folder. The file path should be something like this `\"gs://calitp-analytics-data/data-analyses/starter_kit/aggregated_csis.xlsx\"`.\n",
    "* However, remember our original Excel workbook's file path? It was`\"gs://calitp-analytics-data/data-analyses/starter_kit/starter_kit_csis_scoring_workbook.xlsx\"`\n",
    "* Essentially, the only difference between these two file paths are `aggregated_csis.xlsx` and `starter_kit_csis_scoring_workbook.xlsx` because the folder path `gs://calitp-analytics-data/data-analyses/starter_kit/` remains the same. \n",
    "* This is where f-strings come in.\n",
    "> Python f-strings provide a quick way to interpolate and format strings. They’re readable, concise, and less prone to error than traditional string interpolation and formatting tools...\n",
    "    * Read more about them [here](https://realpython.com/python-f-strings/#f-strings-a-new-and-improved-way-to-format-strings-in-python).\n",
    "* <b> Reference</b>\n",
    "    *  [Saving Code](https://docs.calitp.org/data-infra/analytics_tools/saving_code.html)\n",
    "* <b> Let's practice </b>!\n",
    "    * My file_path is always going to be `gs://calitp-analytics-data/data-analyses/starter_kit/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c9c53a5-dbf3-4dc0-aea0-832f3a91414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCS_FILE_PATH = \"gs://calitp-analytics-data/data-analyses/starter_kit/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a088a5-e8e2-4a12-9736-44ae46c2d771",
   "metadata": {},
   "source": [
    "* However the file is going to change.\n",
    "* Save the file name in an object called `FILE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db111f34-08b8-42f9-96fe-6852c4af50ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FILE = \"starter_kit_example_final_scores.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf96d0cf-7225-4a44-9955-988d982a0f7f",
   "metadata": {},
   "source": [
    "* Using `f-string`, combine `GCS_FILE_PATH` and `FILE` together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "edff403c-ef37-48d8-8c7a-60b388752a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://calitp-analytics-data/data-analyses/starter_kit/starter_kit_example_final_scores.xlsx'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put them together using a f-string\n",
    "f\"{GCS_FILE_PATH}{FILE}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5504c416-b65b-4c74-a2ba-95688cf8e77a",
   "metadata": {},
   "source": [
    "* Now go open up your new Excel workbook and see if it's what you expect.\n",
    "    * Hint: you will probably get a very annoying extra column! \n",
    "    * Try out some of the arguments [listed](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_excel.html#pandas.DataFrame.to_excel) and save your file again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf37fc2d-ac6c-4134-94de-79a9a4141ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scores_df[[\"project_name\",\"overall_score\"]].to_excel(f\"{GCS_FILE_PATH}{FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c17adb-404e-4e54-bdb4-c3295e0e2be2",
   "metadata": {},
   "source": [
    "* Export the entire (not subsetted) dataframe with the new `overall_score` column using `df.to_parquet()`. \n",
    "    * We typically  prefer saving to `parquets`. Why? Read below. Text taken from [here](https://docs.calitp.org/data-infra/analytics_new_analysts/03-data-management.html#parquet).\n",
    "    * <i>Parquet is an “open source columnar storage format for use in data analysis systems.” Columnar storage is more efficient as it is easily compressed and the data is more homogenous. CSV files utilize a row-based storage format which is harder to compress, a reason why Parquets files are preferable for larger datasets. Parquet files are faster to read than CSVs, as they have a higher querying speed and preserve datatypes (i.e. Number, Timestamps, Points). They are best for intermediate data storage and large datasets (1GB+) on most any on-disk storage. This file format is also good for passing dataframes between Python and R. A similar option is feather.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22562f2f-8359-4e44-951c-25e5ac033282",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.to_parquet(f\"{GCS_FILE_PATH}starter_kit_example_final_scores.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d211b4-89f0-4b2c-9093-1118114ba649",
   "metadata": {},
   "source": [
    "## You're almost done!\n",
    "* Name this notebook `YOURNAME_exercise1.ipynb`\n",
    "    * You can't right click and rename the file, since this notebook is tracked with Git. \n",
    "    * Rename it using `git mv OLDNAME.ipynb NEWNAME.ipynb`. \n",
    "    * The `mv` stands for move, and renaming a file is basically \"moving\" its path. \n",
    "    * Doing it this way retains the git history associated with the notebook. If you rename directly with right click, rename, you destroy the git history.\n",
    "* Use a descriptive commit message (ex: adding chart, etc). GitHub already tracks who makes the commit, the date, the timestamp of it, the files being affected, so your commit message should be more descriptive than the metadata already stored."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
