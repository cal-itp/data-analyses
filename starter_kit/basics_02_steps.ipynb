{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04af490c-5230-4b28-aeb4-d636f44a28ba",
   "metadata": {},
   "source": [
    "## Exercise 2: Merging and Deriving New Columns\n",
    "\n",
    "Skills: \n",
    "* Merge 2 dataframes\n",
    "* F-strings!\n",
    "* Markdown cells\n",
    "* Build on groupby/agg knowledge, derive new columns, exporting\n",
    "* Practice committing on GitHub\n",
    "\n",
    "References: \n",
    "* https://docs.calitp.org/data-infra/analytics_new_analysts/01-data-analysis-intro.html\n",
    "* https://docs.calitp.org/data-infra/analytics_tools/saving_code.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940e12c5-6775-4aa1-b7df-c00ca89732af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4487520-d005-4262-b19f-4433203b12df",
   "metadata": {},
   "source": [
    "Use of f-strings. [Read more on this](https://realpython.com/python-f-strings/#f-strings-a-new-and-improved-way-to-format-strings-in-python).\n",
    "\n",
    "Also, click on this Markdown cell and see how to do different formatting syntax within Markdown. [Reference this](https://www.datacamp.com/community/tutorials/markdown-in-jupyter-notebook).\n",
    "\n",
    "If you don't have access to Google Cloud Storage, change the path to pull from our truncated sample parquets stored in the repo.\n",
    "\n",
    "We use [relative paths](https://towardsthecloud.com/get-relative-path-python) rather than absolute paths. Since we are in the `starter_kit` directory, we just need to go one more level in to the `data` subfolder. To get one level outside of `starter_kit`, use `../` and you'll end up in `data-analyses`. \n",
    "\n",
    "```\n",
    "FOLDER = \"./data/\"\n",
    "FILE_NAME = \"exercise_2_3_ntd_metrics_2019.parquet\"\n",
    "df = pd.read_parquet(f\"{FOLDER}{FILE_NAME}\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287cd877-e8a9-4db8-846d-3ba384e7979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCS_FILE_PATH = \"gs://calitp-analytics-data/data-analyses/bus_service_increase/\"\n",
    "FILE_NAME = \"ntd_metrics_2019.csv\"\n",
    "\n",
    "df = pd.read_csv(f\"{GCS_FILE_PATH}{FILE_NAME}\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa36e5f-7ccd-4af0-9edb-f6e0ae96d542",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = \"ntd_vehicles_2019.csv\"\n",
    "df2 = pd.read_csv(f\"{GCS_FILE_PATH}{FILE_NAME}\")\n",
    "\n",
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfc1e31-12d8-490e-9473-1dffe0710047",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3994dc75-80b3-4094-ad3f-d37c415587d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"NTD ID\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b19028-cf65-4cd8-9bbb-e74076365374",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df2)\n",
    "df2[\"NTD ID\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aac90ed-cbf2-4ba8-bd2a-a603cb1c2b26",
   "metadata": {},
   "source": [
    "### To do:\n",
    "\n",
    "* Start with the `ntd_metrics_2019.csv` dataset.\n",
    "* Merge in the `ntd_vehicles_2019.csv` dataset from the same location within the GCS bucket, but only keep a couple of columns.\n",
    "* Print out what states there are using `value_counts`\n",
    "* Subset and only keep the following states: NY, CA, TX, ID, MS\n",
    "* Calculate some aggregate statistics grouping by states (the point of the exercise is to aggregate, less so on whether the stats make sense):\n",
    "    * Include: sum, mean, count (of operators), nunique (of city)\n",
    "    * Challenge: give a per capita measure, such as total service vehicles per 100,000 residents\n",
    "* Plot the per capita measure across the 5 states (some states are very populous and some are not...per capita hopefully normalizes pop differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8ee58a-a478-4ca0-931d-513729dff275",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f668dfe-406d-4786-96bd-ea5df4810119",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Agency.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05784ff-3e73-40d5-8925-4e9a8d75d602",
   "metadata": {},
   "source": [
    "### Step by Step\n",
    "\n",
    "Keep only the columns you need.\n",
    "\n",
    "* `df` is `ntd_metrics` and `df2` is `ntd_vehicles`\n",
    "* For both dfs, keep `Agency`, `City`, `State`, `Legacy NTD ID`, `NTD ID`\n",
    "* For `ntd_metrics`, also keep `Primary UZA\\n Population`, `Mode`, `TOS`\n",
    "* For `ntd_vehicles`, also keep `Total Service Vehicles`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bc9476-4ce5-46e4-afd9-2bf11a29550c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34ec075b-90fd-41d6-905a-da6bfd644b28",
   "metadata": {},
   "source": [
    "Rename columns for both dataframes.\n",
    "* replace spaces with underscores\n",
    "* lowercase letters\n",
    "\n",
    "`df.columns = df.columns.str.strip().str.replace(' ', '_').str.lower()` \n",
    "\n",
    "`df = df.rename(columns = {'old_name': 'new_name'})`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b56da93-a046-4407-b41c-9b348e5241b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c16372b-1d7f-4456-ba25-3500d74922c8",
   "metadata": {},
   "source": [
    "Basic checks for any given dataframe.\n",
    "\n",
    "* Check data types for columns: `df.dtypes`\n",
    "* Get df's info: `df.info()`\n",
    "* Get df's dimensions: `df.shape`\n",
    "* Get df's length (number of rows): `len(df)`\n",
    "* Summary stats for columns: `df.describe()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918147e5-4c95-4506-aad6-07a8f72896a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c728d9d9-16f4-4f82-a440-e9383098a577",
   "metadata": {},
   "source": [
    "Make a plan to clean columns.\n",
    "\n",
    "* Add a Markdown cell\n",
    "* Jot down which columns should be numeric, but are not.\n",
    "* If the data type is `object`, it's string. If it's `float64` or `int64`, it's numeric.\n",
    "* For the columns that should be numeric, do so. Use `assign` to create new columns and overwrite the existing columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7303ca-dd25-4b9e-85c1-3aea3a84de9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ebc5ec5-bb2d-4460-83d7-8353753b744c",
   "metadata": {},
   "source": [
    "Merge the 2 dataframes.\n",
    "* set the validate parameter: `validate = \"m:1\"`. Choose from \"m:1\", \"1:1\", or \"1:m\"\n",
    "* Put `ntd_metrics` on the left and `ntd_vehicles` on the right. What is the validate parameter?\n",
    "* Put `ntd_vehicles` on the left and `ntd_metrics` on the right. What is the validate parameter?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455fdb82-f644-4472-998a-2362ee45a5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71684834-6cf8-4ee5-9883-6baa83d2081f",
   "metadata": {},
   "source": [
    "Play with merges:\n",
    "* set `indicator=True`\n",
    "* adjust the `how` parameter: how = 'inner', 'left', 'right', 'outer'\n",
    "* look at the merge results: `df._merge.value_counts()`\n",
    "* what's changing? What merge results appear when it's an `inner` join vs `left` join vs `right` join vs `outer` join?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bb3ed0-58b3-46dc-94b5-b304bf01b97a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62261f84-c908-4285-9a8c-a0e95f425629",
   "metadata": {},
   "source": [
    "### Helpful Hints and Best Practices\n",
    "\n",
    "* Start with comprehensive approach in writing down all the lines of code to clean data. \n",
    "* Once the data cleaning process is done, work on refining the code and tidying it to see what steps can be chained together, what steps are done repeatedly (use a function!), etc.\n",
    "\n",
    "#### Chaining\n",
    "Similar to **piping** in R, where you can pipe multiple operations in 1 line of code with `>>`, you can do a similar method of chaining in Python. There is also a `df.pipe` function, but that's slightly different.\n",
    "\n",
    "Make use of parentheses to do this. Also, use `df.assign` (see below) so you don't run into the `SettingWithCopyWarning`, which may pop up if you decide to subset your data. \n",
    "\n",
    "#### Assign \n",
    "You can create new columns in place, and the warning that comes up is mostly harmless. But, `assign` also lets you chain more operations after. [More clarification.](https://pythonguides.com/add-a-column-to-a-dataframe-in-python-pandas/)\n",
    "```\n",
    "states_clean = (states_clean\n",
    "    # Assign is similar to R dplyr's mutate\n",
    "    .assign(\n",
    "        # Strip leading or trailing blanks (slightly different than replace)\n",
    "        # Decide if you want to replace all blanks or just leading/trailing\n",
    "        Agency = (states_clean.Agency.str.strip()\n",
    "                .str.replace('(', '').str.replace(')', '')\n",
    "        ),\n",
    "        # Do something similar for City as above\n",
    "        City = states_clean.City.str.strip(),\n",
    "        # Replace blanks with nothing\n",
    "        State = states_clean.State.str.replace(' ', '')\n",
    "    ).astype({\n",
    "        \"Population\": int, \n",
    "        \"Fare_Revenues\": int,\n",
    "    })\n",
    ")\n",
    "```\n",
    "\n",
    "Alternatively, try it with a loop:\n",
    "\n",
    "```\n",
    "for c in [\"Agency\", \"City\"]:\n",
    "    df[c] = (df[c].str.strip()\n",
    "            .str.replace('(', '')\n",
    "            .str.replace(')', '')\n",
    "            .astype(int)\n",
    "            )\n",
    "```\n",
    "\n",
    "#### Using `str.contains` with some special characters\n",
    "Use backslash `\\` to \"escape\". [StackOverflow explanation](https://stackoverflow.com/questions/48699907/error-unbalanced-parenthesis-while-checking-if-an-item-presents-in-a-pandas-d)\n",
    "`states_clean[states_clean.Fare_Revenues.str.contains(\"\\(\")]`\n",
    "\n",
    "\n",
    "#### Merging\n",
    "If your merge results produces a `col_x` and `col_y`, add more columns to your list of merge columns, with `on = [\"col1\", \"col2\"]`.\n",
    "\n",
    "#### Use `isin` to filter by multiple conditions\n",
    "\n",
    "```\n",
    "keep_me = [\"CA\", \"NY\", \"TX\"]\n",
    "df2 = df[df.State.isin(keep_me)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70346051-8093-41cb-ae51-68b26ab8d83d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "792f5848-4f78-4af4-8821-876a9e421ca7",
   "metadata": {},
   "source": [
    "Subset columns to just the 5 states listed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd394e1e-284e-4316-8b5d-e9ffb3ac9710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8a1f635-7a78-49be-9812-f4ba51f9598b",
   "metadata": {},
   "source": [
    "Add a new column with this metric: `service_vehicles_per_capita` (service vehicles divided by population)\n",
    "\n",
    "* [Read more on rate metrics](https://oag.ca.gov/sites/all/files/agweb/pdfs/cjsc/stats/computational_formulas.pdf)\n",
    "* `df[new_column] = df[numerator_col]/df[denominator_col]`\n",
    "* `df[new_column] = df[numerator_col].divide(df[denominator_col])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5097196-cd5c-4c16-a406-5c162c81508c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbf73a16-1f54-4044-b23d-da1a27e67b5b",
   "metadata": {},
   "source": [
    "Add a new column that is `service_vehicles_per_100k`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488a9522-17b7-44c4-ade6-09f77e6d0882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be9a347a-bacd-4eeb-9f8b-06422a01bfdc",
   "metadata": {},
   "source": [
    "Do a group by and aggregate.\n",
    "\n",
    "* Group by state, count the number of agencies and find average of total service vehicles.\n",
    "* Write a sentence to explain the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b0c152-8a28-431d-b81b-601876fb33fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
