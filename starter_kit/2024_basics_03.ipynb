{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f74a524-f90a-4ad5-8d98-368afc398b46",
   "metadata": {},
   "source": [
    "# Exercise 3: Strings, Functions, If Else, For Loops, Git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8a0d90-9d57-4d01-9eb4-0b255970995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from calitp_data_analysis import calitp_color_palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcdbbc1-2e1b-4797-bd34-07d9a1999cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eec9257-7578-422c-b6d1-afe496e8ca70",
   "metadata": {},
   "source": [
    "* Using a `f-string`, load in your merged dataframe from Exercise 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c52b09e-90b5-4a5d-8fda-ca19cb8fe3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCS_FILE_PATH = \"gs://calitp-analytics-data/data-analyses/starter_kit/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0222b8c-0996-47bb-8639-fc703cfbd249",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bbc1d2-4285-4399-a0fd-1e02c5e5d5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "673fa239-dc06-4ef8-9513-ee167e80898e",
   "metadata": {},
   "source": [
    "## Categorizing\n",
    "* There are 40+ projects. They all vary in themes, some contain transit elements while others contain Active Transportation (ATP) components. Some contain both! \n",
    "* Categorizing data is an important part of data cleaning and analyzing so we can present the data on a more succinct level. \n",
    "* Let's organize projects into three categories.\n",
    "    * ATP\n",
    "    * Transit\n",
    "    * General Lanes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49486dc6-a686-47fa-8cef-e252d7ec349d",
   "metadata": {},
   "source": [
    "### Task 1: Strings\n",
    "* Below are some of the common keywords that fall into the categories detailed above. They are held in a `list`.\n",
    "* Add other terms you think are relevant. \n",
    "* We are going to search the `Scope of Work` column for these keywords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6b817f-15e2-4d1c-aeae-5d7e9661a6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transit = [\"transit\", \"passenger rail\", \"bus\", \"ferry\"]\n",
    "atp = [\"bike\", \"pedestrian\", \"bicycle\", \"sidewalk\", \"path\"]\n",
    "general_lanes = [\"general\", \"auxiliary\", \"highway\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caf3a84-fcd7-4531-befe-11e76c01c8f1",
   "metadata": {},
   "source": [
    "#### Step 1: Cleaning\n",
    "* Remember in Exercise 2 some of the project names didn't merge between the two dataframes?\n",
    "* In the real world, you won't have the bandwidth and time to replace each individual string value with a dictionary.\n",
    "* An easy way to clean most of the values up is by lowercasing, stripping the white spaces, and replacing characters.\n",
    "* We can search through a string column  easier when we simplify up the  values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4a4df7-61ec-430b-a827-302704857318",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.scope_of_work = (\n",
    "    df.scope_of_work.str.lower() # Lowers the strings\n",
    "    .str.strip() # Strips trailing white spaces\n",
    "    .str.replace(\"-\", \" \") # Replaces hyphens with a space\n",
    "    .str.replace(\"+\", \" \")\n",
    "    .str.replace(\"_\", \" \")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3da188c-2afe-49f4-bbbd-8fecd8dfe10f",
   "metadata": {},
   "source": [
    "* `str.contains()` allows you to search through the column. \n",
    "* Let's search for projects that have \"transit\" in their descriptions. \n",
    "* There are many modifications you can make to `str.contains()`. Try them out and see what happens.\n",
    "    * `df.loc[df.scope_of_work.str.contains(\"transit\", case=False)]` \n",
    "        * Will search through your column without matching the case. It'll return rows with both \"Transit\" and \"transit\".\n",
    "    * `df.scope_of_work.str.contains(\"transit\", case=False, regex=False) `\n",
    "        * Will return any matches that include `transit` rather than an exact match. It'll return rows with values like \"transit\" and \"Transitory\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be843d6a-b751-4e9f-8820-b521089914d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transit_only_projects = df.loc[df.scope_of_work.str.contains(\"transit\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec68f286-cdeb-4b7b-86ef-6d35c8ee9587",
   "metadata": {},
   "source": [
    "* Let's see how many transit projects are in this dataset.\n",
    "* <b>Tip</b>\n",
    "    * The data we typically work with tends to be wide (read about wide vs. long data [here](https://www.statology.org/long-vs-wide-data/)). Scrolling horizontally gets tiresome.\n",
    "    * Placing all the columns you want to temporarily work within a `list` like `preview_subset` below is a good idea to temporarily narrow down your dataframe while working. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315228d8-a72e-4f18-a0e7-2a254c87cc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_subset = [\"project_name\", \"scope_of_work\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6789307c-5808-4501-a1a6-5a14a12b0219",
   "metadata": {},
   "outputs": [],
   "source": [
    "transit_only_projects[preview_subset]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3adfb74-5a24-47f8-88da-92fe5591821a",
   "metadata": {},
   "source": [
    "#### Step 2: Filtering\n",
    "* We've found all the projects that says \"transit\" somewhere in its description. \n",
    "* Now there are just many more transit related elements to go. We forgot about bikes, bus, rail, so on and so forth.\n",
    "* The method above leaves us with multiple dataframes. We actually just want our one original dataframe tagged with categories. \n",
    "* A faster way: join all the keywords you want into one large string.\n",
    "    * | designates \"or\".\n",
    "    * You can read `transit_keywords` as \"I want projects that contain the word transit or passenger rail or bus or ferry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2575f75-44ac-46ba-a334-fdf984546cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transit_keywords = f\"({'|'.join(transit)})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a2a521-c0ae-4c2d-830d-4020a13855f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print it out\n",
    "transit_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937913db-407e-415c-aabb-31d3f511ef0b",
   "metadata": {},
   "source": [
    "* Filter again - notice the .loc after df and how there are brackets around `df`?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e23b6f-98b8-4219-bc52-d847ea39d121",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.scope_of_work.str.contains(transit_keywords)][preview_subset]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82ef0b7-d2c9-48d1-a53f-625fb083e196",
   "metadata": {},
   "source": [
    "* Count how many more projects appear when we filter for 3 additional transit related keywords, compared to only transit below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b62f28d-7b28-4258-8efa-74d1f9a41d04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c6717f8-4088-4c1f-9ec6-b9959fd6d283",
   "metadata": {},
   "source": [
    "\n",
    "* Let's put this all together. \n",
    "* I want any project that contains a transit component to be tagged as \"Y\" in a column called  \"Transit\". \n",
    "* If a project doesn't have a transit component, it gets tagged as a \"N\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47afb269-672f-44c1-8ab5-d70921c6e703",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Transit\"] = np.where(\n",
    "    (df.scope_of_work.str.contains(transit_keywords)),\n",
    "    \"Y\",\n",
    "    \"N\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe862f0-f77e-4bf5-8710-888d3a8d7a4c",
   "metadata": {},
   "source": [
    "* Using `value_counts()` we can see the total of transit related vs non-transit related projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63f2ff8-3d2f-41c6-96d1-36d35159aef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f18b2040-37f0-4e1a-b7ab-484eea69f1f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 2: Functions \n",
    "* It looks like there are only  9 transit projects.\n",
    "* We are missing the 2 other categories: ATP and General Lane related projects.\n",
    "* We could repeat the steps above or we can use a **function.**\n",
    "    * You can think of a function as a piece of code you write only once but reuse more than once.\n",
    "    * In the long run, functions save you work and look neater when you present your work.\n",
    "* You may not have realized this but you've been using functions this whole time.\n",
    "    * When you are taking the `len()` you are using a built-in function to find the number of rows in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c62fef2-8215-4983-a4e6-c671177b822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2180f69-6b3d-465c-8dda-a067e24f4ed1",
   "metadata": {},
   "source": [
    "* `type` too is a built-in function that tells you what type of variable you are looking at. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0659a036-76ad-4251-80a1-323a0a04c912",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2985ec16-35e1-4eae-b2c5-facb354ce4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(GCS_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c6b0c7-a314-434f-8304-10afd6c84514",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(transit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a5b9d7-1b39-419e-892a-fe44da7a4cf0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Practice with outside resources\n",
    "* Functions are incredibly important as such, **please spend more time than usual on this section and practice the tutorials linked.**\n",
    "* [Tutorial #1 Practical Python for Data Science.](https://www.practicalpythonfordatascience.com/00_python_crash_course_functions)\n",
    "* [DDS Functions.](https://docs.calitp.org/data-infra/analytics_new_analysts/01-data-analysis-intro.html#functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ead246-8879-4075-a632-d0ded58df558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463e13cf-7ba1-4499-bcd0-465a6457f856",
   "metadata": {
    "tags": []
   },
   "source": [
    "####  Let's build a function together.\n",
    "* This will be repetitive after the tutorials, but you will use functions all the time at DDS.\n",
    "##### Step 1\n",
    "* Start your function with `def` and the name you'd like. I'm calling it `categorize():`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e597a2-8625-4f2b-8646-760c0c011208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def categorize():"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ccd282-cf21-462b-8930-9a3148671ff1",
   "metadata": {},
   "source": [
    "##### Step 2 \n",
    "* Now let's think of what are the two elements that we will repeat.\n",
    "* We merely want to substitute `transit_keywords` with ATP or General Lane related keywords.\n",
    "* Instead of the `df[\"Transit]\"`, we want to create two new columns called something like `df[\"ATP]\"` and `df[\"General_Lanes]\"` to hold our yes/no results.\n",
    "* Add the two elements that need to be substituted into the argument of your function.\n",
    "    * It's good practice to specify what exactly the parameter should be: a string/list/dataframe/etc. \n",
    "    * Including this detail make it easier for your coworkers to read and use your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61973dc6-d99b-48f0-842f-a3c8fe74f064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def categorize(df:pd.DataFrame, keywords:list, new_column:str):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae178f6d-0f76-419c-aab2-9924ba294605",
   "metadata": {},
   "source": [
    "##### Step 3\n",
    "* It's also good to document what your function will return.\n",
    "* In our case, it's a Pandas dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a794693a-3bf2-48ba-b0a7-1ca3a41e03af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def categorize(df:pd.DataFrame, keywords:list, new_column:str)->pd.DataFrame:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be820c1a-a0d2-4b2f-bf01-70e753603291",
   "metadata": {},
   "source": [
    "##### Step 4\n",
    "* Think about the steps we took to categorize transit only.\n",
    "* Add the sections of the code we will be reusing and sub in the original variables for the arguments.\n",
    "    *  First, we joined the keywords from a list into a big string.\n",
    "    *  Second, we searched through the Scope of Work column for the keywords.\n",
    "    *  Third, if we find the keyword, we will tag the project as \"Y\" in the column \"new_column\". If the keyword isn't found, the project is tagged as \"N\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4721b564-726a-4e05-9d27-8035609b5fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(df: pd.DataFrame, keywords: list, new_column: str) -> pd.DataFrame:\n",
    "    \n",
    "    # Remember this used to be the list called transit_keywords, but it must be changed into a long string\n",
    "    joined_keywords = f\"({'|'.join(keywords)})\" \n",
    "\n",
    "    # We are now creating a new column: notice how parameters has no quotation marks.\n",
    "    df[new_column] = np.where((df.scope_of_work.str.contains(joined_keywords)), \n",
    "        \"Y\",\n",
    "        \"N\",\n",
    "    )\n",
    "\n",
    "    # We are returning the updated dataframe from this function\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bbb109-beef-452c-b8d9-eb13e7b9ee03",
   "metadata": {},
   "source": [
    "#### Step 5 \n",
    "* Now let's use your function: input the arguments in for each of the lists that hold the categorical keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e31c98-17b3-41e2-883a-14dae9d6da7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = categorize(df = df, \n",
    "                keywords = atp, \n",
    "                new_column = \"ATP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405aac8e-4488-47fa-bbb1-a12121ed8d15",
   "metadata": {},
   "source": [
    "#### Check out your results\n",
    "* Use the `groupby` technique from Exercise 2 to get some descriptive statistics for these 3 new columns\n",
    "* Use `.reset_index()` after `aggregate()` to see what happens.\n",
    "* Try `.reset_index(drop = True)` as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62115dcb-ea34-4bb1-9bd1-e678ec015b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e17c3e18-5f55-4a00-9919-b1f0c826b77f",
   "metadata": {},
   "source": [
    "## Function + If-Else\n",
    "* There are many cases in which we want to categorize our columns to create broader groups for summarizing and aggregating.\n",
    "* Using a function with an If-Else clause will help us accomplish this goal.\n",
    "* **<b>Resources</b>:**\n",
    "    * [DDS Apply Docs](https://docs.calitp.org/data-infra/analytics_new_analysts/01-data-analysis-intro.html#functions)\n",
    "    * [DDS If-Else Tutorial](https://docs.calitp.org/data-infra/analytics_new_analysts/01-data-analysis-intro.html#if-else-statements)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d824c18-4c2b-41c9-950b-866e567ab7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212570f5-e8ed-4151-be24-dd0994304334",
   "metadata": {},
   "source": [
    "### Practice #1: \n",
    "* We are going to write an If-Else function that categorizes projects by whether it scored low, medium, or high based on its `overall_score` and percentiles.\n",
    "    * If a project scores below the 25% percentile, it is a \"low scoring project\". If a project scores above the 25% percentile but below the 75% percentile, it is a \"medium scoring project\". Anything above the 75% percentile is \"high scoring\".\n",
    "* In Data Science, we like to save our work into variables.\n",
    "    * If new projects are added, then different percentiles will likely switch.\n",
    "    * As such, you can save whatever percentile you like using `p75 = df.overall_score.quantile(0.75).astype(float)` which will change automatically when you load in the new data.\n",
    "* Write an if-else and set the various percentiles using variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a10cf89-0997-465d-a3d9-f1464e6c619f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8121275c-a4fa-44d8-861e-4fd6accba0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d91c41b1-76c4-4673-b16f-ef9990d66270",
   "metadata": {},
   "source": [
    "### Practice #2\n",
    "* Goal:\n",
    "    * Above, we can see all types of combinations of categories a project can fall into. \n",
    "    * Let's do away with these \"Y\" and \"N\" columns and create actual categories in an actual column called `categories`.\n",
    "    * If a project has \"N\" for all 3 of the General Lane, Transit, and ATP columns, it should be `Other`. \n",
    "    * If a project has \"Y\" for all 3, it should be categorized as \"General Lane, Transit, and ATP\".\n",
    "    * If a project has \"Y\" for only ATP and Transit, it should be categorized as \"Transit and ATP\".\n",
    "    * Yes this will be very tedious given all the combinations!\n",
    "* Resource:\n",
    "    * [Geeks for Geeks: if-else with multiple conditions](https://www.geeksforgeeks.org/check-multiple-conditions-in-if-statement-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d560dad0-de03-4469-99f8-5fadd9b198dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b7d946-c724-43cb-9a93-d1003f7f024f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df815f56-c2ed-43ff-9180-147beddcffe0",
   "metadata": {},
   "source": [
    "### Please export your output as a `.parquet` to GCS before moving onto the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18a7754-907c-46fa-ad77-4a09abb03206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2245ce0c-97fb-4f08-9791-9fb6b28b49c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14ba020e-e2b3-4447-89e2-abdc0579fc6b",
   "metadata": {},
   "source": [
    "## For Loops \n",
    "* For Loops are one of the greatest gifts of Python. \n",
    "* It runs code from the beginning to the end of a list. \n",
    "* Below is a simple for loop that prints out all the numbers in range of 10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48495a9f-e29c-41eb-b3e7-de6371fbd182",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cdfc33-359c-4687-be4a-7f758c028640",
   "metadata": {},
   "source": [
    "* Here, I'm looping over a couple of columns in my dataframe and printing some descriptive statistics about it.\n",
    "* Notice how I have to use `print` and `display` to show the results.\n",
    "    * Try this same block of code without `print` and `display` to see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca9e430-a906-4d0e-8046-36a0687b0636",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in [\"zev_score\", \"vmt_score\", \"accessibility_score\"]:\n",
    "    print(f\"Statistics for {column}\")\n",
    "    display(df[column].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded54884-4bad-46ae-a82f-2a67936c57dd",
   "metadata": {},
   "source": [
    "### Practice using a for loop\n",
    "* I have aggregated the dataframe for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b414d3f-71a4-4078-9d98-b9082114e2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg1 = (\n",
    "    df.groupby([\"category\"])\n",
    "    .aggregate(\n",
    "        {\"overall_score\": \"median\", \"project_cost\": \"median\", \"project_name\": \"nunique\"}\n",
    "    )\n",
    "    .reset_index()\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"overall_score\": \"median_score\",\n",
    "            \"project_cost\": \"median_project_cost\",\n",
    "            \"project_name\": \"total_projects\",\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1698fe9c-6d1f-412b-a632-826aae1ffc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345a87ee-0f09-43f2-ad3e-70debb7ab25c",
   "metadata": {},
   "source": [
    "* I have also prepared an Altair chart function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320bd91e-b9ed-4423-80d4-c1a1aa5ba59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chart(df: pd.DataFrame, column: str) -> alt.Chart:\n",
    "    title = column.replace(\"_\", \" \").title()\n",
    "    chart = (\n",
    "        alt.Chart(df, title=f\"{title} by Categories\")\n",
    "        .mark_bar(size=20)\n",
    "        .encode(\n",
    "            x=alt.X(column),\n",
    "            y=alt.Y(\"category\"),\n",
    "            color=alt.Color(\n",
    "                \"category\",\n",
    "                scale=alt.Scale(\n",
    "                    range=calitp_color_palette.CALITP_CATEGORY_BRIGHT_COLORS\n",
    "                ),\n",
    "            ),\n",
    "            tooltip=list(df.columns),\n",
    "        )\n",
    "        .properties(width=400, height=250)\n",
    "    )\n",
    "    return chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47dc93c-ab8b-4be7-a90d-3ca941e94050",
   "metadata": {},
   "source": [
    "* Use the function above to create a chart out of the aggregated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6103703-8131-4ed8-9482-314c7895c279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eff3b0be-7091-4995-b2b8-63d62bf9b6c4",
   "metadata": {},
   "source": [
    "\n",
    "* We have a couple of other columns left that still need to be visualized. \n",
    "* This is the perfect case for using a for loop, since all we want to do is replace the column above with the two remaining columns. \n",
    "* Try this below! \n",
    "    * You'll have to create a `list` that contains the rest of the columns.\n",
    "    * You'll have to wrap the function with `display()` to get your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8659f1-0842-4bb5-a544-9a2a5fb93c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35d78005-8c55-4fd9-90cc-2af30ed3fd6b",
   "metadata": {},
   "source": [
    "## GitHub - Pull Requests\n",
    "* In Exercise 1, you created a new branch that you are working on now.\n",
    "* Now that you are done with Exercise 3, you are at a nice stopping point to commit your work to our `main` branch.\n",
    "\n",
    "**Steps**\n",
    "1. Do the normal workflow of `committing` your work. \n",
    "2. Navigate to the our `data-analyses` [repo over here](https://github.com/cal-itp/data-analyses).\n",
    "3. Follow the steps detailed in [this video](https://youtu.be/nCKdihvneS0?si=nPlBOAMcgO1nv3v1&t=95). \n",
    "4. Once you're done writing, scroll down the bottom and click `merge pull request` \n",
    "<img src= \"./starter_kit_img.png\">\n",
    "5. Your work is now merged into the `main` branch of our `data-analyses` repo. \n",
    "6. To check, navigate to the our [repo](https://github.com/cal-itp/data-analyses) and to this `starter_kit` folder to make sure your notebooks are on the `main` branch.\n",
    "7. Delete the branch `your_branch`. \n",
    "    * It's considered outdated now because your changes are on the `main branch`. In the terminal, paste `git branch -d your_branch`. \n",
    "    * If that doesn't work, paste `git branch -D your_branch`.\n",
    "8. Continuing in the terminal, paste `git switch main`. \n",
    "9. Paste `git pull origin main`. \n",
    "    * This pulls down the work you just uploaded, along with the other work your coworkers have committed onto the main branch. \n",
    "9. Create a new branch `git switch -c your_branch` to continue working on exercises 4 and 5.\n",
    "    * Your new branch can have the same name as the branch you just merged in."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
