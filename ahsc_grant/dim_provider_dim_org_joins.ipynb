{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4340183c-18a2-4bef-9f24-55bec1e131be",
   "metadata": {},
   "source": [
    "# GTFS to NTD\n",
    "\n",
    "* Get `schedule_gtfs_dataset_key` to `ntd_id_2022` \n",
    "* Use `dim_provider_gtfs_data` and `dim_organizations`\n",
    "* Would anticipate a similar issue to `schedule_gtfs_dataset_key` having multiple rows being linked to `organization_name`, since NTD is another column in `dim_organizations`\n",
    "* Shweta only found 98 pairs of `schedule_gtfs_dataset_key` to `ntd_id_2022`...should we be expecting more?\n",
    "* How many operators are there, how close to 100% of the operators we have GTFS data for can we associate an NTD ID?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b14385-199c-4051-a1b6-4d91c3e176ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "from shared_utils import portfolio_utils, schedule_rt_utils\n",
    "from gtfs_key_ntd_crosswalk import GCS_FILE_PATH, filter_to_valid_dates\n",
    "\n",
    "with open(\n",
    "    \"../_shared_utils/shared_utils/portfolio_organization_name.yml\", \"r\"\n",
    ") as f:\n",
    "    PORTFOLIO_ORGANIZATIONS_DICT = yaml.safe_load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607285b5-13e0-4b2b-830a-ffd7d3053585",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# It's just 3 dates, so let's just keep all the combos available\n",
    "operators = pd.read_parquet(\n",
    "    f\"{GCS_FILE_PATH}ahsc_test/trips_2022.parquet\",\n",
    "    columns = [\"gtfs_dataset_key\", \"service_date\"]\n",
    ").drop_duplicates().reset_index(drop=True).rename(\n",
    "    columns = {\"gtfs_dataset_key\": \"schedule_gtfs_dataset_key\"}\n",
    ").astype({\"service_date\": \"datetime64[ns]\"})\n",
    "\n",
    "date_list = operators.service_date.unique().tolist()\n",
    "\n",
    "operators.service_date.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6aefc6-21d1-4a5c-a864-e49202cfcecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 208 operators, so why can't we get more NTD IDs to link?\n",
    "# NTD ID 2022, GTFS is from Dec 2022\n",
    "operators.schedule_gtfs_dataset_key.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada1cbf2-938c-4aff-932d-2763f325bb80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from segment_speed_utils import helpers\n",
    "analysis_date_list = ['2022-11-30', '2022-12-03', '2022-12-04']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f36a269-a227-4b11-9248-a3b3c5849b32",
   "metadata": {},
   "source": [
    "## GTFS schedule trips\n",
    "\n",
    "* compare what's downloaded with operator summary\n",
    "* numbers should be close, though gtfs_utils_v2 will filter out and keep agency subfeeds\n",
    "* already, these numbers are not that close, and do a fresh download...but should mimic gtfs_utils_v2, so use gtfs_funnel\n",
    "\n",
    "#### Hypothesis 1: every operator in schedule should merge with `dim_provider_gtfs_data` (because it belongs to a quartet)\n",
    "\n",
    "#### Hypothesis 2: once all operators have an organization_id, all of those should merge with dim_organizations \n",
    "* if `organization_source_record_id` is present in both, we should expect this\n",
    "* but perhaps only most should have an NTD ID (we can't be sure here, since NTD IDs can be nulls).\n",
    "* possible null NTD IDs are college campus shuttle feeds, those *might* not have NTD ID\n",
    "* we care about `schedule_gtfs_dataset_key` to `ntd_id_2022` relationship (even if we have to use `organization_source_record_id` to merge tables. \n",
    "   * multiple `schedule_gtfs_dataset_key` to 1 `ntd_id_2022` (LA Metro Bus/Rail -> LA Metro)\n",
    "   * 1 key to multiple NTD IDs? is this even possible? where would this make sense?\n",
    "   * maybe a regional feed, `VCTC GMV Schedule: 'Ventura County (VCTC, Gold Coast, Cities of Camarillo, Moorpark,\n",
    "  Ojai, Simi Valley, Thousand Oaks)` could have multiple NTD IDs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ff6fd7-401d-4bea-b7fc-590e1c2da2d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_operator_df = pd.concat(\n",
    "    [helpers.import_scheduled_trips(\n",
    "        one_date, \n",
    "        columns = [\"gtfs_dataset_key\", \"name\"],\n",
    "        get_pandas = True\n",
    "    ) for one_date in analysis_date_list], \n",
    "    ignore_index=True \n",
    ")\n",
    "\n",
    "new_operator_df.schedule_gtfs_dataset_key.nunique(), new_operator_df.name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef17755-3f10-414b-b2b0-5a6140aa2e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dim_provider_gtfs_data_full = pd.read_parquet(\n",
    "    f\"{GCS_FILE_PATH}ahsc_test/dim_provider_gtfs_data_full.parquet\"\n",
    ").pipe(\n",
    "    schedule_rt_utils.localize_timestamp_col, \n",
    "    [\"_valid_from\", \"_valid_to\"]\n",
    ")\n",
    "\n",
    "valid_provider_full = filter_to_valid_dates(dim_provider_gtfs_data_full, date_list)\n",
    "\n",
    "dim_orgs = pd.read_parquet(\n",
    "    f\"{GCS_FILE_PATH}ahsc_test/organizations.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af862a1-74c2-4575-a9f4-c6e9cd1821fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_operator_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f5f860-ce09-455f-975c-fbd6872c6892",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1 gtfs_key can have multiple organizations\n",
    "# can 1 org have multiple NTD IDs? null NTD IDs, we know. but we think only multiple NTD IDs if the ID changed\n",
    "df2 = pd.merge(\n",
    "    new_operator_df.rename(columns = {\"name\": \"schedule_gtfs_dataset_name\"}),\n",
    "    valid_provider_full[\n",
    "        [\"schedule_gtfs_dataset_key\", \n",
    "         \"organization_source_record_id\"]].drop_duplicates(),\n",
    "    on = \"schedule_gtfs_dataset_key\",\n",
    "    how = \"left\",\n",
    "    #indicator = True\n",
    ").merge(\n",
    "    dim_orgs,\n",
    "    left_on = \"organization_source_record_id\",\n",
    "    right_on = \"source_record_id\",\n",
    "    how = \"left\",\n",
    "    indicator = True\n",
    ")\n",
    "\n",
    "df2._merge.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3581969d-cf6d-4b55-a9cb-c7285946223f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df2[df2.ntd_id_2022.isna()].schedule_gtfs_dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221f149b-3ee8-4cac-a2ea-4b9f68f5d80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "operator_summary = pd.read_parquet(\n",
    "    f\"{GCS_FILE_PATH}ahsc_test/fct_daily_feed_scheduled_service_summary.parquet\"\n",
    ")\n",
    "\n",
    "# ok, maybe go back to download full trips table, excluding some feeds\n",
    "# 194 seems reasonable, but 125 seems low\n",
    "operator_summary.service_date.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31830e74-2bed-4c84-9ea5-328a205f296a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_operator_df.schedule_gtfs_dataset_key.nunique(), new_operator_df.name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febe2dce-ea3c-4361-bfbd-0d231164c7f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from shared_utils import rt_dates\n",
    "\n",
    "dec2024_date = rt_dates.DATES[\"dec2024\"]\n",
    "\n",
    "dec2024_operators = helpers.import_scheduled_trips(\n",
    "    dec2024_date,\n",
    "    columns = [\"name\", \"gtfs_dataset_key\"],\n",
    "    get_pandas = True\n",
    ")\n",
    "dec2024_operators.shape, dec2024_operators.name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568a62ac-3dcb-424e-9c77-73674bfb5843",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dec2023_date = rt_dates.DATES[\"dec2023\"]\n",
    "\n",
    "dec2023_operators = helpers.import_scheduled_trips(\n",
    "    dec2023_date,\n",
    "    columns = [\"name\", \"gtfs_dataset_key\"],\n",
    "    get_pandas = True\n",
    ")\n",
    "dec2023_operators.shape, dec2023_operators.name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9667cd0-0180-413a-8a71-be40c1c5832d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for now, allow m:m merge because we know operators show up for multiple dates,\n",
    "# and 1 gtfs_key can link to several orgs\n",
    "# yikes, this is too crazy to deal with\n",
    "dim_provider_gtfs_data = pd.read_parquet(\n",
    "    f\"{GCS_FILE_PATH}ahsc_test/dim_provider_gtfs_data.parquet\"\n",
    ").pipe(\n",
    "    schedule_rt_utils.localize_timestamp_col, \n",
    "    [\"_valid_from\", \"_valid_to\"]\n",
    ")\n",
    "\n",
    "valid_gtfs_data = filter_to_valid_dates(dim_provider_gtfs_data, date_list)\n",
    "\n",
    "\n",
    "operator_to_orgs = pd.merge(\n",
    "    operators[[\"schedule_gtfs_dataset_key\"]].drop_duplicates(),\n",
    "    valid_gtfs_data [[\"schedule_gtfs_dataset_key\", \"schedule_gtfs_dataset_name\", \n",
    "                              \"organization_source_record_id\", \"_valid_from_local\", \"_valid_to_local\"]],\n",
    "    on = \"schedule_gtfs_dataset_key\",\n",
    "    how = \"inner\",\n",
    "    validate = \"1:m\",\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "operator_to_orgs._merge.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19e47ba-7a81-4e24-9a20-a4464ca4e0be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# started with 208, yet only some merge on, weird\n",
    "operators.schedule_gtfs_dataset_key.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cfb657-0aa4-4425-aaf0-6d2603a73e63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# schedule_gtfs_dataset_key:org_name (can be 1:m, 1:1 for majority).\n",
    "# schedule_gtfs_dataset_key:portfolio_org_name is 1:1. But LA Metro Bus / LA Metro Rail both map to LA Metro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5226a08-278d-4a44-b0e9-70377d7a2b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
