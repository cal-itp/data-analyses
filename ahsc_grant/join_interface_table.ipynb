{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0f5f51d-a0bf-4e7e-a824-bcfa80a9ac62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.10.3-CAPI-1.16.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CALITP_BQ_MAX_BYTES\"] = str(800_000_000_000) ## 800GB?\n",
    "\n",
    "import shared_utils\n",
    "\n",
    "from siuba import *\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None) \n",
    "\n",
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "from calitp import get_engine\n",
    "from calitp.tables import tbls\n",
    "\n",
    "engine = get_engine()\n",
    "connection = engine.connect()\n",
    "\n",
    "GCS_FILE_PATH = 'gs://calitp-analytics-data/data-analyses/ahsc_grant/'\n",
    "\n",
    "import gcsfs\n",
    "fs = gcsfs.GCSFileSystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8c2776-6ff9-4c63-981e-87f6abdecd1e",
   "metadata": {},
   "source": [
    "# Collating Big Stop Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c5fc078-c353-4591-a01c-fa3c6670ced4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in and concatenate all geoparquets\n",
    "fs_list = fs.ls(f\"{GCS_FILE_PATH}tool_data/\")\n",
    "\n",
    "#fs_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15b35280-16c9-4347-8e9f-19bcdd7b867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = []\n",
    "for f in fs_list[1:]:\n",
    "    try: \n",
    "        test_pqt = pd.read_parquet(f\"gs://{f}\")\n",
    "        filelist.append(f)\n",
    "    except:\n",
    "        print(f\"error on {f.split('tool_data/')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "329e630c-9b83-434c-bb31-be666ecc8b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (pd.concat(\n",
    "        pd.read_parquet(f\"gs://{f}\")\n",
    "        for f in filelist\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0512d39f-246e-4c5f-9321-f97154ef4818",
   "metadata": {},
   "source": [
    "Note: Running into memory issues adding spatial weights matrix. Proceeding without spatially-lagged factors for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9678008a-699e-41b1-811a-18e2aaafb64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put coefficients into arrays - variable order from spatial_regression_exploration_kmk\n",
    "# in future, save out coefficients somewhere \n",
    "import numpy as np\n",
    "\n",
    "wkd_coeff = np.array([-0.1610594,0.0001214,-0.0000173,0.0224169,-0.0152673,-0.0505976,-0.0423512,0.0111763])\n",
    "sat_coeff = np.array([-0.1424400,0.0001344,-0.0000186,0.0256008,-0.0169793,-0.0408743,-0.0419725,0.0126354])\n",
    "sun_coeff = np.array([-0.1082477,0.0001477,-0.0000202,0.0209053,-0.0145447,-0.0449611,-0.0502937, 0.0132250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b05b7b3e-40d3-41da-8c46-ca7bd730e965",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bring on NTD ID\n",
    "NTD_agency_info = (tbls.mart_transit_database.dim_ntd_agency_info()\n",
    "                   >> select(_.key,_.ntd_id,_.ntd_agency_name)\n",
    "                   >> collect()\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "371d1335-5495-4215-a3e3-688b83538225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in NTD ridership\n",
    "NTD_ridership = pd.read_excel(\"gs://calitp-analytics-data/data-analyses/2021-Annual-Database-Files/September 2022 Adjusted Database.xlsx\", sheet_name=\"UPT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0641ccc2-4216-425b-b99d-7aa47e06fe6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ntd_id_num</th>\n",
       "      <th>ntd_ridership</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>61493156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001.0</td>\n",
       "      <td>9686309.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003.0</td>\n",
       "      <td>82543984.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004.0</td>\n",
       "      <td>1361603.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ntd_id_num  ntd_ridership\n",
       "0        1.0     61493156.0\n",
       "1    10001.0      9686309.0\n",
       "2    10002.0            0.0\n",
       "3    10003.0     82543984.0\n",
       "4    10004.0      1361603.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean names - pip install pyjanitor\n",
    "from janitor import clean_names\n",
    "\n",
    "NTD_ridership_clean = (NTD_ridership\n",
    "                        >> _.clean_names()\n",
    "                        >> rename(ntd_id_num = \"5_digit_ntd_id\")\n",
    "                       >> mutate(ntd_id_num=_.ntd_id_num.astype(str))\n",
    "                      )\n",
    "\n",
    "rider_cols = [\"oct21\",\"nov21\",\"dec21\",\"jan22\",\"feb22\",\"mar22\",\"apr22\",\"may22\",\"jun22\",\"jul22\",\"aug22\",\"sep22\"]\n",
    "NTD_ridership_clean['ridership_to_sep22'] = NTD_ridership_clean[rider_cols].sum(axis=1)\n",
    "                       \n",
    "NTD_ridership_clean = (NTD_ridership_clean                       \n",
    "                        >> select(_.ntd_id_num, _.modes, _.tos, _.ridership_to_sep22)\n",
    "                        >> filter(_.modes.str.endswith(\"B\"))\n",
    "                        >> group_by(_.ntd_id_num)\n",
    "                        >> summarize(ntd_ridership=_.ridership_to_sep22.sum())\n",
    "                      )\n",
    "\n",
    "NTD_ridership_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b507375-2764-4ff6-ad24-ba25cbbcacde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull off decimal\n",
    "NTD_ridership_clean['ntd_id'] = NTD_ridership_clean['ntd_id_num'].str.partition('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11f78fd8-9a03-41d8-82c3-b1eac75a0478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create list of n additional trips, use for final explode\n",
    "range_trips = list(range(0,21))\n",
    "range_trips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f13945-9741-4738-8dbc-fc92dce6ab5d",
   "metadata": {},
   "source": [
    "## Megatable\n",
    "\n",
    "Establish stop-level ridership estimate: \n",
    "- NTD-scaled estmated stop ridership = (model estimate stop ridership* NTD system ridership)/ model estimate system ridership\\\n",
    "\n",
    "Expand by Route\n",
    "Expand by N Additional Trips (0-20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c20c96-9694-4939-a076-694f41f0468e",
   "metadata": {},
   "source": [
    "## Big Function (loop over daytype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89c14b26-447e-405d-b8a0-35ea0ee8f295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridership(daytype,coeff_list,coefficient,constant,variance,daytype_count):\n",
    "    df1 = (df >> filter(_.daytype==daytype))\n",
    "    # multiply by coefficients - everything except n_trips\n",
    "    df1.loc[:, ['n_routes', 'pop_density', 'job_density','pct_not_us_citizen_pop',\n",
    "                        'pct_youth_pop', 'pct_seniors_pop', 'pct_pop_workers_no_car', 'pct_poverty']] *= coeff_list\n",
    "\n",
    "    # create stop-specific ridership factor\n",
    "    df1 = (df1\n",
    "               >> mutate(control_vars_sum = _.n_routes+_.pop_density+_.job_density+_.pct_not_us_citizen_pop+_.pct_youth_pop+_.pct_seniors_pop+_.pct_pop_workers_no_car+_.pct_poverty,\n",
    "                         control_vars_factor = _.control_vars_sum+(_.n_trips*coefficient)+constant\n",
    "               )\n",
    "              )\n",
    "\n",
    "    # baseline ridership model estimate: np.exp(control_vars_factor + (n_trips*n_trips_coeff) + correction factor)\n",
    "    df1['model_est_ridership'] = np.exp(df1['control_vars_factor']+(variance/2))\n",
    "    \n",
    "    # drop outlier stops\n",
    "    cutoff = df1['model_est_ridership'].quantile(0.99)\n",
    "    df2 = (df1\n",
    "              >> filter(_.model_est_ridership< cutoff)\n",
    "              )\n",
    "\n",
    "    # pull off aggregate system level ridership estimate\n",
    "    sys_riders = (df2\n",
    "                     >> group_by(_.calitp_itp_id,_.name,_.ntd_agency_info_key)\n",
    "                      >> summarize(sys_model_est_ridership = _.model_est_ridership.sum())\n",
    "                     )\n",
    "\n",
    "    # join ID to system level model estimate\n",
    "    sys_riders = (sys_riders\n",
    "              >> left_join(_,NTD_agency_info, {\"ntd_agency_info_key\":\"key\"})\n",
    "              )\n",
    "\n",
    "    # join NTD agg to system agg ridership, adjust for weekday\n",
    "    sys_riders = (sys_riders\n",
    "                      >> left_join(_,NTD_ridership_clean)\n",
    "                      >> mutate(ntd_ridership_daytype = _.ntd_ridership*(daytype_count/365))\n",
    "                     )\n",
    "\n",
    "    # many missings, but we know that model generally over predicts ridership\n",
    "    # fill with the median overprediction proportion\n",
    "    med_overpred_df = (sys_riders \n",
    "                       >> mutate(model_over_ntd = _.sys_model_est_ridership/_.ntd_ridership_daytype) \n",
    "                       >> summarize(med_model_over_ntd = _.model_over_ntd.median())\n",
    "                      )\n",
    "    \n",
    "    med_overpred = med_overpred_df['med_model_over_ntd'].values[0]\n",
    "\n",
    "    # Merge to stop-level ridership\n",
    "    df3 = (df2\n",
    "              >> left_join(_,sys_riders)\n",
    "              >> mutate(ntd_scaled_ridership = case_when({\n",
    "                  _.ntd_ridership>0 : _.model_est_ridership/(_.sys_model_est_ridership/_.ntd_ridership_daytype),\n",
    "                  True : _.model_est_ridership/med_overpred\n",
    "                  }\n",
    "                  )\n",
    "                )\n",
    "              )\n",
    "\n",
    "    # turn routelist string into actual list\n",
    "    df3['route_list_dups'] = df3['route_list_string'].str.split(',')\n",
    "\n",
    "    # deduplicate list - https://stackoverflow.com/questions/57107125/remove-duplicates-from-python-dataframe-list \n",
    "    df3['route_name'] = df3['route_list_dups'].map(np.unique)\n",
    "\n",
    "    # explode routes\n",
    "    df4 = df3.explode('route_name')\n",
    "\n",
    "    df4['n_addtl_trips'] = [range_trips]*len(df4)\n",
    "\n",
    "    #explode n addtional trips\n",
    "    df5 = df4.explode('n_addtl_trips')\n",
    "\n",
    "    coeff_pct = np.exp(coefficient)-1\n",
    "\n",
    "    # keep only relevant columns\n",
    "    df5 = (df5\n",
    "               >> mutate(n_addtl_riders = _.ntd_scaled_ridership.mul(coeff_pct).mul(_.n_addtl_trips))\n",
    "               >> select(_.calitp_itp_id,_.name,_.daytype,_.route_name,_.stop_id,_.stop_name,_.n_addtl_trips,_.n_addtl_riders)\n",
    "              )\n",
    "    \n",
    "    return df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4952195-598e-455e-8465-51175a4cc9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/pandas/core/nanops.py:1670: DeprecationWarning: the `interpolation=` argument to percentile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they. (Deprecated NumPy 1.22)\n",
      "/opt/conda/lib/python3.9/site-packages/pandas/core/nanops.py:1670: DeprecationWarning: the `interpolation=` argument to percentile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they. (Deprecated NumPy 1.22)\n",
      "/opt/conda/lib/python3.9/site-packages/pandas/core/nanops.py:1670: DeprecationWarning: the `interpolation=` argument to percentile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they. (Deprecated NumPy 1.22)\n"
     ]
    }
   ],
   "source": [
    "df_weekday = ridership(\"Weekday\",\n",
    "                       wkd_coeff,\n",
    "                       coefficient=0.0200865,\n",
    "                       constant=6.8721538,\n",
    "                       variance=2.434,\n",
    "                       daytype_count=261\n",
    "                      )\n",
    "\n",
    "df_saturday = ridership(\"Saturday\",\n",
    "                       sat_coeff,\n",
    "                       coefficient=0.0262958,\n",
    "                       constant=4.2261843,\n",
    "                       variance=3.007,\n",
    "                       daytype_count=52\n",
    "                      )\n",
    "\n",
    "df_sunday = ridership(\"Sunday\",\n",
    "                       sun_coeff,\n",
    "                       coefficient=0.0263988,\n",
    "                       constant=3.9734396,\n",
    "                       variance=3.119,\n",
    "                       daytype_count=52\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f659cb22-41d3-4436-b698-29a343f09fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_weekday,df_saturday,df_sunday], ignore_index=True)\n",
    "df_all.to_csv(f\"{GCS_FILE_PATH}AHSC_analysis_table.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44012eb6-f020-4201-8223-9dd88123586f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6650007 entries, 0 to 6650006\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Dtype \n",
      "---  ------          ----- \n",
      " 0   calitp_itp_id   int64 \n",
      " 1   name            object\n",
      " 2   daytype         object\n",
      " 3   route_name      object\n",
      " 4   stop_id         object\n",
      " 5   stop_name       object\n",
      " 6   n_addtl_trips   object\n",
      " 7   n_addtl_riders  object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 405.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d3507b-7ba8-4671-bb73-dd6f54f766d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
