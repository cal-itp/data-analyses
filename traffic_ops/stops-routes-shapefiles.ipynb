{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc836059-0980-4225-b7fd-3bf215479849",
   "metadata": {},
   "source": [
    "# Create routes and bus stops shapefiles\n",
    "\n",
    "Create 2 datasets to upload to ArcGIS:\n",
    "1. every stop + what route at those stops\n",
    "1. every route, with a line representing the route either from `shapes.txt` or creating one from `stops.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94320ab9-cd23-48d2-8822-fea339ee75d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from shared_utils import geography_utils\n",
    "\n",
    "os.environ[\"CALITP_BQ_MAX_BYTES\"] = str(100_000_000_000)\n",
    "pd.set_option(\"display.max_rows\", 20)\n",
    "\n",
    "from calitp.tables import tbl\n",
    "from calitp import query_sql\n",
    "from siuba import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393718d5-844c-418a-8781-12ef4e5838c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "stops = (\n",
    "    tbl.gtfs_schedule.stops()\n",
    "    >> select(_.calitp_itp_id, _.stop_id, \n",
    "              _.stop_lat, _.stop_lon, \n",
    "              _.stop_name, _.stop_code\n",
    "             )\n",
    "    >> distinct()\n",
    "    >> collect()\n",
    ").to_parquet(\"./stops.parquet\")\n",
    "\n",
    "\n",
    "trips = (\n",
    "    tbl.gtfs_schedule.trips()\n",
    "    >> select(_.calitp_itp_id, _.route_id, _.shape_id)\n",
    "    >> distinct()\n",
    "    >> collect()\n",
    ").to_parquet(\"./trips.parquet\")\n",
    "\n",
    "\n",
    "route_info = (\n",
    "    tbl.gtfs_schedule.routes()\n",
    "    # NB/SB may share same route_id, but different short/long names\n",
    "    >> select(_.calitp_itp_id, _.route_id, \n",
    "              _.route_short_name, _.route_long_name)\n",
    "    >> distinct()\n",
    "    >> collect()\n",
    ").to_parquet(\"./route_info.parquet\")\n",
    "\n",
    "\n",
    "agencies = (\n",
    "    tbl.gtfs_schedule.agency()\n",
    "    >> select(_.calitp_itp_id, _.agency_id, _.agency_name)\n",
    "    >> distinct()\n",
    "    >> collect()\n",
    ").to_parquet(\"./agencies.parquet\")\n",
    "'''\n",
    "\n",
    "stops = pd.read_parquet(\"./stops.parquet\")\n",
    "trips = pd.read_parquet(\"./trips.parquet\")\n",
    "route_info = pd.read_parquet(\"./route_info.parquet\")\n",
    "agencies = pd.read_parquet(\"./agencies.parquet\")\n",
    "routes = gpd.read_parquet(\"./routes.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2760b73d-bb31-4804-b4d7-c0a347d54e0b",
   "metadata": {},
   "source": [
    "## Routes\n",
    "\n",
    "Create a routes shapefile with line geometry, each row representing a route for an operator.\n",
    "\n",
    "* Link `shape_id` column back to route identifiers (route_id, route_name).\n",
    "* Link `calitp_itp_id` back to operator name.\n",
    "\n",
    "Traffic Signals - Arc gdb with all traffic signals maintained by Caltrans. They want to know which signals should have preemption, which % that should have it have it already enabled.\n",
    "\n",
    "### Add operator-routes that exist in `shapes.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2f8221-e1bb-4d22-a05c-ade4f058623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to attach route_info\n",
    "def attach_route_name(df, route_info_df):\n",
    "    # Attach route info from gtfs_schedule.routes, using route_id\n",
    "    routes = pd.merge(\n",
    "        df, \n",
    "        route_info_df,\n",
    "        on = [\"calitp_itp_id\", \"route_id\"],\n",
    "        # None that are left_only\n",
    "        how = \"inner\",\n",
    "        # route_id can have multiple long/short names\n",
    "        validate = \"m:m\",\n",
    "    )\n",
    "\n",
    "    return routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0196e4d8-e2a4-4f44-bcd4-7de765c22d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Use geography_utils to assemble routes from shapes.txt\n",
    "ITP_ID_LIST = list(agencies.calitp_itp_id.unique())\n",
    "\n",
    "routes = (geography_utils.make_routes_shapefile(\n",
    "            ITP_ID_LIST, CRS = geography_utils.WGS84, \n",
    "            alternate_df=None)\n",
    "          .to_parquet(\"./routes.parquet\")\n",
    "         )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e2c6c1-11db-4b12-8fea-e632d0b457f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "routes1 = pd.merge(\n",
    "    routes,\n",
    "    trips,\n",
    "    on = [\"calitp_itp_id\", \"shape_id\"],\n",
    "    # There are shape_ids that are left_only (1,600 obs)\n",
    "    how = \"inner\",\n",
    "    validate = \"1:m\",\n",
    ")\n",
    "\n",
    "\n",
    "routes_part1 = attach_route_name(routes1, route_info)\n",
    "routes_part1.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92511268-cc36-4e31-9b8a-c3662fe2a87c",
   "metadata": {},
   "source": [
    "### Add operator-routes that aren't found in `shapes.txt`\n",
    "For agencies that don't publish `shapes.txt`, go to their `stops.txt`, string together stop sequences and draw a line through it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2665360-8eb7-401a-949c-256b4454d036",
   "metadata": {},
   "source": [
    "What's the difference between `list(missing_trips.calitp_itp_id.unique())` and `missing_trips.calitp_itp_id.unique().tolist()`?\n",
    "\n",
    "`list(missing_trips.calitp_itp_id.unique())` doesn't work with the loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe169c48-49a4-4b88-ac17-4e68b9544268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the stops that aren't in `shapes.txt`\n",
    "missing_trips = (\n",
    "    tbl.gtfs_schedule.trips()\n",
    "    >> select(_.calitp_itp_id, _.route_id, _.shape_id, _.trip_id)\n",
    "    >> distinct()\n",
    "    >> collect()\n",
    "    >> filter(~_.shape_id.isin(routes_part1.shape_id))\n",
    ")\n",
    "\n",
    "missing_trips.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f52bd9-b2d6-48d7-b11a-d1b038f3ac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"# operators with missing trips: {missing_trips.calitp_itp_id.nunique()}\")\n",
    "print(f\"operators: {list(missing_trips.calitp_itp_id.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f2f5e2-a0ec-4ad2-84ca-c05b923f960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_missing_stops(ITP_ID, missing_trips_df, stops_df):\n",
    "    df = (\n",
    "        tbl.gtfs_schedule.stop_times()\n",
    "        # Loop through individual operators, then do the join to find those trips\n",
    "        # until the issue that makes kernel restarts is fixed\n",
    "        >> filter(_.calitp_itp_id == ITP_ID)\n",
    "        >> select(_.calitp_itp_id, _.stop_id, _.stop_sequence, _.trip_id)\n",
    "        # Can't do isin without the collect()\n",
    "        # But collect() is what is making kernel restart / shutting down notebook\n",
    "        >> distinct()\n",
    "        >> collect()\n",
    "        >> inner_join(_, missing_trips_df, [\"calitp_itp_id\", \"trip_id\"])\n",
    "        >> inner_join(_, stops_df, [\"calitp_itp_id\", \"stop_id\"])\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0797ae-407f-485c-ab83-bf2d78a9b4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOP_ME = missing_trips.calitp_itp_id.unique().tolist()\n",
    "'''\n",
    "missing_trips_stops = pd.DataFrame()\n",
    "for ITP_ID in LOOP_ME:\n",
    "    df = grab_missing_stops(ITP_ID, missing_trips, stops)\n",
    "    \n",
    "    missing_trips_stops = (missing_trips_stops.append(df)\n",
    "                           .sort_values([\"calitp_itp_id\", \"trip_id\", \"stop_sequence\"])\n",
    "                           .reset_index(drop=True)\n",
    "                          )\n",
    "\n",
    "missing_trips_stops.to_parquet(\"./missing_trips_stops.parquet\")    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37174d1d-ac0c-4116-b689-decac560b25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "missing_trips_stops = pd.read_parquet(\"./missing_trips_stops.parquet\")\n",
    "\n",
    "# Rename colums to match what's used in geography_utils\n",
    "missing_trips_stops = missing_trips_stops.rename(\n",
    "    columns = {\"stop_lon\": \"shape_pt_lon\", \n",
    "              \"stop_lat\": \"shape_pt_lat\",\n",
    "               \"stop_sequence\": \"shape_pt_sequence\",\n",
    "              }\n",
    ")\n",
    "\n",
    "\n",
    "missing_trips_stops2 = geography_utils.make_routes_shapefile(\n",
    "    LOOP_ME, CRS = geography_utils.WGS84, alternate_df=missing_trips_stops)\n",
    "\n",
    "\n",
    "missing_trips_stops2.to_parquet(\"./missing_routes.parquet\")\n",
    "'''\n",
    "\n",
    "missing_trips_stops2 = gpd.read_parquet(\"./missing_routes.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3fe7f0-c24d-409c-816c-a8d9d3532f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "routes2 = pd.merge(\n",
    "    missing_trips_stops2,\n",
    "    missing_trips_stops[[\"calitp_itp_id\", \"route_id\", \"shape_id\"]].drop_duplicates(),\n",
    "    on = [\"calitp_itp_id\", \"shape_id\"],\n",
    "    how = \"inner\",\n",
    "    validate = \"1:m\",\n",
    ")\n",
    "\n",
    "routes_part2 = attach_route_name(routes2, route_info)\n",
    "routes_part2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707f4b9e-4bd5-4be3-a4b0-ef06dde17bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `trips` table to merge `shape_id` to `route_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7a21e9-d076-47d2-8281-c4639597b4b3",
   "metadata": {},
   "source": [
    "## Stops\n",
    "\n",
    "Create a stops shapefile with point geometry, each row representing a stop for an operator-route.\n",
    "\n",
    "* Keep `lat`, `lon` columns as numeric, as well as `geometry` column\n",
    "* Link `stop_id` column back to stop identifiers (route_id, route_name, stop_code, stop_name).\n",
    "* Link calitp_itp_id back to operator name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57554efd-b01d-4c43-90ae-a23dae64188e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "stops = pd.read_parquet(\"./stops.parquet\")\n",
    "\n",
    "stops = geography_utils.create_point_geometry(stops, \n",
    "                        longitude_col = \"stop_lon\", \n",
    "                        latitude_col = \"stop_lat\", \n",
    "                        crs = geography_utils.WGS84\n",
    "                        )\n",
    "\n",
    "# There are a couple of duplicates when looking at ID-stop_id (but diff stop_code)\n",
    "# Drop these, since stop_id is used to merge with route_id\n",
    "stops = (stops\n",
    "         .sort_values([\"calitp_itp_id\", \"stop_id\", \"stop_code\"])\n",
    "         .drop_duplicates(subset=[\"calitp_itp_id\", \"stop_id\"])\n",
    "         .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "stops.to_parquet(\"./stops_with_geom.parquet\")\n",
    "'''\n",
    "\n",
    "stops = gpd.read_parquet(\"./stops_with_geom.parquet\")\n",
    "stops.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781cef2c-1089-4f2e-82ea-36b71c713f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "stops_with_route = (\n",
    "    tbl.gtfs_schedule.stop_times()    \n",
    "    >> select(_.calitp_itp_id, _.stop_id, _.trip_id)\n",
    "    # join on trips table using trip_id to get route_id\n",
    "    >> inner_join(_, \n",
    "                  (tbl.gtfs_schedule.trips()\n",
    "                   >> select(_.calitp_itp_id, _.route_id, _.trip_id)\n",
    "                  ),\n",
    "                  [\"calitp_itp_id\", \"trip_id\"]\n",
    "                 )\n",
    "    # Keep stop_id and route_id, no longer need trip info\n",
    "    >> select(_.calitp_itp_id, _.stop_id, _.route_id)\n",
    "    >> distinct()\n",
    "    >> collect()\n",
    ")\n",
    "stops_with_route.to_parquet(\"./stops_with_route_id\")\n",
    "\n",
    "'''\n",
    "stops_with_route = pd.read_parquet(\"./stops_with_route_id\")\n",
    "\n",
    "stops_with_route.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e44e3f-d760-4cb0-8269-faec851ae174",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_with_route2 = pd.merge(\n",
    "    stops,\n",
    "    stops_with_route,\n",
    "    on = [\"calitp_itp_id\", \"stop_id\"],\n",
    "    # About 6,000 rows that are left_only (stop_id) not linked with route\n",
    "    # Drop these, we want full information\n",
    "    how = \"inner\",\n",
    "    validate = \"1:m\",\n",
    ")\n",
    "\n",
    "stops_with_route2.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59041cba-89f8-4a6f-aef0-d406156bc9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_with_route3 = pd.merge(\n",
    "    stops_with_route2,\n",
    "    route_info,\n",
    "    on = [\"calitp_itp_id\", \"route_id\"],\n",
    "    # 121 obs that are left_only , keep these (have route_id, but no names associated)\n",
    "    how = \"left\",\n",
    "    # many on left is expected\n",
    "    # many on right is because there are some route_ids with different long/short names\n",
    "    validate = \"m:m\",\n",
    ")\n",
    "\n",
    "stops_with_route3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5a16ce-965b-4b57-a3f7-7f45437d2e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "agencies = pd.read_parquet(\"./agencies.parquet\")\n",
    "agencies.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277ee3a1-3f53-4bfb-b9c7-09d6f2834e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn df from long, and condense values into list\n",
    "# They'll want to look at stops by ID, but see the list of agencies it's associated with\n",
    "agencies2 = (agencies.groupby(\"calitp_itp_id\")\n",
    "             .agg(pd.Series.tolist)\n",
    "             .reset_index()\n",
    "             .rename(columns = {\n",
    "                 \"agency_id\": \"agency_id_list\",\n",
    "                 \"agency_name\": \"agency_name_list\",\n",
    "             })\n",
    "            )\n",
    "\n",
    "agencies2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4945cbbe-0f32-4990-b58d-7190298bfaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_with_route4 = pd.merge(\n",
    "    stops_with_route3,\n",
    "    agencies2,\n",
    "    on = \"calitp_itp_id\",\n",
    "    how = \"left\",\n",
    "    validate = \"m:1\",\n",
    ")\n",
    "\n",
    "stops_with_route4.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e66017c-7d36-4775-a54a-0ebfaad51265",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
