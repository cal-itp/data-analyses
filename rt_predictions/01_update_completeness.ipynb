{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bf54534-7eb0-4c98-b202-03cedeea5923",
   "metadata": {},
   "source": [
    "# Metric 1: Update Completeness\n",
    "\n",
    "\n",
    "### Rabbit Hole\n",
    "* `_extract_ts_local` doesn't always lead up to the stop's actual arrival, or even the max(stop's predicted arrival). If we stop asking, should we penalize? \n",
    "* Right now, we'll only count the trip updates for as much as we're asking.\n",
    "* If `_extract_ts` is not present, we're not asking, then that's a different issue.\n",
    "* Notice that if we subset to prediction durations, we might lose a lot of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f69b0e8-b173-40e2-8aa6-9b7dfb88b7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/dask_geopandas/backends.py:13: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import utils\n",
    "from segment_speed_utils.project_vars import (PREDICTIONS_GCS, \n",
    "                                              analysis_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53634e49-a173-4c86-beee-6dc8dc0fcb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atleast2_updates_by_trip_stop(\n",
    "    df: pd.DataFrame,\n",
    "    timestamp_col: str = \"_extract_ts_local\",\n",
    "    metric_timestamp_col: str = \"trip_update_timestamp_local\"\n",
    ") -> pd.DataFrame: \n",
    "    \"\"\"\n",
    "    For every trip-stop-minute combination,\n",
    "    count the number of unique trip_update_timestamps.\n",
    "    (Checked that this is 3 max).\n",
    "    If that minute has at least 2, flag that as passing.\n",
    "    \n",
    "    Sum up the number that of passing for that stop and \n",
    "    calculate the percent. The denominator is the number of \n",
    "    trip_min_elapsed.\n",
    "    \n",
    "    Note: size here used to count number of rows as denominator.\n",
    "    But, if we are not asking for predictions (`_extract_ts`), \n",
    "    we are also not going to penalize operator for not having predictions\n",
    "    leading up to the stop.\n",
    "    \"\"\"\n",
    "    all_stop_cols = [\n",
    "        \"gtfs_dataset_key\", \"_gtfs_dataset_name\", \n",
    "        \"service_date\", \n",
    "        \"shape_id\", \"route_id\",\n",
    "        \"trip_id\", \n",
    "        \"stop_id\", \"stop_sequence\",\n",
    "        \"scheduled_arrival\", \"actual_stop_arrival_pacific\", \n",
    "    ]\n",
    "    minute_cols = [f\"{timestamp_col}_hour\", f\"{timestamp_col}_min\"]\n",
    "    \n",
    "    # Count for every stop-min, how many unique trip updates\n",
    "    df2 = (df.groupby(all_stop_cols + minute_cols)\n",
    "           .agg({metric_timestamp_col: \"nunique\"})\n",
    "           .reset_index()\n",
    "    )\n",
    "    \n",
    "    # 1 if it has more than 2 updates, 0 otherwise.\n",
    "    # Easier to sum and calculate percent.\n",
    "    df2 = df2.assign(\n",
    "        atleast2_trip_updates = df2.apply(\n",
    "            lambda x: 1 if x[metric_timestamp_col] >= 2\n",
    "            else 0, axis=1)\n",
    "    )    \n",
    "    \n",
    "    # Size: gets us number of rows for that stop\n",
    "    df3 = (df2.groupby(all_stop_cols)\n",
    "           .agg({\n",
    "               f\"{timestamp_col}_hour\": \"size\",\n",
    "               \"atleast2_trip_updates\": \"sum\"})\n",
    "           .reset_index()\n",
    "          ).rename(columns = {\n",
    "            f\"{timestamp_col}_hour\": \"trip_min_elapsed\"\n",
    "    })\n",
    "    \n",
    "    df3 = df3.assign(\n",
    "        pct_update_complete = df3.atleast2_trip_updates.divide(\n",
    "            df3.trip_min_elapsed)\n",
    "    ) \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0b71b52-22e5-49d5-b9f9-559b7768e42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_completeness_metric(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Start with assembled RT stop_time_updates with \n",
    "    scheduled stop_times and also final_trip_updates columns.\n",
    "    \n",
    "    For a given stop, if there are predictions/rows present because\n",
    "    of _extract_ts after the \"actual stop arrival\" (final_trip_updates), \n",
    "    exclude those.\n",
    "    \"\"\"\n",
    "    # Set timestamp columns here, in case these are not correct\n",
    "    # Row should be derived from _extract_ts (convert to minute combinations)\n",
    "    # along with stop identifiers\n",
    "    # For metric, we want to get # unique trip updates\n",
    "    timestamp_col = \"_extract_ts_local\"\n",
    "    metric_col = \"trip_update_timestamp_local\"\n",
    "  \n",
    "    df2 = utils.exclude_predictions_after_actual_stop_arrival(\n",
    "        df, timestamp_col)\n",
    "    df3 = utils.parse_hour_min(df2, [timestamp_col])\n",
    "    \n",
    "    df4 = atleast2_updates_by_trip_stop(\n",
    "        df3, \n",
    "        timestamp_col,\n",
    "        metric_col\n",
    "    )\n",
    "    \n",
    "    return df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee7059f1-7989-4a9f-a6c4-e71b99447d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Anaheim Resort TripUpdates',\n",
       "       'Bay Area 511 Dumbarton Express TripUpdates',\n",
       "       'Bay Area 511 Fairfield and Suisun Transit TripUpdates'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\n",
    "    f\"{PREDICTIONS_GCS}rt_sched_stop_times_{analysis_date}.parquet\", \n",
    ")\n",
    "df._gtfs_dataset_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffbaf26d-3437-49c8-bd5b-56b79a607d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_trip_stop = update_completeness_metric(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42639d61-b284-4b8e-8956-0a5696df6152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_descriptives(df: pd.DataFrame, \n",
    "                       operator: str,\n",
    "                       cols_to_describe: list):\n",
    "    print(f\"------------- {operator}-------------\")\n",
    "    subset_df = df[df._gtfs_dataset_name==operator] \n",
    "    \n",
    "    for c in cols_to_describe:\n",
    "        print(subset_df[c].describe())\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d83eeb2-d910-449b-8034-8917268fe07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- Anaheim Resort TripUpdates-------------\n",
      "count    265.000000\n",
      "mean      23.698113\n",
      "std       18.645197\n",
      "min        0.000000\n",
      "25%        7.000000\n",
      "50%       21.000000\n",
      "75%       38.000000\n",
      "max       60.000000\n",
      "Name: atleast2_trip_updates, dtype: float64\n",
      "\n",
      "\n",
      "count    265.000000\n",
      "mean      24.603774\n",
      "std       18.775528\n",
      "min        1.000000\n",
      "25%        8.000000\n",
      "50%       22.000000\n",
      "75%       38.000000\n",
      "max       61.000000\n",
      "Name: trip_min_elapsed, dtype: float64\n",
      "\n",
      "\n",
      "count    265.000000\n",
      "mean       0.927220\n",
      "std        0.124070\n",
      "min        0.000000\n",
      "25%        0.941176\n",
      "50%        0.962963\n",
      "75%        0.983607\n",
      "max        1.000000\n",
      "Name: pct_update_complete, dtype: float64\n",
      "\n",
      "\n",
      "------------- Bay Area 511 Dumbarton Express TripUpdates-------------\n",
      "count    1424.000000\n",
      "mean       47.509831\n",
      "std        16.144330\n",
      "min         6.000000\n",
      "25%        39.000000\n",
      "50%        55.000000\n",
      "75%        60.000000\n",
      "max        60.000000\n",
      "Name: atleast2_trip_updates, dtype: float64\n",
      "\n",
      "\n",
      "count    1424.000000\n",
      "mean       48.806180\n",
      "std        16.103594\n",
      "min         6.000000\n",
      "25%        39.000000\n",
      "50%        56.000000\n",
      "75%        61.000000\n",
      "max        61.000000\n",
      "Name: trip_min_elapsed, dtype: float64\n",
      "\n",
      "\n",
      "count    1424.000000\n",
      "mean        0.967361\n",
      "std         0.030350\n",
      "min         0.818182\n",
      "25%         0.962788\n",
      "50%         0.982143\n",
      "75%         0.983607\n",
      "max         1.000000\n",
      "Name: pct_update_complete, dtype: float64\n",
      "\n",
      "\n",
      "------------- Bay Area 511 Fairfield and Suisun Transit TripUpdates-------------\n",
      "count    1278.000000\n",
      "mean       34.063380\n",
      "std        12.502525\n",
      "min         6.000000\n",
      "25%        24.000000\n",
      "50%        32.000000\n",
      "75%        44.000000\n",
      "max        60.000000\n",
      "Name: atleast2_trip_updates, dtype: float64\n",
      "\n",
      "\n",
      "count    1278.000000\n",
      "mean       35.369327\n",
      "std        12.512662\n",
      "min         8.000000\n",
      "25%        25.000000\n",
      "50%        33.000000\n",
      "75%        46.000000\n",
      "max        61.000000\n",
      "Name: trip_min_elapsed, dtype: float64\n",
      "\n",
      "\n",
      "count    1278.000000\n",
      "mean        0.957803\n",
      "std         0.024041\n",
      "min         0.750000\n",
      "25%         0.949153\n",
      "50%         0.964286\n",
      "75%         0.974359\n",
      "max         1.000000\n",
      "Name: pct_update_complete, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = [\n",
    "    \"atleast2_trip_updates\", \n",
    "    \"trip_min_elapsed\",\n",
    "    \"pct_update_complete\"]\n",
    "\n",
    "for i in by_trip_stop._gtfs_dataset_name.unique():\n",
    "    quick_descriptives(by_trip_stop, i, cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d4e9de-5350-4625-bec4-af1f9d247582",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
