{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bf54534-7eb0-4c98-b202-03cedeea5923",
   "metadata": {},
   "source": [
    "# Metric 1: Update Completeness\n",
    "\n",
    "\n",
    "### Rabbit Hole\n",
    "* `_extract_ts_local` doesn't always lead up to the stop's actual arrival, or even the max(stop's predicted arrival). If we stop asking, should we penalize? \n",
    "* Right now, we'll only count the trip updates for as much as we're asking.\n",
    "* If `_extract_ts` is not present, we're not asking, then that's a different issue.\n",
    "* Notice that if we subset to prediction durations, we might lose a lot of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f69b0e8-b173-40e2-8aa6-9b7dfb88b7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "\n",
    "#import dask.dataframe as dd\n",
    "#import dask_geopandas as dg\n",
    "#import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "import utils\n",
    "from segment_speed_utils.project_vars import (PREDICTIONS_GCS, \n",
    "                                              analysis_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53634e49-a173-4c86-beee-6dc8dc0fcb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stop_cols = [\n",
    "    \"gtfs_dataset_key\", \"_gtfs_dataset_name\", \n",
    "    \"service_date\", \n",
    "    \"shape_id\", \"route_id\",\n",
    "    \"trip_id\", \n",
    "    \"stop_id\", \"stop_sequence\",\n",
    "    \"scheduled_arrival\", \"actual_stop_arrival_pacific\", \n",
    "]\n",
    "\n",
    "def atleast2_updates_by_trip_stop(\n",
    "    df: pd.DataFrame,\n",
    "    timestamp_col: str = \"_extract_ts_local\",\n",
    "    metric_timestamp_col: str = \"trip_update_timestamp_local\"\n",
    ") -> pd.DataFrame: \n",
    "    \"\"\"\n",
    "    For every trip-stop-minute combination,\n",
    "    count the number of unique trip_update_timestamps.\n",
    "    (Checked that this is 3 max).\n",
    "    If that minute has at least 2, flag that as passing.\n",
    "    \n",
    "    Sum up the number that of passing for that stop and \n",
    "    calculate the percent. The denominator is the number of \n",
    "    trip_min_elapsed.\n",
    "    \n",
    "    Note: size here used to count number of rows as denominator.\n",
    "    But, if we are not asking for predictions (`_extract_ts`), \n",
    "    we are also not going to penalize operator for not having predictions\n",
    "    leading up to the stop.\n",
    "    \"\"\"\n",
    "    minute_cols = [f\"{timestamp_col}_hour\", f\"{timestamp_col}_min\"]\n",
    "    \n",
    "    # Count for every stop-min, how many unique trip updates\n",
    "    df2 = (df.groupby(all_stop_cols + minute_cols)\n",
    "           .agg({metric_timestamp_col: \"nunique\"})\n",
    "           .reset_index()\n",
    "    )\n",
    "    \n",
    "    # 1 if it has more than 2 updates, 0 otherwise.\n",
    "    # Easier to sum and calculate percent.\n",
    "    df2 = df2.assign(\n",
    "        atleast2_trip_updates = df2.apply(\n",
    "            lambda x: 1 if x[metric_timestamp_col] >= 2\n",
    "            else 0, axis=1)\n",
    "    )    \n",
    "    \n",
    "    # Size: gets us number of rows for that stop\n",
    "    df3 = (df2.groupby(all_stop_cols)\n",
    "           .agg({\n",
    "               f\"{timestamp_col}_hour\": \"size\",\n",
    "               \"atleast2_trip_updates\": \"sum\"})\n",
    "           .reset_index()\n",
    "          ).rename(columns = {\n",
    "            f\"{timestamp_col}_hour\": \"trip_min_elapsed\"\n",
    "    })\n",
    "    \n",
    "    df3 = df3.assign(\n",
    "        pct_update_complete = df3.atleast2_trip_updates.divide(\n",
    "            df3.trip_min_elapsed)\n",
    "    ) \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b71b52-22e5-49d5-b9f9-559b7768e42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_completeness_metric(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Start with assembled RT stop_time_updates with \n",
    "    scheduled stop_times and also final_trip_updates columns.\n",
    "    \n",
    "    For a given stop, if there are predictions/rows present because\n",
    "    of _extract_ts after the \"actual stop arrival\" (final_trip_updates), \n",
    "    exclude those.\n",
    "    \"\"\"\n",
    "    # Set timestamp columns here, in case these are not correct\n",
    "    # Row should be derived from _extract_ts (convert to minute combinations)\n",
    "    # along with stop identifiers\n",
    "    # For metric, we want to get # unique trip updates\n",
    "    timestamp_col = \"_extract_ts_local\"\n",
    "    metric_col = \"trip_update_timestamp_local\"\n",
    "  \n",
    "    df2 = utils.exclude_predictions_after_actual_stop_arrival(\n",
    "        df, timestamp_col)\n",
    "    df3 = utils.parse_hour_min(df2, [timestamp_col])\n",
    "    \n",
    "    df4 = atleast2_updates_by_trip_stop(\n",
    "        df3, \n",
    "        timestamp_col,\n",
    "        metric_col\n",
    "    )\n",
    "    \n",
    "    return df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7059f1-7989-4a9f-a6c4-e71b99447d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\n",
    "    \"rt_sched_stop_times.parquet\", \n",
    ")\n",
    "df._gtfs_dataset_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbaf26d-3437-49c8-bd5b-56b79a607d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_trip_stop = update_completeness_metric(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d83eeb2-d910-449b-8034-8917268fe07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_trip_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f3c311-54b5-4da2-9289-8a4e577958a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669edc32-1a76-49fd-b7a2-7db6636af901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581bb1f0-07a9-4115-bfa6-a47b8f177180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6b897e-ca87-4dd5-9dc7-9766d7d30f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def9baf7-1a0a-4ddb-954d-21dbe93f6324",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2.stop_sequence==3].scheduled_arrival.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b088de9-7cc9-43b8-aba9-f18ea1b90107",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2.stop_sequence==3].predicted_pacific.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe5803b-70d4-455b-9854-1a131eb8514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2.stop_sequence==3].actual_stop_arrival_pacific.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9732f69-7188-4ff8-aa51-6c4ebd0b4e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2.stop_sequence==3]._extract_ts_local.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b2edff-ce9b-43e3-9252-5b2d07baccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2.stop_sequence==3].trip_update_timestamp_local.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cc21af-ef8b-4926-b6c2-dffa7ce466ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c3dc0cd-e440-40fe-8d05-e5084be394fc",
   "metadata": {},
   "source": [
    "\"Actual\" stop arrivals appears really close together.\n",
    "\n",
    "If we care about `prediction_duration`, no rows will be kept because predictions within the `prediction_duration` do not exist. There are predictions for stop 4 when we're at stops 1, 2, and 3, but nothing between stop 3 and 4.\n",
    "\n",
    "Based on the query set up for final updates, we want to get the `max(arrival_time_pacific)` for each stop. Equivalently, this is would e `max(predicted_pacific)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7061987d-ad10-41b7-bee2-e3811e4b9a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    \"stop_sequence\", \"stop_id\", \n",
    "    \"predicted_pacific\",\n",
    "    \"_extract_ts_local\",\n",
    "    \"trip_update_timestamp_local\",\n",
    "    \"prior_stop_arrival_pacific\",\n",
    "    \"actual_stop_arrival_pacific\",\n",
    "]\n",
    "\n",
    "# Pick 1 trip\n",
    "df[(df.trip_id==one_trip) & \n",
    "   (df.stop_sequence == 3)\n",
    "  ][cols].sort_values(\n",
    "    [\"_extract_ts_local\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da0fae3-e396-4cd1-b284-607845cef977",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.trip_id==one_trip) & \n",
    "   (df.stop_sequence == 3) & \n",
    "   (df._extract_ts_local > df.prior_stop_arrival_pacific) & \n",
    "   (df._extract_ts_local <= df.actual_stop_arrival_pacific)\n",
    "  ][cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360295c1-89f1-4326-a10d-84d60ea1a5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7187cb-08c0-4ce6-a5a7-c4a1c7844900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the query, ignoring nulls and populating by\n",
    "# arrival_time, we do want to use the max(predicted arrival time) \n",
    "# for that stop\n",
    "max_predicted_prior = df[(df.trip_id==one_trip) & \n",
    "   (df.stop_sequence == 2)][cols].predicted_pacific.max()\n",
    "max_predicted_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c80475-c069-48dd-9306-075eb9105730",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.trip_id==one_trip) & \n",
    "   (df.stop_sequence == 3) #& \n",
    "   #(df._extract_ts_local > max_predicted_prior)\n",
    "  ][cols].trip_update_timestamp_local.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6462b568-3d41-4508-8610-934e08557e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.trip_id==one_trip) & \n",
    "   (df.stop_sequence == 3)\n",
    "  ][cols].actual_stop_arrival_pacific.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4974f05-4e2f-4be3-93de-2d0a11e5e333",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.trip_id==one_trip) & \n",
    "   (df.stop_sequence == 4)\n",
    "  ][cols].sort_values(\n",
    "    [\"_extract_ts_local\", \"stop_sequence\"]).prior_stop_arrival_pacific.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43a89b9-e034-4474-bf5b-34920a106740",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
