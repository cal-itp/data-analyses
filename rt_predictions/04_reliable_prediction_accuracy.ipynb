{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31d1d0dd-5bf8-4472-bfc6-2d5f3788e37f",
   "metadata": {},
   "source": [
    "# Metric 4: Reliable Prediction Accuracy\n",
    "\n",
    "Use this equation: \n",
    "\n",
    "-60ln(`Time to Prediction`+1.3) < `Prediction Error` < 60ln(`Time to Prediction`+1.5)\n",
    "\n",
    "## Rabbit Hole \n",
    "* time to prediction should be positive. Using `predicted arrival - _extract_ts` should yield positive time differences, but there are cases where negative time differences exists\n",
    "* negative time difference means the predicted arrival is earlier than the `_extract_ts`, which definitely can be possible in the case of a delayed bus\n",
    "* for now, just use absolute value to make sure it's positive\n",
    "\n",
    "Summary Levels\n",
    "* Route by hour of day/day of week\n",
    "* Stops by  hour of day/day of week\n",
    "* Route by stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "143cca80-0fca-425f-8b38-d33540e99e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/dask_geopandas/backends.py:13: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas\n"
     ]
    }
   ],
   "source": [
    "import numpy as  np\n",
    "import pandas as pd\n",
    "\n",
    "import utils\n",
    "from segment_speed_utils.project_vars import (PREDICTIONS_GCS, \n",
    "                                              analysis_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aac58f2-a72a-4970-9967-272710608e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\n",
    "    f\"{PREDICTIONS_GCS}rt_sched_stop_times_{analysis_date}.parquet\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41d9ae9b-ee6b-4b12-afde-ffb0a5c5f0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_prediction_accuracy_parts(\n",
    "    df: pd.DataFrame,\n",
    "    metric_col: str = \"reliable_accuracy\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Time to prediction: current time until predicted stop arrival, \n",
    "    in minutes. \n",
    "    To be positive, we'll flip this, predicted arrival - extract_ts.\n",
    "    \n",
    "    Prediction error: actual stop arrival - predicted stop arrival,\n",
    "    in seconds.\n",
    "    \n",
    "    Calculate metric:\n",
    "    lower_bound = -60 ln(Time to Prediction+1.3) \n",
    "    upper_bound = 60ln(Time to Prediction+1.5)\n",
    "    prediction_error = actual - predicted arrival \n",
    "    reliable_accuracy: 1 if prediction_error within [lower_bound, upper_bound],\n",
    "    and 0 if it's not.\n",
    "    \n",
    "    Future TODO: if we implement prediction score, we will need to score\n",
    "    the actual value (how close it is and also penalty), \n",
    "    not just dummy variable for yes/no.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.assign(\n",
    "        time_to_prediction_min = (\n",
    "            abs(df.predicted_pacific - df._extract_ts_local)\n",
    "            .dt.total_seconds().divide(60)),\n",
    "        prediction_error = (\n",
    "            (df.actual_stop_arrival_pacific - df.predicted_pacific)\n",
    "            .dt.total_seconds())\n",
    "    )\n",
    "\n",
    "    time_to_predic = df.time_to_prediction_min.to_numpy()\n",
    "    predic_error = df.prediction_error.to_numpy()\n",
    "    \n",
    "    lower_bound = -60 * np.log(time_to_predic + 1.3)\n",
    "    upper_bound = 60 * np.log(time_to_predic + 1.5)\n",
    "    \n",
    "    #https://stackoverflow.com/questions/45314494/is-there-a-nice-way-to-check-if-numpy-array-elements-are-within-a-range\n",
    "    acceptable_prediction = np.logical_and(\n",
    "        lower_bound < predic_error, \n",
    "        predic_error < upper_bound)\n",
    "    \n",
    "    df = df.assign(\n",
    "        metric_col = acceptable_prediction.astype(int)\n",
    "    ).rename(columns = {\"metric_col\": metric_col})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a45ae7c5-466f-4245-974a-b1967755cf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reliably_accurate_metric(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Start with assembled RT stop_time_updates with \n",
    "    scheduled stop_times and also final_trip_updates columns.\n",
    "    \n",
    "    For a given stop, if there are predictions present \n",
    "    for the same minute as the actual arrival or after, exclude these.\n",
    "    \n",
    "    Apply the equation and check if the prediction error \n",
    "    falls within certain bounds.\n",
    "    Get percent by dividing up predictions within the bounds over \n",
    "    all predictions for that stop.\n",
    "    \"\"\"\n",
    "    timestamp_col = \"_extract_ts_local\"\n",
    "    minute_cols = [f\"{timestamp_col}_hour\", f\"{timestamp_col}_min\"]\n",
    "    metric_col = \"reliable_accuracy\"\n",
    "    \n",
    "    all_stop_cols = [\n",
    "        \"gtfs_dataset_key\", \"_gtfs_dataset_name\", \n",
    "        \"service_date\", \n",
    "        \"shape_id\", \"route_id\",\n",
    "        \"trip_id\", \n",
    "        \"stop_id\", \"stop_sequence\",\n",
    "        \"scheduled_arrival\", \"actual_stop_arrival_pacific\", \n",
    "    ]\n",
    "\n",
    "    df2 = utils.exclude_predictions_at_actual_stop_arrival(df)\n",
    "    df2 = utils.exclude_predictions_after_actual_stop_arrival(\n",
    "        df2, timestamp_col)\n",
    "    \n",
    "    df2 = calculate_prediction_accuracy_parts(\n",
    "        df, \n",
    "        metric_col\n",
    "    )    \n",
    "    \n",
    "    df3 = utils.parse_hour_min(df2, [timestamp_col])\n",
    "    \n",
    "    df4 = (df3.groupby(all_stop_cols)\n",
    "       .agg({\n",
    "           f\"{timestamp_col}_hour\": \"size\",\n",
    "           metric_col: \"sum\"})\n",
    "       .reset_index()\n",
    "       .rename(columns = {\n",
    "           f\"{timestamp_col}_hour\": \"total_stop_predictions\",\n",
    "           metric_col: \"num_accurate_predictions\"})\n",
    "      )\n",
    "\n",
    "    df4[f\"pct_{metric_col}\"] = df4.num_accurate_predictions.divide(\n",
    "            df4.total_stop_predictions)\n",
    "    \n",
    "    \n",
    "    return df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebdf4655-78cd-412b-a705-cc259784caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_trip_stop = reliably_accurate_metric(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cf78ec0-55b4-44f8-9323-7342146bff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_descriptives(df: pd.DataFrame, \n",
    "                       operator: str,\n",
    "                       cols_to_describe: list):\n",
    "    print(f\"------------- {operator}-------------\")\n",
    "    subset_df = df[df._gtfs_dataset_name==operator] \n",
    "    \n",
    "    for c in cols_to_describe:\n",
    "        print(subset_df[c].describe())\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef095311-97f5-4775-bdef-9c367051ce57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- Anaheim Resort TripUpdates-------------\n",
      "count    2041.000000\n",
      "mean       42.042626\n",
      "std        53.035991\n",
      "min         0.000000\n",
      "25%         1.000000\n",
      "50%        29.000000\n",
      "75%        58.000000\n",
      "max       517.000000\n",
      "Name: num_accurate_predictions, dtype: float64\n",
      "\n",
      "\n",
      "count    2041.000000\n",
      "mean       96.505145\n",
      "std        72.931045\n",
      "min         1.000000\n",
      "25%        40.000000\n",
      "50%        83.000000\n",
      "75%       120.000000\n",
      "max       517.000000\n",
      "Name: total_stop_predictions, dtype: float64\n",
      "\n",
      "\n",
      "count    2041.000000\n",
      "mean        0.454093\n",
      "std         0.354258\n",
      "min         0.000000\n",
      "25%         0.013652\n",
      "50%         0.458333\n",
      "75%         0.791667\n",
      "max         1.000000\n",
      "Name: pct_reliable_accuracy, dtype: float64\n",
      "\n",
      "\n",
      "------------- Bay Area 511 Dumbarton Express TripUpdates-------------\n",
      "count    1490.000000\n",
      "mean       76.927517\n",
      "std        68.559613\n",
      "min         1.000000\n",
      "25%        18.000000\n",
      "50%        54.000000\n",
      "75%       125.750000\n",
      "max       294.000000\n",
      "Name: num_accurate_predictions, dtype: float64\n",
      "\n",
      "\n",
      "count    1490.000000\n",
      "mean      245.918121\n",
      "std       107.953924\n",
      "min         6.000000\n",
      "25%       170.000000\n",
      "50%       249.000000\n",
      "75%       312.000000\n",
      "max       692.000000\n",
      "Name: total_stop_predictions, dtype: float64\n",
      "\n",
      "\n",
      "count    1490.000000\n",
      "mean        0.372663\n",
      "std         0.345104\n",
      "min         0.002105\n",
      "25%         0.081366\n",
      "50%         0.254687\n",
      "75%         0.598546\n",
      "max         1.000000\n",
      "Name: pct_reliable_accuracy, dtype: float64\n",
      "\n",
      "\n",
      "------------- Bay Area 511 Fairfield and Suisun Transit TripUpdates-------------\n",
      "count    1289.000000\n",
      "mean      108.227308\n",
      "std        55.452951\n",
      "min         1.000000\n",
      "25%        62.000000\n",
      "50%       129.000000\n",
      "75%       137.000000\n",
      "max       321.000000\n",
      "Name: num_accurate_predictions, dtype: float64\n",
      "\n",
      "\n",
      "count    1289.000000\n",
      "mean      150.430566\n",
      "std        31.213426\n",
      "min         6.000000\n",
      "25%       136.000000\n",
      "50%       142.000000\n",
      "75%       151.000000\n",
      "max       334.000000\n",
      "Name: total_stop_predictions, dtype: float64\n",
      "\n",
      "\n",
      "count    1289.000000\n",
      "mean        0.733704\n",
      "std         0.345512\n",
      "min         0.006211\n",
      "25%         0.440789\n",
      "50%         0.943662\n",
      "75%         1.000000\n",
      "max         1.000000\n",
      "Name: pct_reliable_accuracy, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = [\n",
    "    \"num_accurate_predictions\", \n",
    "    \"total_stop_predictions\",\n",
    "    \"pct_reliable_accuracy\"]\n",
    "\n",
    "for i in by_trip_stop._gtfs_dataset_name.unique():\n",
    "    quick_descriptives(by_trip_stop, i, cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ad805d-3097-4a54-9deb-19f953d56f22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
