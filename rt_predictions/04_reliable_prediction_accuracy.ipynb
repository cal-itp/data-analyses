{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31d1d0dd-5bf8-4472-bfc6-2d5f3788e37f",
   "metadata": {},
   "source": [
    "# Metric 4: Reliable Prediction Accuracy\n",
    "\n",
    "Use this equation: \n",
    "\n",
    "-60ln(`Time to Prediction`+1.3) < `Prediction Error` < 60ln(`Time to Prediction`+1.5)\n",
    "\n",
    "## Rabbit Hole \n",
    "* time to prediction should be positive. Using `predicted arrival - _extract_ts` should yield positive time differences, but there are cases where negative time differences exists\n",
    "* negative time difference means the predicted arrival is earlier than the `_extract_ts`, which definitely can be possible in the case of a delayed bus\n",
    "* for now, just use absolute value to make sure it's positive\n",
    "\n",
    "Summary Levels\n",
    "* Route by hour of day/day of week\n",
    "* Stops by  hour of day/day of week\n",
    "* Route by stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "143cca80-0fca-425f-8b38-d33540e99e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/dask_geopandas/backends.py:13: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas\n"
     ]
    }
   ],
   "source": [
    "import numpy as  np\n",
    "import pandas as pd\n",
    "\n",
    "import utils\n",
    "from segment_speed_utils.project_vars import (PREDICTIONS_GCS, \n",
    "                                              analysis_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aac58f2-a72a-4970-9967-272710608e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\n",
    "    f\"{PREDICTIONS_GCS}rt_sched_stop_times_{analysis_date}.parquet\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41d9ae9b-ee6b-4b12-afde-ffb0a5c5f0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_prediction_accuracy_parts(\n",
    "    df: pd.DataFrame,\n",
    "    metric_col: str = \"reliable_accuracy\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Time to prediction: current time until predicted stop arrival, \n",
    "    in minutes. \n",
    "    To be positive, we'll flip this, predicted arrival - extract_ts.\n",
    "    \n",
    "    Prediction error: actual stop arrival - predicted stop arrival,\n",
    "    in seconds.\n",
    "    \n",
    "    Calculate metric:\n",
    "    lower_bound = -60 ln(Time to Prediction+1.3) \n",
    "    upper_bound = 60ln(Time to Prediction+1.5)\n",
    "    prediction_error = actual - predicted arrival \n",
    "    reliable_accuracy: 1 if prediction_error within [lower_bound, upper_bound],\n",
    "    and 0 if it's not.\n",
    "    \n",
    "    Future TODO: if we implement prediction score, we will need to score\n",
    "    the actual value (how close it is and also penalty), \n",
    "    not just dummy variable for yes/no.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.assign(\n",
    "        time_to_prediction_min = (\n",
    "            abs(df.predicted_pacific - df._extract_ts_local)\n",
    "            .dt.total_seconds().divide(60)),\n",
    "        prediction_error = (\n",
    "            (df.actual_stop_arrival_pacific - df.predicted_pacific)\n",
    "            .dt.total_seconds())\n",
    "    )\n",
    "\n",
    "    time_to_predic = df.time_to_prediction_min.to_numpy()\n",
    "    predic_error = df.prediction_error.to_numpy()\n",
    "    \n",
    "    lower_bound = -60 * np.log(time_to_predic + 1.3)\n",
    "    upper_bound = 60 * np.log(time_to_predic + 1.5)\n",
    "    \n",
    "    #https://stackoverflow.com/questions/45314494/is-there-a-nice-way-to-check-if-numpy-array-elements-are-within-a-range\n",
    "    acceptable_prediction = np.logical_and(\n",
    "        lower_bound < predic_error, \n",
    "        predic_error < upper_bound)\n",
    "    \n",
    "    df = df.assign(\n",
    "        metric_col = acceptable_prediction.astype(int)\n",
    "    ).rename(columns = {\"metric_col\": metric_col})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a45ae7c5-466f-4245-974a-b1967755cf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reliably_accurate_metric(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Start with assembled RT stop_time_updates with \n",
    "    scheduled stop_times and also final_trip_updates columns.\n",
    "    \n",
    "    For a given stop, if there are predictions present \n",
    "    for the same minute as the actual arrival or after, exclude these.\n",
    "    \n",
    "    Apply the equation and check if the prediction error \n",
    "    falls within certain bounds.\n",
    "    Get percent by dividing up predictions within the bounds over \n",
    "    all predictions for that stop.\n",
    "    \"\"\"\n",
    "    timestamp_col = \"_extract_ts_local\"\n",
    "    minute_cols = [f\"{timestamp_col}_hour\", f\"{timestamp_col}_min\"]\n",
    "    metric_col = \"reliable_accuracy\"\n",
    "    \n",
    "    all_stop_cols = [\n",
    "        \"gtfs_dataset_key\", \"_gtfs_dataset_name\", \n",
    "        \"service_date\", \n",
    "        \"shape_id\", \"route_id\",\n",
    "        \"trip_id\", \n",
    "        \"stop_id\", \"stop_sequence\",\n",
    "        \"scheduled_arrival\", \"actual_stop_arrival_pacific\", \n",
    "    ]\n",
    "\n",
    "    df2 = utils.exclude_predictions_at_actual_stop_arrival(df)\n",
    "    df2 = utils.exclude_predictions_after_actual_stop_arrival(\n",
    "        df2, timestamp_col)\n",
    "    \n",
    "    df2 = calculate_prediction_accuracy_parts(\n",
    "        df, \n",
    "        metric_col\n",
    "    )    \n",
    "    \n",
    "    df3 = utils.parse_hour_min(df2, [timestamp_col])\n",
    "    \n",
    "    df4 = (df3.groupby(all_stop_cols)\n",
    "       .agg({\n",
    "           f\"{timestamp_col}_hour\": \"size\",\n",
    "           metric_col: \"sum\"})\n",
    "       .reset_index()\n",
    "       .rename(columns = {\n",
    "           f\"{timestamp_col}_hour\": \"total_stop_predictions\",\n",
    "           metric_col: \"num_accurate_predictions\"})\n",
    "      )\n",
    "\n",
    "    df4[f\"pct_{metric_col}\"] = df4.num_accurate_predictions.divide(\n",
    "            df4.total_stop_predictions)\n",
    "    \n",
    "    \n",
    "    return df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebdf4655-78cd-412b-a705-cc259784caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_trip_stop = reliably_accurate_metric(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cf78ec0-55b4-44f8-9323-7342146bff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_descriptives(df: pd.DataFrame, \n",
    "                       operator: str,\n",
    "                       cols_to_describe: list):\n",
    "    print(f\"------------- {operator}-------------\")\n",
    "    subset_df = df[df._gtfs_dataset_name==operator] \n",
    "    \n",
    "    for c in cols_to_describe:\n",
    "        print(subset_df[c].describe())\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef095311-97f5-4775-bdef-9c367051ce57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- Anaheim Resort TripUpdates-------------\n",
      "count    265.000000\n",
      "mean      18.792453\n",
      "std       33.366740\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%       17.000000\n",
      "max      142.000000\n",
      "Name: num_accurate_predictions, dtype: float64\n",
      "\n",
      "\n",
      "count    265.000000\n",
      "mean      72.822642\n",
      "std       55.296743\n",
      "min        2.000000\n",
      "25%       23.000000\n",
      "50%       64.000000\n",
      "75%      113.000000\n",
      "max      181.000000\n",
      "Name: total_stop_predictions, dtype: float64\n",
      "\n",
      "\n",
      "count    265.000000\n",
      "mean       0.282106\n",
      "std        0.396125\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.605263\n",
      "max        1.000000\n",
      "Name: pct_reliable_accuracy, dtype: float64\n",
      "\n",
      "\n",
      "------------- Bay Area 511 Dumbarton Express TripUpdates-------------\n",
      "count    1424.000000\n",
      "mean       40.735955\n",
      "std        58.752496\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         1.000000\n",
      "75%        65.000000\n",
      "max       233.000000\n",
      "Name: num_accurate_predictions, dtype: float64\n",
      "\n",
      "\n",
      "count    1424.000000\n",
      "mean      145.768258\n",
      "std        52.390296\n",
      "min        18.000000\n",
      "25%       117.000000\n",
      "50%       167.000000\n",
      "75%       181.000000\n",
      "max       306.000000\n",
      "Name: total_stop_predictions, dtype: float64\n",
      "\n",
      "\n",
      "count    1424.000000\n",
      "mean        0.296268\n",
      "std         0.390797\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.013812\n",
      "75%         0.548836\n",
      "max         1.000000\n",
      "Name: pct_reliable_accuracy, dtype: float64\n",
      "\n",
      "\n",
      "------------- Bay Area 511 Fairfield and Suisun Transit TripUpdates-------------\n",
      "count    1278.000000\n",
      "mean       73.353678\n",
      "std        53.018341\n",
      "min         0.000000\n",
      "25%        20.000000\n",
      "50%        77.000000\n",
      "75%       112.000000\n",
      "max       181.000000\n",
      "Name: num_accurate_predictions, dtype: float64\n",
      "\n",
      "\n",
      "count    1278.000000\n",
      "mean      102.964789\n",
      "std        37.540700\n",
      "min        20.000000\n",
      "25%        73.000000\n",
      "50%        97.000000\n",
      "75%       134.000000\n",
      "max       181.000000\n",
      "Name: total_stop_predictions, dtype: float64\n",
      "\n",
      "\n",
      "count    1278.000000\n",
      "mean        0.703682\n",
      "std         0.421394\n",
      "min         0.000000\n",
      "25%         0.217513\n",
      "50%         1.000000\n",
      "75%         1.000000\n",
      "max         1.000000\n",
      "Name: pct_reliable_accuracy, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = [\n",
    "    \"num_accurate_predictions\", \n",
    "    \"total_stop_predictions\",\n",
    "    \"pct_reliable_accuracy\"]\n",
    "\n",
    "for i in by_trip_stop._gtfs_dataset_name.unique():\n",
    "    quick_descriptives(by_trip_stop, i, cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ad805d-3097-4a54-9deb-19f953d56f22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
