{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77106c12-82aa-4be4-8d9c-e66fafec4d67",
   "metadata": {},
   "source": [
    "## General function to clean up data from various grants\n",
    "TO DO\n",
    "* Switch City of Berkeley to Berkeley City. https://github.com/cal-itp/data-analyses/blob/main/Agreement_Overlap/add_dla.ipynb\n",
    "* De duplicate projects\n",
    "* Rearrange counties in County column in alphabetical order.\n",
    "* What to do with \"None\" in project description? Replace it with title?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ac19fe-7b6c-4560-9740-8a4f72c5b6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import _cleaning_utils\n",
    "import _harmonization_utils as harmonization_utils\n",
    "import _state_rail_plan_utils as srp_utils\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import shapely\n",
    "from calitp_data_analysis.sql import to_snakecase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78be4e7-2349-4ffd-9d59-f9fa450ae7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import re\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re\n",
    "from collections import Counter\n",
    "from autocorrect import Speller\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b68eeb-422d-4be8-b557-7bd9e95599af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0541b671-a020-485f-9b0a-f46238f1d4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lost = harmonization_utils.load_lost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3829bd6-8fc1-4c15-809f-75020248a722",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\n",
    "    \"project_title\",\n",
    "    \"lead_agency\",\n",
    "    \"project_year\",\n",
    "    \"project_category\",\n",
    "    \"grant_program\",\n",
    "    \"phase\",\n",
    "    \"project_description\",\n",
    "    \"total_project_cost\",\n",
    "    \"total_available_funds\",\n",
    "    \"city\",\n",
    "    \"county\",\n",
    "    \"location\",\n",
    "    \"geometry\",\n",
    "    \"data_source\",\n",
    "    \"notes\",\n",
    "    \"funding_notes\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db720477-44f5-4cbd-80ac-a0fe86e47cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_notes(df, note_cols: list, new_col_name: str):\n",
    "    \"\"\"\n",
    "    Concat multiple columns into one.\n",
    "    \"\"\"\n",
    "    prefix = \"_\"\n",
    "    for column in note_cols:\n",
    "        df[f\"{prefix}{column}\"] = df[column].astype(str)\n",
    "    note_cols = [prefix + sub for sub in note_cols]\n",
    "\n",
    "    # https://stackoverflow.com/questions/65532480/how-to-combine-column-names-and-values\n",
    "    def combine_notes(x):\n",
    "        return \", \".join([col + \": \" + x[col] for col in note_cols])\n",
    "\n",
    "    df[new_col_name] = df.apply(combine_notes, axis=1)\n",
    "    df[new_col_name] = df[new_col_name].str.replace(\"_\", \" \")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44c2cff-9ba4-49a6-a511-f4e8a0041a6d",
   "metadata": {},
   "source": [
    "#### Why does erase this project cost detail\n",
    "* For SRP..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f02b741-487c-49e5-a860-7d278e2e11e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb1 = harmonization_utils.load_sb1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b5d13c-f4ba-4baf-8c3a-f520a960a44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# srp = harmonization_utils.load_state_rail_plan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2785a29-bdb6-4f8a-92ae-c2b7a0bac080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_cost_fund(df, monetary_cols:list):\n",
    "    \"\"\"\n",
    "    Change columns with cost/fund in\n",
    "    its name to be integer datatype\n",
    "    \"\"\"\n",
    "    for i in monetary_cols:\n",
    "        try:\n",
    "            df[i] = (\n",
    "                df[i]\n",
    "                .str.lower()\n",
    "                .str.replace(\"$\", \"\")\n",
    "                .str.replace(\",\", \"\")\n",
    "                .str.replace(\"tbd\",\"\")\n",
    "                .astype(int)\n",
    "                .fillna(0)\n",
    "            )\n",
    "        except:\n",
    "            df[i] = df[i].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288add14-7582-4f10-b6d5-ba8cefc99029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonizing2(df,\n",
    "    agency_name_col: str,\n",
    "    project_name_col: str,\n",
    "    project_description_col: str,\n",
    "    project_category_col: str,\n",
    "    project_cost_col: str,\n",
    "    location_col: str,\n",
    "    geography_col: str,\n",
    "    phase_col: str,\n",
    "    county_col: str,\n",
    "    city_col: str,\n",
    "    project_year_col: str,\n",
    "    data_source_col: str,\n",
    "    fund_cols: list,\n",
    "    program: str,\n",
    "    cost_in_millions: bool = True,):\n",
    "    # Rename columns\n",
    "    rename_columns = {\n",
    "        agency_name_col: \"lead_agency\",\n",
    "        project_name_col: \"project_title\",\n",
    "        project_description_col: \"project_description\",\n",
    "        project_category_col: \"project_category\",\n",
    "        project_cost_col: \"total_project_cost\",\n",
    "        location_col: \"location\",\n",
    "        geography_col: \"geometry\",\n",
    "        phase_col: \"phase\",\n",
    "        county_col: \"county\",\n",
    "        city_col: \"city\",\n",
    "        project_year_col: \"project_year\",\n",
    "        data_source_col: \"data_source\",\n",
    "    }\n",
    "    # Rename columns\n",
    "    df = df.rename(columns=rename_columns)\n",
    "    \n",
    "    # Correct monetary columns\n",
    "    cost_columns = df.columns[df.columns.str.contains(\"(cost|funds)\")].tolist()\n",
    "    df = correct_cost_fund(df,cost_columns)\n",
    "    \n",
    "    # Divide cost columns by millions\n",
    "    # If bool is set to True\n",
    "    if cost_in_millions:\n",
    "        for i in cost_columns:\n",
    "            df[i] = df[i].divide(1_000_000)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1436f27-0a3c-4409-9758-4947c8c6318e",
   "metadata": {},
   "outputs": [],
   "source": [
    "srp2 = harmonizing2(srp, agency_name_col=\"lead_agency\",\n",
    "        project_name_col=\"project_name\",\n",
    "        project_description_col=\"project_description\",\n",
    "        project_category_col=\"project_category\",\n",
    "        project_cost_col=\"total_project_cost\",\n",
    "        location_col=\"corridor\",\n",
    "        geography_col=\"\",\n",
    "        phase_col=\"\",\n",
    "        county_col=\"\",\n",
    "        city_col=\"\",\n",
    "        project_year_col=\"\",\n",
    "        data_source_col=\"\",\n",
    "        fund_cols=[],\n",
    "        program=\"State Rail Plan\",\n",
    "        cost_in_millions=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291e821d-9b3f-40a2-bde9-7a12b31eb410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonizing(\n",
    "    df,\n",
    "    agency_name_col: str,\n",
    "    project_name_col: str,\n",
    "    project_description_col: str,\n",
    "    project_category_col: str,\n",
    "    project_cost_col: str,\n",
    "    location_col: str,\n",
    "    geography_col: str,\n",
    "    phase_col: str,\n",
    "    county_col: str,\n",
    "    city_col: str,\n",
    "    project_year_col: str,\n",
    "    program: str,\n",
    "    data_source_col: str,\n",
    "    fund_cols: list,\n",
    "    cost_in_millions: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Take a dataset and change the column names/types to\n",
    "    default names and formats.\n",
    "    \"\"\"\n",
    "    rename_columns = {\n",
    "        agency_name_col: \"lead_agency\",\n",
    "        project_name_col: \"project_title\",\n",
    "        project_description_col: \"project_description\",\n",
    "        project_category_col: \"project_category\",\n",
    "        project_cost_col: \"total_project_cost\",\n",
    "        location_col: \"location\",\n",
    "        geography_col: \"geometry\",\n",
    "        phase_col: \"phase\",\n",
    "        county_col: \"county\",\n",
    "        city_col: \"city\",\n",
    "        project_year_col: \"project_year\",\n",
    "        data_source_col: \"data_source\",\n",
    "    }\n",
    "    # Rename columns\n",
    "    df = df.rename(columns=rename_columns)\n",
    "    \n",
    "    # Clean up monetary columns to be interger\n",
    "    cost_columns = df.columns[df.columns.str.contains(\"(cost|funds)\")].tolist()\n",
    "    df = correct_cost_fund(df,cost_columns)\n",
    "    \n",
    "    # Clean up string columns\n",
    "    string_cols = df.select_dtypes(include=[\"object\"]).columns.to_list()\n",
    "    for i in string_cols:\n",
    "        df[i] = df[i].str.replace(\"_\", \" \").str.strip().str.title()\n",
    "\n",
    "\n",
    "    # Divide cost columns by millions\n",
    "    # If bool is set to True\n",
    "    if cost_in_millions:\n",
    "        for i in fund_cols + [\"total_project_cost\"]:\n",
    "            df[i] = df[i].divide(1_000_000)\n",
    "\n",
    "\n",
    "    # Add new column with funding breakout\n",
    "    # Since it's summarized above and the details are suppressed.\n",
    "    df[\"total_available_funds\"] = df[fund_cols].sum(axis=1)\n",
    "    df = create_notes(df, fund_cols, \"funding_notes\")\n",
    "\n",
    "    # Add program\n",
    "    df[\"grant_program\"] = program\n",
    "    \n",
    "    # Create columns even if they don't exist, just to harmonize\n",
    "    # before concatting.\n",
    "    create_columns = [\n",
    "        \"county\",\n",
    "        \"city\",\n",
    "        \"notes\",\n",
    "        \"project_year\",\n",
    "        \"project_category\",\n",
    "        \"location\",\n",
    "        \"phase\",\n",
    "    ]\n",
    "    for column in create_columns:\n",
    "        if column not in df:\n",
    "            df[column] = \"None\"\n",
    "    if \"geometry\" not in df:\n",
    "        df[\"geometry\"] = None\n",
    "    if \"data_source\" not in df:\n",
    "        df[\"data_source\"] = program\n",
    "\n",
    "    # Only keep certain columns\n",
    "    df = df[columns_to_keep]\n",
    "\n",
    "    # Fill in any nulls\n",
    "    df['project_description2'] = df.project_description.fillna(df.project_title)\n",
    "    df = df.fillna(df.dtypes.replace({\"float64\": 0.0, \"object\": \"None\"}))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea5badb-841b-4941-b48f-23d750b5ed27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonize_srp():\n",
    "    df = harmonization_utils.load_state_rail_plan()\n",
    "    df = harmonizing(\n",
    "        df,\n",
    "        agency_name_col=\"lead_agency\",\n",
    "        project_name_col=\"project_name\",\n",
    "        project_description_col=\"project_description\",\n",
    "        project_category_col=\"project_category\",\n",
    "        project_cost_col=\"total_project_cost\",\n",
    "        location_col=\"corridor\",\n",
    "        geography_col=\"\",\n",
    "        phase_col=\"\",\n",
    "        county_col=\"\",\n",
    "        city_col=\"\",\n",
    "        project_year_col=\"\",\n",
    "        program=\"State Rail Plan\",\n",
    "        data_source_col=\"\",\n",
    "        fund_cols=[],\n",
    "        cost_in_millions=True,\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b60a4e7-cc69-41fb-9285-c32f9fa0791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = harmonize_srp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23804222-466a-4754-a1ad-fd8f3f8a5239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def harominze_lost():\n",
    "    df = harmonization_utils.load_lost()\n",
    "    df = harmonizing(\n",
    "        df,\n",
    "        agency_name_col=\"agency\",\n",
    "        project_name_col=\"project_title\",\n",
    "        project_description_col=\"project_description\",\n",
    "        project_category_col=\"project_category\",\n",
    "        project_cost_col=\"cost__in_millions_\",\n",
    "        location_col=\"location\",\n",
    "        geography_col=\"\",\n",
    "        phase_col=\"\",\n",
    "        county_col=\"county\",\n",
    "        city_col=\"city\",\n",
    "        project_year_col=\"\",\n",
    "        program=\"Local Options Sales Tax\",\n",
    "        data_source_col=\"measure\",\n",
    "        fund_cols=[\n",
    "            \"estimated_lost_funds\",\n",
    "            \"estimated_federal_funds\",\n",
    "            \"estimated_state_funds\",\n",
    "            \"estimated_local_funds\",\n",
    "            \"estimated_other_funds\",\n",
    "        ],\n",
    "        cost_in_millions=False,\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e8a81a-e6b1-4bdf-a0f8-21420c62b68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonize_sb1():\n",
    "    df = harmonization_utils.load_sb1()\n",
    "    df = harmonizing(\n",
    "        df,\n",
    "        agency_name_col=\"agencies\",\n",
    "        project_name_col=\"projecttitle_x\",\n",
    "        project_description_col=\"projectdescription\",\n",
    "        project_category_col=\"\",\n",
    "        project_cost_col=\"totalcost\",\n",
    "        location_col=\"\",\n",
    "        geography_col=\"geometry\",\n",
    "        phase_col=\"projectstatuses\",\n",
    "        county_col=\"countynames\",\n",
    "        city_col=\"citynames\",\n",
    "        project_year_col=\"fiscalyears\",\n",
    "        program=\"SB1\",\n",
    "        data_source_col=\"programcodes\",\n",
    "        fund_cols=[\"sb1funds\", \"iijafunds\"],\n",
    "        cost_in_millions=True,\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd2a79a-700b-446e-8346-5aa6fb2309f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_all_projects():\n",
    "\n",
    "    # Load  dataframes\n",
    "    state_rail_plan = harmonize_srp()\n",
    "    lost = harominze_lost()\n",
    "    sb1 = harmonize_sb1()\n",
    "\n",
    "    # Concat for df\n",
    "    df = pd.concat([lost, state_rail_plan, sb1])\n",
    "    \n",
    "    # Clean agency names\n",
    "    df = harmonization_utils.organization_cleaning(df, \"lead_agency\")\n",
    "    \n",
    "    # Determine if the project completely funded or not?\n",
    "    # Add up all available funds\n",
    "    df[\"fully_funded\"] = df.apply(harmonization_utils.funding_vs_expenses, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcafef7-30b9-4582-93c8-188ede6b8562",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects = add_all_projects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c6a43d-0a8c-4f7c-a3cc-df3415163bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0983ba29-f492-4a1a-ad40-78ebd291f7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects.grant_program.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c066920-6b09-4584-bc82-4f88b41e00d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects.total_project_cost.value_counts().head() / len(all_projects) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e92d731-6de5-4a0b-be2a-2632063dbb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects.project_description2.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82408ec-540e-46dc-abd9-244aea7657f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects.project_title.value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a8e2a2-9d49-4e55-a2ee-bd6224d7fb61",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Does this project have enough information to be useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3926aa77-991b-48be-b57d-04077a0a485b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_info(df): \n",
    " \n",
    "    #Get percentiles in objects for total vehicle.\n",
    "    p50_project_desc= df.project_description_count.quantile(0.50).astype(float)\n",
    "    p50_null_values = df.total_percent_null_values.quantile(0.50).astype(float)\n",
    "    \n",
    "    #Function for fleet size\n",
    "    def percentile_info (row):\n",
    "        if ((row.project_description_count >= p50_project_desc) and (row.total_percent_null_values <= p25_null_values)):\n",
    "            return \"Yes\"\n",
    "        else: \n",
    "            return \"No\"\n",
    "    df[\"enough_info\"] = df.apply(lambda x: percentile_info(x), axis=1)\n",
    "  \n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48854cb1-3fa8-4d4e-8e8f-7218fc8b9c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enough_info(df):\n",
    "    # Select string columns\n",
    "    string_cols = all_projects.select_dtypes(include=[\"object\"]).columns.to_list()\n",
    "    \n",
    "    # https://stackoverflow.com/questions/73839250/count-number-of-occurrences-of-text-over-row-python-pandas\n",
    "    # Count \"nones\" in string columns\n",
    "    df['none_counts'] = df[string_cols].astype(str).sum(axis=1).str.lower().str.count(\"none\")\n",
    "    \n",
    "    # Count zeroes\n",
    "    df['zero_counts'] = (df == 0).astype(int).sum(axis=1)\n",
    "    \n",
    "    # Total up all none/zeroes \n",
    "    df[\"total_percent_null_values\"] = df[['none_counts','zero_counts']].sum(axis=1)/len(all_projects.columns) * 100\n",
    "    \n",
    "    # Count project descriptions\n",
    "    df[\"project_description_count\"] = df[\"project_description\"].str.count('\\w+')\n",
    "    \n",
    "    # Categorize whether it has enough info or not\n",
    "    df = categorize_info(df)\n",
    "    \n",
    "    # Compress columns to retain some info\n",
    "    df['counts'] = 'number of strings in project desc: ' + df.project_description_count.astype(str) + ' % of null values:' + df.total_percent_null_values.astype(int).astype(str)\n",
    "    \n",
    "    df = df.drop(columns = ['none_counts','zero_counts','project_description_count','total_percent_null_values'])\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8560fc-bc1a-4812-bd7f-ab37664a8791",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects = enough_info(all_projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0292042a-16dd-4df8-abbd-7dc160ed0d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects.enough_info.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27db9eeb-ad5d-4b95-88dd-fc71fe0e3d8e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_projects.drop(columns = ['geometry']).sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8add5491-77d7-4eaa-ad79-57072f7eddd9",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "* Rewrite to be shorter?\n",
    "* Correct spelling of descriptions?\n",
    "* https://github.com/cal-itp/data-analyses/blob/29ed3ad1d107c6be09fecbc1a5f3d8ef5f2b2da6/dla/dla_utils/clean_data.py#L305"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbf8456-0592-41c6-93c4-8f96491c502a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PASSENGER_MODE = ['non sov', 'high quality transit areas', \n",
    "                      'hqta', 'hov']\n",
    "    \n",
    "    \n",
    "SAFETY = ['fatalities','safe', 'speed management','signal coordination',\n",
    "              'slow speeds', 'roundabouts', 'victims','collisoins','protect',\n",
    "              'crash', 'modification factors', 'safety system'] \n",
    "\n",
    "CONGESTION_RELIEF = ['congestion', 'rideshare','ridesharing', 'vanpool', 'car share']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a25e26-a7a5-4892-bcb0-a23c55c13009",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [PASSENGER_MODE,SAFETY,CONGESTION_RELIEF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168269cc-7d99-4dea-9486-a172d4285e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_values = ['passenger mode shift', 'safety', 'congestion relief']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14ed5e4-f695-4508-a269-2d7c4319e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(my_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5428a3d2-8682-4c46-b9b8-37b42a946f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(df, keywords:list, columns:list):\n",
    "    \n",
    "    # Clean project information\n",
    "    project_description = (row.project_description2.lower()\n",
    "                               .replace(\"-\",\"\")\n",
    "                               .replace(\".\",\"\")\n",
    "                               .replace(\":\",\"\")\n",
    "                              )\n",
    "    \n",
    "    for item in keywords:\n",
    "        if any(word in project_description for word in item):\n",
    "            congestion_relief = \"congestion relief\"    \n",
    "    if any(word in project_description for word in PASSENGER_MODE):\n",
    "            passenger_mode_shift = \"passenger_mode_shift\"    \n",
    "    if any(word in project_description for word in SAFETY):\n",
    "            safety = \"safety\"    \n",
    "    return pd.Series(\n",
    "            [active_transp, transit, bridge, street, freeway, infra_resiliency_er, congestion_relief], \n",
    "            index=['active_transp', 'transit', 'bridge', 'street', \n",
    "                   'freeway', 'infra_resiliency_er', 'congestion_relief',\n",
    "                  'passenger_mode_shift', 'safety']\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f88dfa-e95a-4a8c-a457-405ffbd80548",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'a': 1, 'b': 2, 'c': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6253cd-b5f8-4431-a575-9a274e6e8bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_categories(df):\n",
    "    # There are many projects that are \n",
    "    ACTIVE_TRANSPORTATION = ['bike', 'bicycle', 'cyclist', \n",
    "                             'pedestrian', \n",
    "                             ## including the spelling errors of `pedestrian`\n",
    "                             'pedestrain',\n",
    "                             'crosswalk', \n",
    "                             'bulb out', 'bulb-out', \n",
    "                             'active transp', 'traffic reduction', \n",
    "                             'speed reduction', 'ped', 'srts', \n",
    "                             'safe routes to school',\n",
    "                             'sidewalk', 'side walk', 'Cl ', 'trail',\n",
    "                             'atp'\n",
    "                            ]\n",
    "    TRANSIT = ['bus', 'metro', 'station', #Station comes up a few times as a charging station and also as a train station\n",
    "               'transit','fare', 'brt', 'yarts', 'railroad', 'highway-rail'\n",
    "               # , 'station' in description and 'charging station' not in description\n",
    "              ] \n",
    "    BRIDGE = [\"bridge\", 'viaduct']\n",
    "    STREET = ['traffic signal', 'resurface', 'resurfacing', 'slurry', 'seal' \n",
    "              'sign', 'stripe', 'striping', 'median', \n",
    "              'guard rail', 'guardrail', \n",
    "              'road', 'street', \n",
    "              'sinkhole', 'intersection', 'signal', 'curb',\n",
    "              'light', 'tree', 'pavement', 'roundabout'\n",
    "             ]\n",
    "\n",
    "    FREEWAY = ['hov ', 'hot ', 'freeway', 'highway', 'express lanes', 'hwy']\n",
    "\n",
    "    INFRA_RESILIENCY_ER = ['repair', 'emergency', 'replace','retrofit', 'er',\n",
    "                           'rehab', 'improvements', 'seismic', 'reconstruct', 'restoration']\n",
    "\n",
    "    CONGESTION_RELIEF = ['congestion', 'rideshare','ridesharing', 'vanpool', 'car share']\n",
    "\n",
    "    NOT_INC = ['charging', 'fueling', 'cng', 'bridge', 'trail',\n",
    "           'k-rail', 'guardrails', 'bridge rail', 'guard', 'guarrail']\n",
    "    \n",
    "    PASSENGER_MODE = ['non sov', 'high quality transit areas', \n",
    "                      'hqta', 'hov']\n",
    "    \n",
    "    \n",
    "    SAFETY = ['fatalities','safe', 'speed management','signal coordination',\n",
    "              'slow speeds', 'roundabouts', 'victims','collisoins','protect',\n",
    "              'crash', 'modification factors', 'safety system'] \n",
    "    \n",
    "    def categorize_project_descriptions(row):\n",
    "        \"\"\"\n",
    "        This function takes a individual type of work description (row of a dataframe)\n",
    "        and returns a dummy flag of 1 if it finds keyword present in\n",
    "        project categories (active transportation, transit, bridge, etc).\n",
    "        A description can contain multiple keywords across categories.\n",
    "        \"\"\"\n",
    "        # Clean up project description 2\n",
    "        project_description = (row.project_description2.lower()\n",
    "                               .replace(\"-\",\"\")\n",
    "                               .replace(\".\",\"\")\n",
    "                               .replace(\":\",\"\")\n",
    "                              )\n",
    "    \n",
    "        # Store a bunch of columns that will be flagged\n",
    "        # A project can involve multiple things...also, not sure what's in the descriptions\n",
    "        active_transp = \"\"\n",
    "        transit = \"\"\n",
    "        bridge =\"\"\n",
    "        street = \"\"\n",
    "        freeway = \"\"\n",
    "        infra_resiliency_er = \"\"\n",
    "        congestion_relief = \"\"\n",
    "        passenger_mode_shift = \"\"\n",
    "        safety = \"\"\n",
    "        \n",
    "        if any(word in project_description for word in ACTIVE_TRANSPORTATION):\n",
    "            active_transp = \"active transportation\"\n",
    "        \n",
    "        #if any(word in description if instanceof(word, str) else word(description) for word in TRANSIT)\n",
    "\n",
    "        if (any(word in project_description for word in TRANSIT) and \n",
    "            not any(exclude_word in project_description for exclude_word in NOT_INC)\n",
    "           ):\n",
    "            transit = \"transit\"\n",
    "        if any(word in project_description for word in BRIDGE):\n",
    "            bridge = \"bridge\"\n",
    "        if any(word in project_description for word in STREET):\n",
    "            street = \"street\"\n",
    "        if any(word in project_description for word in FREEWAY):\n",
    "            freeway = \"freeway\" \n",
    "        if any(word in project_description for word in INFRA_RESILIENCY_ER):\n",
    "            infra_resiliency_er = \"infrastructure\"\n",
    "        if any(word in project_description for word in CONGESTION_RELIEF):\n",
    "            congestion_relief = \"congestion relief\"    \n",
    "        if any(word in project_description for word in PASSENGER_MODE):\n",
    "            passenger_mode_shift = \"passenger_mode_shift\"    \n",
    "        if any(word in project_description for word in SAFETY):\n",
    "            safety = \"safety\"    \n",
    "        return pd.Series(\n",
    "            [active_transp, transit, bridge, street, freeway, infra_resiliency_er, congestion_relief,\n",
    "            passenger_mode_shift, safety], \n",
    "            index=['active_transp', 'transit', 'bridge', 'street', \n",
    "                   'freeway', 'infra_resiliency_er', 'congestion_relief',\n",
    "                  'passenger_mode_shift', 'safety']\n",
    "        )\n",
    "    \n",
    "    \n",
    "    work_categories = df.apply(categorize_project_descriptions, axis=1)\n",
    "    work_cols = list(work_categories.columns)\n",
    "    df2 = pd.concat([df, work_categories], axis=1)\n",
    "    \n",
    "    df2['all_categories'] = df2[work_cols].agg(' '.join, axis=1)\n",
    "    df2['all_categories'] = df2['all_categories'].str.replace(\"N/A\",\"\").str.strip()\n",
    "    df2 = df2.drop(columns = work_cols)\n",
    "    \n",
    "    return df2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea11daa-3a18-4d8a-9004-b2fc5e6d4343",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects_metric = add_metrics(all_projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad99b589-1d78-4052-96ac-4617f0494544",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects_metric.all_categories.value_counts().head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270e8b35-cc6b-4461-835c-40c4b850916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_metrics(df):\n",
    "    def categorize_metrics(row):\n",
    "        all_categories = row.all_categories.lower()\n",
    "        safety = \"\"\n",
    "        passenger_mode_shift = \"\"\n",
    "        infill_development = \"\"\n",
    "        \n",
    "        if any(word in all_categories for word in ['infrastructure', 'bridge', 'safety', 'street']):\n",
    "            safety = \"safety\"\n",
    "        if any(word in all_categories for word in ['active transportation', 'passenger_mode_shift']):\n",
    "            passenger_mode_shift = \"passenger_mode_shift\"\n",
    "        if any(word in all_categories for word in ['transit', 'active transportation', 'infrastructure']):\n",
    "            infill_development = \"infill_development\" \n",
    "       \n",
    "        return pd.Series(\n",
    "            [safety,passenger_mode_shift,infill_development], \n",
    "            index=['safety', 'passenger_mode_shift', 'infill_development']\n",
    "        )\n",
    "    \n",
    "    work_categories = df.apply(categorize_metrics, axis=1)\n",
    "    work_cols = list(work_categories.columns)\n",
    "    df2 = pd.concat([df, work_categories], axis=1)\n",
    "    \n",
    "    df2['all_metrics'] = df2[work_cols].agg(' '.join, axis=1)\n",
    "    df2['all_metrics'] = df2['all_metrics'].str.replace(\"N/A\",\"\").str.strip()\n",
    "    df2 = df2.drop(columns = work_cols)\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a643de4-b6b3-4751-9a9f-b68abe4d7a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects_metric = apply_metrics(all_projects_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae7f371-2a04-4644-a802-3d089b65d372",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects_metric.all_metrics.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6da3b49-dd3f-4b01-b394-23f44bf8e3a6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_projects_metric[['grant_program','project_description','all_metrics']].sample(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad5b6ae-9407-46ae-b2ff-c9ad6cbea83c",
   "metadata": {},
   "source": [
    "### Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a86d28-9b77-48c3-ba6d-27dc360f2fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_words(df, col: str) -> list:\n",
    "    \"\"\"\n",
    "    Natalie's function to clean and place words in a project description column\n",
    "    into a list\n",
    "    \"\"\"\n",
    "    # get just the one col\n",
    "    column = df[[col]]\n",
    "\n",
    "    # remove single-dimensional entries from the shape of an array\n",
    "    col_text = column.squeeze()\n",
    "    # get list of words\n",
    "    text_list = col_text.tolist()\n",
    "\n",
    "    # Join all the column into one large text blob, lower text\n",
    "    text_list = \" \".join(text_list).lower()\n",
    "\n",
    "    # remove punctuation\n",
    "    text_list = re.sub(r\"[^\\w\\s]\", \"\", text_list)\n",
    "\n",
    "    # List of stopwords\n",
    "    swords = [re.sub(r\"[^A-z\\s]\", \"\", sword) for sword in stopwords.words(\"english\")]\n",
    "\n",
    "    # Remove stopwords\n",
    "    clean_text_list = [\n",
    "        word for word in word_tokenize(text_list.lower()) if word not in swords\n",
    "    ]\n",
    "\n",
    "    return clean_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd602787-2444-49c5-8bb8-c59a63975de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_common_phrases(df, description_column: str, values_to_add: list):\n",
    "\n",
    "    # Break apart every word in the description column into a list\n",
    "    descriptions_list = get_list_of_words(df, description_column)\n",
    "\n",
    "    # Get phrases of whatever length you want (2,3,4,etc)\n",
    "    c = Counter([\" \".join(y) for x in [2] for y in ngrams(descriptions_list, x)])\n",
    "\n",
    "    # Make a dataframe out of the counter values\n",
    "    df_phrases = pd.DataFrame({\"phrases\": list(c.keys()), \"total\": list(c.values())})\n",
    "\n",
    "    # Take phrases that are repeated more than 40 times and turn it into a list\n",
    "    df_phrases = ((df_phrases.loc[df_phrases[\"total\"] > 40])).reset_index(drop=True)\n",
    "    common_phrases_list = df_phrases.phrases.tolist()\n",
    "\n",
    "    phrases_to_del = [\n",
    "        \"san bernardino\",\n",
    "        \"los angeles\",\n",
    "        \"contra costa\",\n",
    "        \"el dorado\",\n",
    "        \"san luis obispo\",\n",
    "        \"luis obispo\",\n",
    "        \"del norte\",\n",
    "        \"san francisco\",\n",
    "        \"improve approximately\",\n",
    "    ]\n",
    "\n",
    "    common_phrases_list = list(set(common_phrases_list) - set(phrases_to_del))\n",
    "\n",
    "    # CLean up the list to delete county information/etc\n",
    "    words_to_delete = [\n",
    "        \"county\",\n",
    "        \"route\",\n",
    "        \"dollar\",\n",
    "        \"mile\",\n",
    "        \"santa\",\n",
    "        \"project\",\n",
    "        \"san\",\n",
    "        \"lanes\",\n",
    "        \"lane\",\n",
    "        \"2\",\n",
    "        \"4\",\n",
    "        \"financial\",\n",
    "        \"prop\",\n",
    "        \"best\",\n",
    "        \"approximately\",\n",
    "    ]\n",
    "\n",
    "    for word in words_to_delete:\n",
    "        common_phrases_list = [x for x in common_phrases_list if word not in x]\n",
    "\n",
    "    # ADD certain keywords here\n",
    "    # Operating Additional Service\n",
    "    common_phrases_list.extend(values_to_add)\n",
    "\n",
    "    return common_phrases_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec139873-4bb7-4428-9fd7-ceb9e247d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_projects(\n",
    "    df,\n",
    "    description_column: str,\n",
    "    project_id_column: str,\n",
    "    title_column: str,\n",
    "    values_to_add: list,\n",
    "):\n",
    "\n",
    "    # Find most common 2 word phrases for some automatic project categories\n",
    "    common_phrases_list = find_common_phrases(df, description_column, values_to_add)\n",
    "\n",
    "    # Place all the words in common_phrases_list into a blob named query\n",
    "    # https://stackoverflow.com/questions/64727090/extract-all-matching-keywords-from-a-list-of-words-and-create-a-new-dataframe-pa\n",
    "    query = \"|\".join(common_phrases_list)\n",
    "\n",
    "    # Remove punctation and lower strings in original description column befores searching\n",
    "    df[\"clean_description\"] = (\n",
    "        df[description_column]\n",
    "        .str.lower()\n",
    "        .str.replace(\"-\", \" \", regex=True)\n",
    "        .str.replace(\"(\", \" \", regex=True)\n",
    "        .str.replace(\")\", \" \", regex=True)\n",
    "        .str.replace(\".\", \" \", regex=True)\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "    # Search through description column for the most common phrases\n",
    "    # Input the results in the new column\n",
    "    df[\"auto_project_category\"] = df[\"clean_description\"].str.findall(\n",
    "        r\"\\b({})\\b\".format(query)\n",
    "    )\n",
    "\n",
    "    # Explode to take categories out of a list\n",
    "    # Drop duplicate project keywords by title\n",
    "    df = (\n",
    "        df.explode(\"auto_project_category\")\n",
    "        .sort_values([project_id_column, title_column])\n",
    "        .drop_duplicates(\n",
    "            subset=[\n",
    "                description_column,\n",
    "                project_id_column,\n",
    "                title_column,\n",
    "                \"auto_project_category\",\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Fill any uncategorized projects as \"Other\"\n",
    "    df[\"auto_project_category\"] = (\n",
    "        df[\"auto_project_category\"].fillna(\"Other\").str.title()\n",
    "    )\n",
    "\n",
    "    # Correct spelling\n",
    "    spell = Speller(lang=\"en\")\n",
    "    df[\"auto_project_category\"] = df[\"auto_project_category\"].apply(\n",
    "        lambda x: \" \".join([spell(i) for i in x.split()])\n",
    "    )\n",
    "\n",
    "    # Summarize - put all the categories onto one line\n",
    "    df = (\n",
    "        df.groupby(\n",
    "            [\n",
    "                description_column,\n",
    "                project_id_column,\n",
    "                title_column,\n",
    "            ]\n",
    "        )[\"auto_project_category\"]\n",
    "        .apply(\",\".join)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d123f3b9-da23-4d4d-a2e2-dc3769100171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_all_projects2():\n",
    "\n",
    "    # Load  dataframes\n",
    "    state_rail_plan = harmonize_srp()\n",
    "    lost = harominze_lost()\n",
    "    sb1 = harmonize_sb1()\n",
    "\n",
    "    # Concat for df\n",
    "    all_projects_df = pd.concat([lost, state_rail_plan, sb1])\n",
    "\n",
    "    # Categorize\n",
    "    categories = categorize_projects(\n",
    "        all_projects_df,\n",
    "        \"project_description\",\n",
    "        \"project_title\",\n",
    "        \"project_id\",\n",
    "        [\n",
    "            \"operating\",\n",
    "            \"service\",\n",
    "            \"zero emission vehicle\",\n",
    "            \"zev\",\n",
    "            \"maintain/repair\",\n",
    "            \"repair/replace\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Merge categorized\n",
    "    all_projects_df = pd.merge(\n",
    "        all_projects_df.drop(columns=[\"clean_description\"]),\n",
    "        categories,\n",
    "        how=\"left\",\n",
    "        on=[\"project_description\", \"project_title\", \"project_id\"],\n",
    "    )\n",
    "\n",
    "    # Rename\n",
    "    all_projects_df = all_projects_df.drop(columns=[\"auto_project_category_x\"]).rename(\n",
    "        columns={\"auto_project_category_y\": \"auto_tagged_project_categories\"}\n",
    "    )\n",
    "    # Concat for gdf\n",
    "    all_projects_gdf = pd.concat([sb1])\n",
    "    all_projects_gdf = all_projects_gdf.set_geometry(\"location\")\n",
    "\n",
    "    return all_projects_df, all_projects_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a29e05-0ba6-40cb-93e2-d097159e6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_projects, all_projects_geo = add_all_projects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873a88ca-5a47-4bfe-a1d3-715a5bed05bb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all_projects.drop(columns = ['location'])[['project_title','project_category', 'auto_tagged_project_categories','project_description','total_available_funds','funding_notes']].sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de14390-c6a8-4117-8cc8-00d5d6a52611",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89874fbf-1c72-412b-8235-ea8153322bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects.drop(columns=[\"location\"]).sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cfedf8-14aa-4d6c-b30e-cc9f6ee5bbf8",
   "metadata": {},
   "source": [
    "### Look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e39b78-af8b-4bc5-8911-572839a72b36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_projects.groupby([\"lead_agency\"]).agg({\"project_id\": \"nunique\"}).sort_values(\n",
    "    \"project_id\", ascending=False\n",
    ").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa0b1d3-4416-4537-b568-bdaae9fd1fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects[\n",
    "    (all_projects.county == \"Kern\")\n",
    "    & (all_projects.project_description.str.contains(\"Seal Coat\"))\n",
    "].drop(columns=[\"location\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc906308-31d4-4fde-b492-8218b05cec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_projects.groupby(['project_category','auto_tagged_project_categories']).agg({'project_id':'nunique'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d6ac3a-c517-4df2-b907-0bac0a09e34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects.groupby([\"auto_tagged_project_categories\"]).agg(\n",
    "    {\"project_id\": \"nunique\"}\n",
    ").sort_values(\"project_id\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5150da00-2a30-4f4d-bec8-1d9e5c66d623",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects.groupby([\"project_category\"]).agg({\"project_id\": \"nunique\"}).sort_values(\n",
    "    \"project_id\", ascending=False\n",
    ").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf38631-a734-47b0-9465-fcfb8ebafcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects.groupby([\"project_description\"]).agg(\n",
    "    {\"project_id\": \"nunique\"}\n",
    ").sort_values(\"project_id\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1baa16-e15c-48e7-9772-ef67755f9d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects.groupby([\"county\"]).agg({\"project_id\": \"nunique\"}).sort_values(\n",
    "    \"project_id\", ascending=False\n",
    ").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d55e4ed-9b69-4111-b2ed-69715c9d90c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects.lead_agency.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a534d9-75e4-4ff8-aa11-99db480de733",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects.total_project_cost.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6985e5d0-cf27-423f-8775-16eb3c518beb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_projects.loc[all_projects.fully_funded == \"Fully funded\"].groupby(\n",
    "    [\"data_source\"]\n",
    ").agg({\"project_id\": \"nunique\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3259fc95-2db6-46ad-8cc6-a0357aa19077",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects.loc[all_projects.fully_funded == \"Partially funded\"].groupby(\n",
    "    [\"data_source\"]\n",
    ").agg({\"project_id\": \"nunique\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef08825-9e29-4268-9172-d0d83e08243b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects.groupby([\"data_source\"]).agg({\"project_id\": \"nunique\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fae701e-4132-4d06-8c27-3e598e072172",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects.groupby([\"fully_funded\"]).agg(\n",
    "    {\"project_id\": \"nunique\"}\n",
    ").reset_index().sort_values(\"project_id\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171611d6-acf9-46d8-9814-20534114d43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects.groupby([\"data_source\", \"fully_funded\"]).agg({\"project_id\": \"nunique\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
