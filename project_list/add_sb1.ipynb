{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6ddf257-863a-41d8-9830-ef8b7d91647b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_2191/3899940571.py:1: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import _harmonization_utils \n",
    "from calitp_data_analysis.sql import to_snakecase\n",
    "from shared_utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "001844d0-bfec-47a2-b396-6087dcac9343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a49b60c-2fb0-44fd-80c4-a7f98556585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "629b5faf-1278-41cb-9c62-ebea1a730848",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_pt1 = \"https://odpsvcs.dot.ca.gov/arcgis/rest/services/RCA/RCA_Projects_032022/FeatureServer/\"\n",
    "url_pt2 = \"/query?where=1%3D1&objectIds=&time=&geometry=&geometryType=esriGeometryEnvelope&inSR=&spatialRel=esriSpatialRelIntersects&distance=&units=esriSRUnit_Foot&relationParam=&outFields=*+&returnGeometry=true&maxAllowableOffset=&geometryPrecision=&outSR=&gdbVersion=&historicMoment=&returnDistinctValues=false&returnIdsOnly=false&returnCountOnly=false&returnExtentOnly=false&orderByFields=&groupByFieldsForStatistics=&outStatistics=&returnZ=false&returnM=false&multipatchOption=&resultOffset=&resultRecordCount=&returnTrueCurves=false&sqlFormat=none&f=geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa6cf22d-a5dd-4092-80fb-1c9fb84b2fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sb1_basic_cleaning(\n",
    "    df,\n",
    "    agency_col: str,\n",
    "    project_name_col: str,\n",
    "    project_id_col: str,\n",
    "    project_desc_col: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform basic cleaning before joining\n",
    "    SB1 & Non SHOPP data together.\n",
    "    \"\"\"\n",
    "    # Remove all punctation, lowercase, and strip whitespaces from\n",
    "    # project titles & descriptions.\n",
    "    for i in [project_name_col, project_desc_col]:\n",
    "        df[i] = df[i].str.lower().str.replace(\"[^\\w\\s]\", \"\").str.strip()\n",
    "\n",
    "    # Some project names contain the year. Remove anything after 20..\n",
    "    df[project_name_col] = df[project_name_col].str.split(\"20\").str[0]\n",
    "\n",
    "    # Get rid of | in object cols\n",
    "    # https://stackoverflow.com/questions/68152902/extracting-only-object-type-columns-in-a-separate-list-from-a-data-frame-in-pand\n",
    "    string_cols = df.select_dtypes(include=[\"object\"]).columns.to_list()\n",
    "    try:\n",
    "        for i in string_cols:\n",
    "            df[i] = df[i].str.replace(\"|\", \"\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Try to extract titles from popups\n",
    "    try:\n",
    "        df[\"popup\"] = (\n",
    "            df[\"popup\"]\n",
    "            .str.split(\"<br  />\")\n",
    "            .str[1]\n",
    "            .str.split(\"20\")\n",
    "            .str[0]\n",
    "            .str.lower()\n",
    "            .str.strip()\n",
    "            .str.replace(\"[^\\w\\s]\", \"\")\n",
    "        )\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbb423a0-a31b-4c28-8d58-14ef58a32b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sb1_rest_server() -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Load all the projects on the SB1\n",
    "    map from the Feature Server.\n",
    "\n",
    "    https://odpsvcs.dot.ca.gov/arcgis/rest/services/RCA/RCA_Projects_032022/FeatureServer\n",
    "    \"\"\"\n",
    "    full_gdf = pd.DataFrame()\n",
    "    for i in [*range(0, 22)]:\n",
    "        df = to_snakecase(gpd.read_file(f\"{url_pt1}{i}{url_pt2}\"))\n",
    "        full_gdf = pd.concat([full_gdf, df], axis=0)\n",
    "\n",
    "    # Basic cleaning\n",
    "    full_gdf = sb1_basic_cleaning(\n",
    "        full_gdf, \"agencies\", \"projecttitle\", \"projectid\", \"projectdescription\"\n",
    "    )\n",
    "\n",
    "    # Fill in project titles that are empty with information\n",
    "    # gleaned from the pop up.\n",
    "    full_gdf[\"projecttitle\"] = full_gdf[\"projecttitle\"].fillna(full_gdf[\"popup\"])\n",
    "\n",
    "    # Throw out missing geometry\n",
    "    missing_geo = full_gdf[full_gdf.geometry.is_empty]\n",
    "    full_gdf = full_gdf[~full_gdf.geometry.is_empty].reset_index(drop=True)\n",
    "\n",
    "    return full_gdf, missing_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0bb2532-b0d2-4a06-a9e1-ab7b2615b1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sb1, missing_geo_sb1 = load_sb1_rest_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ac7b6d2-492b-414c-8dc5-73ca033d1a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(sb1), type(sb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62aa37e5-91cc-4c7b-88da-8498f05baa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(missing_geo_sb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe57ecfb-fd8c-4008-87c2-1f5a3c26d746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sb1_all_projects() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load in all projects layer of SB1 because it\n",
    "    contains a value for every row in the\n",
    "    project title column.\n",
    "    \"\"\"\n",
    "    df = f\"{url_pt1}22{url_pt2}\"\n",
    "\n",
    "    df = to_snakecase(gpd.read_file(df))\n",
    "\n",
    "    # No geometry, just drop it\n",
    "    df = df.drop(columns=[\"geometry\"])\n",
    "\n",
    "    # Basic cleaning\n",
    "    df = sb1_basic_cleaning(\n",
    "        df, \"implementingagency\", \"projecttitle\", \"projectid\", \"projectdescription\"\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc2484ee-dfd5-4e15-b858-e264f6008b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sb1_all_projects = load_sb1_all_projects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17f555ad-8990-41bb-a50c-da5a9a960b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(sb1_all_projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9ad9c79-56b3-4400-9697-b7efccfe1db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sb1_final() -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Layers 0-21 with geographic information\n",
    "    don't always have project titles for each\n",
    "    of the projects. Merge these layers with\n",
    "    layer 22, which does have title information.\n",
    "    \"\"\"\n",
    "    all_projects_subset = [\n",
    "        \"projecttitle\",\n",
    "        \"programcodes\",\n",
    "        \"totalcost\",\n",
    "        \"implementingagency\",\n",
    "        \"fiscalyearcode\",\n",
    "    ]\n",
    "\n",
    "    sb1_geo, missing_geo = load_sb1_rest_server()\n",
    "    sb1_all_projects = load_sb1_all_projects()[all_projects_subset]\n",
    "\n",
    "    # Merge\n",
    "    merge1 = pd.merge(\n",
    "        sb1_geo,\n",
    "        sb1_all_projects,\n",
    "        how=\"left\",\n",
    "        left_on=[\"programcodes\", \"totalcost\", \"agencies\", \"fiscalyearcodes\"],\n",
    "        right_on=[\"programcodes\", \"totalcost\", \"implementingagency\", \"fiscalyearcode\"],\n",
    "    )\n",
    "\n",
    "    # Fill in missing project titles in sb1_geo with information from\n",
    "    # sb1_all_projects\n",
    "    merge1.projecttitle_x = merge1.projecttitle_x.fillna(merge1.projecttitle_y)\n",
    "\n",
    "    # Fill missing titles with none\n",
    "    merge1.projecttitle_x = merge1.projecttitle_x.fillna(\"None\")\n",
    "    \n",
    "    # Drop columns\n",
    "    merge1 = merge1.drop(columns = ['projecttitle_y'])\n",
    "    \n",
    "    # Add a new column detailing where this information comes from \n",
    "    merge1 = merge1.assign(\n",
    "        notes = merge1.programcodes + '/' + 'SB1')\n",
    "    \n",
    "    merge1 = merge1.fillna(merge1.dtypes.replace({'float64': 0.0, 'object': 'None'}))\n",
    "    return merge1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcc62451-98c7-4187-bab3-ad89a039cf75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2191/750967614.py:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "/tmp/ipykernel_2191/750967614.py:25: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "/tmp/ipykernel_2191/750967614.py:32: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "/tmp/ipykernel_2191/750967614.py:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "/tmp/ipykernel_2191/750967614.py:25: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n"
     ]
    }
   ],
   "source": [
    "sb1_final_gdf = sb1_final()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afbd958b-5836-4789-9372-62edac321165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completed                     2693\n",
       "InProgress                    1483\n",
       "Planned                       1321\n",
       "CompletedInProgress            231\n",
       "CompletedInProgressPlanned     154\n",
       "CompletedPlanned               128\n",
       "InProgressPlanned               72\n",
       "In Progress                     22\n",
       "Name: projectstatuscodes, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb1_final_gdf.projectstatuscodes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2af4504-84bc-48b5-85ad-0b0324510590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6104, 5448)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sb1_final_gdf), sb1_final_gdf.geometry.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a52f1771-0064-493b-a339-d1dcece8ed2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Int64Index: 6104 entries, 0 to 6103\n",
      "Data columns (total 41 columns):\n",
      " #   Column                  Non-Null Count  Dtype   \n",
      "---  ------                  --------------  -----   \n",
      " 0   objectid                6104 non-null   int64   \n",
      " 1   agencyids               6104 non-null   object  \n",
      " 2   agencies                6104 non-null   object  \n",
      " 3   programcodes            6104 non-null   object  \n",
      " 4   iijaprogram             6104 non-null   object  \n",
      " 5   iijacodes               6104 non-null   object  \n",
      " 6   projectstatuscodes      6104 non-null   object  \n",
      " 7   fiscalyears             6104 non-null   object  \n",
      " 8   fiscalyearcodes         6104 non-null   object  \n",
      " 9   projectstatuses         6104 non-null   object  \n",
      " 10  sb1funds                6104 non-null   float64 \n",
      " 11  iijafunds               6104 non-null   float64 \n",
      " 12  totalcost               6104 non-null   float64 \n",
      " 13  dateupdated             6104 non-null   object  \n",
      " 14  projectcount            6104 non-null   int64   \n",
      " 15  assemblydistricts       6104 non-null   object  \n",
      " 16  senatedistricts         6104 non-null   object  \n",
      " 17  congressionaldistricts  6104 non-null   object  \n",
      " 18  assemblycodes           6104 non-null   object  \n",
      " 19  senatecodes             6104 non-null   object  \n",
      " 20  congressionalcodes      6104 non-null   object  \n",
      " 21  countynames             6104 non-null   object  \n",
      " 22  citynames               6104 non-null   object  \n",
      " 23  countycodes             6104 non-null   object  \n",
      " 24  citycodes               6104 non-null   object  \n",
      " 25  ct_codes                6104 non-null   object  \n",
      " 26  ct_districts            6104 non-null   object  \n",
      " 27  issb1                   6104 non-null   object  \n",
      " 28  isiija                  6104 non-null   object  \n",
      " 29  isonshs                 6104 non-null   object  \n",
      " 30  issb1codes              6104 non-null   object  \n",
      " 31  isiijacode              6104 non-null   object  \n",
      " 32  isonshscodes            6104 non-null   object  \n",
      " 33  popup                   6104 non-null   object  \n",
      " 34  geometry                6104 non-null   geometry\n",
      " 35  projectid               6104 non-null   object  \n",
      " 36  projecttitle_x          6104 non-null   object  \n",
      " 37  projectdescription      6104 non-null   object  \n",
      " 38  implementingagency      6104 non-null   object  \n",
      " 39  fiscalyearcode          6104 non-null   object  \n",
      " 40  notes                   6104 non-null   object  \n",
      "dtypes: float64(3), geometry(1), int64(2), object(35)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "sb1_final_gdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d82b2c-3c26-4671-a219-71934318f4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Natalie's function to clean and place words in a project description column\n",
    "# into a list\n",
    "def get_list_of_words(df, col: str) -> list:\n",
    "\n",
    "    # get just the one col\n",
    "    column = df[[col]]\n",
    "    \n",
    "    # Correct spelling \n",
    "    # https://stackoverflow.com/questions/49364664/how-to-use-autocorrect-in-pandas-column-of-sentences\n",
    "    # spell = Speller(lang='en')\n",
    "    # df[col] = df[col].apply(lambda x: \" \".join([spell(i) for i in x.split()]))\n",
    "    \n",
    "    # remove single-dimensional entries from the shape of an array\n",
    "    col_text = column.squeeze()\n",
    "    # get list of words\n",
    "    text_list = col_text.tolist()\n",
    "\n",
    "    # Join all the column into one large text blob, lower text\n",
    "    text_list = \" \".join(text_list).lower()\n",
    "\n",
    "    # remove punctuation\n",
    "    text_list = re.sub(r\"[^\\w\\s]\", \"\", text_list)\n",
    "\n",
    "    # List of stopwords\n",
    "    swords = [re.sub(r\"[^A-z\\s]\", \"\", sword) for sword in stopwords.words(\"english\")]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    clean_text_list = [\n",
    "        word for word in word_tokenize(text_list.lower()) if word not in swords\n",
    "    ]\n",
    "\n",
    "    return clean_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14c0f46-1980-457a-be7a-946fffffe15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_common_phrases(df, description_column:str):\n",
    "    \n",
    "    # Break apart every word in the description column into a list\n",
    "    descriptions_list = get_list_of_words(df, description_column)\n",
    "    \n",
    "    # Get phrases of whatever length you want (2,3,4,etc)\n",
    "    c = Counter([\" \".join(y) for x in [2] for y in ngrams(descriptions_list, x)])\n",
    "    \n",
    "    # Make a dataframe out of the counter values\n",
    "    df_phrases = pd.DataFrame({\"phrases\": list(c.keys()), \"total\": list(c.values())})\n",
    "    \n",
    "    # Take phrases that are the most repeated and turn it into a list\n",
    "    df_phrases = ((df_phrases.loc[df_phrases[\"total\"] > 7])).reset_index(drop = True)\n",
    "    \n",
    "    common_phrases_list = df_phrases.phrases.tolist()\n",
    "\n",
    "    return common_phrases_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1527f92f-ca33-4520-b578-310e5c1c3791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_projects(df, \n",
    "                        description_column:str,\n",
    "                        agency_column:str,\n",
    "                        project_year_column:str,\n",
    "                        title_column:str):\n",
    "    \n",
    "    # Find most common 2 word phrases for some automatic project categories\n",
    "    common_phrases_list = find_common_phrases(df,description_column)\n",
    "    \n",
    "    # Place all the words in common_phrases_list into a blob named query\n",
    "    # Ex: 'lrv|zero emission|electric' \n",
    "    # https://stackoverflow.com/questions/64727090/extract-all-matching-keywords-from-a-list-of-words-and-create-a-new-dataframe-pa\n",
    "    query = \"|\".join(common_phrases_list)\n",
    "    \n",
    "    # Remove punctation and lower strings in original description column befores searching\n",
    "    df[\"clean_description\"] = (df[description_column]\n",
    "                      .str.lower()\n",
    "                      .str.replace(\"-\", \" \", regex=True)\n",
    "                      .str.replace(\"(\",\" \", regex=True)\n",
    "                      .str.replace(\")\",\" \", regex=True)\n",
    "                      .str.replace(\".\",\" \", regex=True)\n",
    "                      .str.strip()\n",
    "                     )\n",
    "    \n",
    "    # Search through description column for the most common phrases \n",
    "    df[\"project_category\"] = df[\"clean_description\"].str.findall(\n",
    "    r\"\\b({})\\b\".format(query))\n",
    "    \n",
    "    # Explode to take categories out of a list\n",
    "    # Drop duplicate project keywords by title\n",
    "    df = (df\n",
    "          .explode(\"project_category\")\n",
    "          .sort_values([project_year_column, title_column])\n",
    "          .drop_duplicates(subset=[description_column, project_year_column, title_column, agency_column, \"project_category\"]))\n",
    "    \n",
    "    # Fill any uncategorized projects as \"Other\"\n",
    "    df[\"project_category\"] = (df[\"project_category\"].fillna(\"Other\").str.title())\n",
    "    \n",
    "    # Summarize - put all the categories onto one line\n",
    "    df = (df\n",
    "          .groupby([agency_column, project_year_column, title_column, description_column])[\"project_category\"]\n",
    "          .apply(\",\".join)\n",
    "          .reset_index())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab1ba91-53c9-4b31-adec-2bb06b1046b1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sb1_final_gdf2 = categorize_projects(sb1_final_gdf, 'projectdescription', 'agencies', 'fiscalyears', 'projecttitle_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee813aeb-fa9e-4bfa-9dd6-e85211bd9b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(sb1_final_gdf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045061b0-1fce-4e79-b212-ee8761571c1f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sb1_final_gdf2.project_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745aa289-db23-4dac-89e1-369bc370785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sb1_harmonized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b73e4de-f430-443c-b8e1-9db5cba95080",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb1_harmonized.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64182c9e-6431-4d4f-88a1-9ccdef38272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sb1_harmonized = sb1_harmonized.set_geometry('location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaadb6a-5eb4-479e-8163-d88f2e85a9f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sb1_harmonized.fully_funded.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
