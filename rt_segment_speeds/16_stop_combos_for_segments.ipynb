{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa4f900c-137c-4069-866a-9d8393ea535e",
   "metadata": {},
   "source": [
    "# Between trip variation in stop_ids and stop_sequences for the same shape on rare occasions\n",
    "\n",
    "When segments are missing, there may be 2 complicating factors we haven't yet considered in the workflow: \n",
    "1. stops for a looping route use a start position and `distance` to capture the full length of the segment. This distance is a straight line / crow flies distance, not distance traveled along shape. If it errors, it most likely errors by cutting *too little* of the segment (ex: roads are in an L-shape, but straight line distance is hypotenuse).\n",
    "   * potential fix: do an extra check of the segment's endpoint to the next stop, and if distance > 0, it needs to add a bit more to the segment.\n",
    "1. too many stops are used as cut-points for a shape, there are some zero-length segments in between. \n",
    "   * in `17_debug_empty_stop_segments`, there's a between-trip variation we're not accounting for. within trip revisiting the same stop_id twice is ok. but between trips, it's possible for stop B to show up as sequence 1 and sequence 2. \n",
    "   Trip A: (A1, B2, C3). Trip B: (B1, B2). stop B, in our df assembled for segmenting, shows up as B1 and B2, and now we're cutting an empty length segment in between. \n",
    "   * the above example is a simple shift of where the bus began its trip. but, if it's happening in the middle of the trip, these switches could potentially confound how the segment is cut, since we factor in the previous stop's location when we cut the segment.\n",
    "   * potential fix: figure out a least common denominator approach for cutting segments, maybe by picking the trip with the most stops to stand-in for that shape, and cut segments from that. keeping it to 1 trip means stop sequence increases monotonically. \n",
    "   \n",
    "**Problem**: By taking into account all the trips for a shape, we're convoluting what `stop_sequence` means.\n",
    "\n",
    "Use the heuristic of picking a trip (sorted alphabetically) for the shape with the most stops. \n",
    "\n",
    "**Finding 1**: Between 95-98% of trips that share same shape have exactly same number of stops (looking at Mar-Jul 2023). The remaining are trips with the same shape_id, but have varying number of stops, usually 2 or 3 variants on number of stops. It can go up to 6 variants. Hopefully, hitting the trip with most stops will cut the segments in a least-common-denominator fashion.\n",
    "\n",
    "**Finding 2**: It is not the case that all the stops of the lesser stop numbers is a subset of the trip with most stops. But of these 2% of trips, now about 1% of them have at least 1 stop that we'd be missing. This is infrequent enough, we should just go with a trip that contains the most stop, and use that trip's stops for segmenting the shape. As long as vehicle positions can be contained (somewhere on that shape), it should fall onto a segment, even if our segment becomes longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76814ae0-98ef-467b-8294-ee159849ba66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/dask_geopandas/backends.py:13: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dask import delayed, compute\n",
    "\n",
    "from shared_utils import rt_dates\n",
    "from segment_speed_utils import helpers, gtfs_schedule_wrangling\n",
    "from segment_speed_utils.project_vars import SEGMENT_GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f7f4526-9856-4b99-a840-d357a469da8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2023-03-15', '2023-04-12', '2023-05-17', '2023-06-14', '2023-07-12']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "months = [\"mar\", \"apr\", \"may\", \"jun\", \"jul\"]\n",
    "\n",
    "dates = [\n",
    "    rt_dates.DATES[f\"{m}2023\"] for m in months\n",
    "]\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79ef5a7a-4694-456d-bb24-6a7c761ecfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stops_per_shape(date: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Import stop_times, merge in trips, and count\n",
    "    number of stops for trips grouped by shape.\n",
    "    \"\"\"\n",
    "    \n",
    "    stop_times = helpers.import_scheduled_stop_times(\n",
    "        date,\n",
    "        columns = [\"feed_key\", \"trip_id\", \"stop_sequence\", \"stop_id\"]\n",
    "    )\n",
    "\n",
    "    stops_per_trip = (stop_times.groupby([\"feed_key\", \"trip_id\"], \n",
    "                                         observed=True, group_keys=False)\n",
    "                      .agg({\"stop_id\": \"count\"})\n",
    "                      .reset_index()\n",
    "                      .rename(columns = {\"stop_id\": \"n_stops\"})\n",
    "    ).compute()\n",
    "    \n",
    "    \n",
    "    trips = helpers.import_scheduled_trips(\n",
    "        date,\n",
    "        columns = [\"feed_key\", \"name\", \"trip_id\", \"shape_array_key\"],\n",
    "        get_pandas = True\n",
    "    )\n",
    "    \n",
    "    # we exclude Amtrak and Flex in speeds\n",
    "    trips = gtfs_schedule_wrangling.exclude_scheduled_operators(trips)\n",
    "    \n",
    "    df = pd.merge(\n",
    "        trips,\n",
    "        stops_per_trip,\n",
    "        on = [\"feed_key\", \"trip_id\"],\n",
    "        how = \"inner\"\n",
    "    )\n",
    "    \n",
    "    df2 = (df.groupby(\"shape_array_key\")\n",
    "           .agg({\"n_stops\": lambda x: list(set(x))})\n",
    "           .reset_index()\n",
    "      )\n",
    "    \n",
    "    df2 = df2.assign(\n",
    "        multiple = df2.apply(lambda x: len(x.n_stops), axis=1),\n",
    "        service_date = date\n",
    "    )\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5d24168-9125-49dd-85c9-49dc64f5221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "delayed_dfs = [delayed(get_stops_per_shape)(d) for d in dates]\n",
    "results = [compute(i)[0] for i in delayed_dfs]\n",
    "\n",
    "df = pd.concat(results, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbdc31bc-fe04-4d4f-bd86-780f3df86198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-15\n",
      "1    0.963241\n",
      "2    0.026530\n",
      "3    0.007991\n",
      "4    0.001119\n",
      "5    0.000959\n",
      "6    0.000160\n",
      "Name: multiple, dtype: float64\n",
      "1    6027\n",
      "2     166\n",
      "3      50\n",
      "4       7\n",
      "5       6\n",
      "6       1\n",
      "Name: multiple, dtype: int64\n",
      "2023-04-12\n",
      "1    0.966117\n",
      "2    0.024267\n",
      "3    0.007479\n",
      "4    0.001068\n",
      "5    0.000916\n",
      "6    0.000153\n",
      "Name: multiple, dtype: float64\n",
      "1    6330\n",
      "2     159\n",
      "3      49\n",
      "4       7\n",
      "5       6\n",
      "6       1\n",
      "Name: multiple, dtype: int64\n",
      "2023-05-17\n",
      "1    0.989540\n",
      "2    0.006437\n",
      "3    0.002575\n",
      "5    0.000805\n",
      "4    0.000644\n",
      "Name: multiple, dtype: float64\n",
      "1    6149\n",
      "2      40\n",
      "3      16\n",
      "5       5\n",
      "4       4\n",
      "Name: multiple, dtype: int64\n",
      "2023-06-14\n",
      "1    0.986443\n",
      "2    0.008694\n",
      "3    0.003242\n",
      "5    0.000884\n",
      "4    0.000589\n",
      "6    0.000147\n",
      "Name: multiple, dtype: float64\n",
      "1    6694\n",
      "2      59\n",
      "3      22\n",
      "5       6\n",
      "4       4\n",
      "6       1\n",
      "Name: multiple, dtype: int64\n",
      "2023-07-12\n",
      "1    0.986163\n",
      "2    0.008630\n",
      "3    0.003273\n",
      "5    0.001042\n",
      "4    0.000744\n",
      "6    0.000149\n",
      "Name: multiple, dtype: float64\n",
      "1    6628\n",
      "2      58\n",
      "3      22\n",
      "5       7\n",
      "4       5\n",
      "6       1\n",
      "Name: multiple, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for d in dates:\n",
    "    print(d)\n",
    "    subset_df = df[df.service_date == d]\n",
    "    print(subset_df.multiple.value_counts(normalize=True))\n",
    "    print(subset_df.multiple.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c549ccb4-b27b-4a14-86e9-0c83805ec996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the shapes we need to filter for by service_date\n",
    "shapes_needed_dict =  {\n",
    "    d: df[(df.service_date == d) & \n",
    "          (df.multiple > 1)].shape_array_key.unique().tolist()\n",
    "    for d in dates\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4a1d2d7-f56b-4fe3-92f4-00b4844ee044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_stop_info(date: str, shapes_needed: dict) -> pd.DataFrame:\n",
    "    shapes_list = shapes_needed[date]\n",
    "    \n",
    "    trips = helpers.import_scheduled_trips(\n",
    "        date,\n",
    "        filters = [[(\"shape_array_key\", \"in\", shapes_list)]],\n",
    "        columns = [\"feed_key\", \"name\", \"trip_id\", \"shape_array_key\"],\n",
    "        get_pandas = True\n",
    "    )\n",
    "    \n",
    "    operators_list = trips.feed_key.unique().tolist()\n",
    "    trips_list = trips.trip_id.unique().tolist()\n",
    "\n",
    "    stop_times = helpers.import_scheduled_stop_times(\n",
    "        date,\n",
    "        filters = [[(\"feed_key\", \"in\", operators_list),\n",
    "                    (\"trip_id\", \"in\", trips_list)]],\n",
    "        columns = [\"feed_key\", \"trip_id\", \"stop_sequence\", \"stop_id\"]\n",
    "    )\n",
    "    \n",
    "    st_with_shape = dd.merge(\n",
    "        stop_times,\n",
    "        trips,\n",
    "        on = [\"feed_key\", \"trip_id\"],\n",
    "        how = \"inner\"\n",
    "    ).compute()\n",
    "    \n",
    "    df = (st_with_shape.groupby([\"feed_key\", \"name\",\n",
    "                                 \"shape_array_key\", \"trip_id\"], \n",
    "                                observed=True, group_keys=False)\n",
    "          .agg({\"stop_id\": lambda x: list(x)})\n",
    "          .reset_index()\n",
    "          .rename(columns = {\"stop_id\": \"stops_present\"})\n",
    "         )\n",
    "    \n",
    "    df = df.assign(\n",
    "        num_stops = df.apply(lambda x: len(x.stops_present), axis=1),\n",
    "        service_date = date\n",
    "    )\n",
    "    \n",
    "    df = df.assign(\n",
    "        max_stops = df.groupby(\"shape_array_key\").num_stops.transform(\"max\")\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33045a49-ccda-48e5-9d5e-bc8dfeb7d2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_stop_results = [\n",
    "    delayed(full_stop_info)(d, shapes_needed_dict) \n",
    "    for d in dates\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81b29ee6-7987-44c1-9471-c16d27a94df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_stop_results2 = [compute(i)[0] for i in full_stop_results]\n",
    "\n",
    "full_df = (pd.concat(full_stop_results2, axis=0)\n",
    "           .sort_values([\"service_date\", \"shape_array_key\", \n",
    "                         \"num_stops\", \"trip_id\"], \n",
    "                        ascending=[True, True, False, True])\n",
    "           .reset_index(drop=True)\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "963e3b0d-f8b8-44a6-8c83-ab123bfafda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's keep the unique variations of num_stops\n",
    "full_df2 = full_df.drop_duplicates(\n",
    "    subset=[\"service_date\", \"feed_key\", \"shape_array_key\", \n",
    "    \"num_stops\", \"max_stops\"]\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46767c05-1f88-4fa9-b45b-a6ee79bb6099",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df2 = full_df2.assign(\n",
    "    list_max_stops = full_df2.apply(\n",
    "        lambda x: x.stops_present \n",
    "        if x.num_stops == x.max_stops else np.nan, axis=1)\n",
    ")\n",
    "\n",
    "full_df2 = full_df2.assign(\n",
    "    list_max_stops = full_df2.groupby(\n",
    "        [\"feed_key\", \"shape_array_key\", \"service_date\"]\n",
    "    ).list_max_stops.fillna(method = 'ffill')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4e88970-181b-4bc0-bc84-7fb28d40cd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df2 = full_df2.assign(\n",
    "    missing_stops = full_df2.apply(\n",
    "        lambda x: \n",
    "        list(\n",
    "            set(x.stops_present).difference(set(x.list_max_stops))\n",
    "        ), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6018e994-2c2c-4ae9-a868-8b873e26b9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]                                                   0.993035\n",
       "[2436343]                                            0.003482\n",
       "[80403, 80406, 80407, 80401, 80402, 80404, 80405]    0.001161\n",
       "[515, 503]                                           0.001161\n",
       "[510, 535, 513]                                      0.000580\n",
       "[510, 513, 535]                                      0.000580\n",
       "Name: missing_stops, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df2.missing_stops.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66db8535-4273-462a-8f45-82834356ba0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7d12db085da6cd5cff99680c147cba9a    6\n",
       "49edd787a8f56c4e96b6b3c128e91a6e    2\n",
       "a05e032fbc7f677fdc9afaa6c1b20f3c    2\n",
       "b9e5620a5f48b1104b87195858c893b0    2\n",
       "Name: feed_key, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/56903912/how-to-check-if-an-element-is-an-empty-list-in-pandas\n",
    "full_df2[full_df2.missing_stops.str.len() != 0].feed_key.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b7ca9cf-a108-46e3-82b5-030ee2d7f659",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_operators = full_df2[full_df2.missing_stops.str.len() != 0\n",
    "                          ].feed_key.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0395c60-4e9e-43a7-9ce4-447d6f6bef2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2023-03-15    28\n",
       "2023-04-12    10\n",
       "2023-05-17     6\n",
       "2023-06-14     6\n",
       "Name: service_date, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df2[full_df2.feed_key.isin(check_operators)].service_date.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96b08227-3da8-4575-8f40-40d9202aa604",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_trips = full_df2[full_df2.feed_key.isin(check_operators)\n",
    "                      ].trip_id.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7160d15-07ff-4b65-8cb4-16817daec937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feed_key</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7d12db085da6cd5cff99680c147cba9a</td>\n",
       "      <td>Amador Schedule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b9e5620a5f48b1104b87195858c893b0</td>\n",
       "      <td>Tuolumne Schedule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49edd787a8f56c4e96b6b3c128e91a6e</td>\n",
       "      <td>LA Metro Rail Schedule</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           feed_key                    name\n",
       "0  7d12db085da6cd5cff99680c147cba9a         Amador Schedule\n",
       "1  b9e5620a5f48b1104b87195858c893b0       Tuolumne Schedule\n",
       "2  49edd787a8f56c4e96b6b3c128e91a6e  LA Metro Rail Schedule"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helpers.import_scheduled_trips(\n",
    "    dates[0],\n",
    "    filters = [[(\"feed_key\", \"in\", check_operators)]],\n",
    "    columns = [\"feed_key\", \"name\"],\n",
    "    get_pandas = True\n",
    ").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1f23722-e3f9-4591-a328-c4be056388e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips2 = helpers.import_scheduled_trips(\n",
    "    dates[0],\n",
    "    filters = [[(\"feed_key\", \"in\", check_operators), \n",
    "                (\"trip_id\", \"in\", check_trips)\n",
    "               ]],\n",
    "    columns = [\"feed_key\", \"name\",\n",
    "               \"shape_array_key\", \"trip_id\"],\n",
    "    get_pandas = True\n",
    ").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0fedf07-fd64-42c2-92e9-b687e80eed36",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_me = helpers.import_scheduled_stop_times(\n",
    "    dates[0],\n",
    "    filters = [[(\"feed_key\", \"in\", check_operators),\n",
    "        (\"trip_id\", \"in\", trips2.trip_id.unique().tolist())]],\n",
    "    columns = [\"feed_key\", \"trip_id\", \"stop_id\", \"stop_sequence\"]\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8599fd4f-b2c8-40b3-86f4-f4aa765b9b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_me2 = pd.merge(\n",
    "    check_me,\n",
    "    trips2,\n",
    "    on = [\"feed_key\", \"trip_id\"],\n",
    "    how = \"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bd02fe2-c5b9-43aa-9b29-e38ed9fc5445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shape_array_key</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>name</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111a979d3a4d17bb74e18488c470a544</td>\n",
       "      <td>57706684</td>\n",
       "      <td>LA Metro Rail Schedule</td>\n",
       "      <td>[80109, 80110, 80111, 80112, 80113, 80114, 801...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111a979d3a4d17bb74e18488c470a544</td>\n",
       "      <td>57706689</td>\n",
       "      <td>LA Metro Rail Schedule</td>\n",
       "      <td>[80101, 80102, 80105, 80106, 80107, 80108, 801...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1b9cfa59b70c557cc833ef560e80b9de</td>\n",
       "      <td>57706683</td>\n",
       "      <td>LA Metro Rail Schedule</td>\n",
       "      <td>[80122, 80121, 80120, 80119, 80118, 80117, 801...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1b9cfa59b70c557cc833ef560e80b9de</td>\n",
       "      <td>57706686</td>\n",
       "      <td>LA Metro Rail Schedule</td>\n",
       "      <td>[80118, 80117, 80116, 80115, 80114, 80113, 801...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1b9cfa59b70c557cc833ef560e80b9de</td>\n",
       "      <td>57706703</td>\n",
       "      <td>LA Metro Rail Schedule</td>\n",
       "      <td>[80108, 80107, 80106, 80105, 80154, 80153, 80101]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    shape_array_key   trip_id                    name  \\\n",
       "0  111a979d3a4d17bb74e18488c470a544  57706684  LA Metro Rail Schedule   \n",
       "1  111a979d3a4d17bb74e18488c470a544  57706689  LA Metro Rail Schedule   \n",
       "2  1b9cfa59b70c557cc833ef560e80b9de  57706683  LA Metro Rail Schedule   \n",
       "3  1b9cfa59b70c557cc833ef560e80b9de  57706686  LA Metro Rail Schedule   \n",
       "4  1b9cfa59b70c557cc833ef560e80b9de  57706703  LA Metro Rail Schedule   \n",
       "\n",
       "                                             stop_id  \\\n",
       "0  [80109, 80110, 80111, 80112, 80113, 80114, 801...   \n",
       "1  [80101, 80102, 80105, 80106, 80107, 80108, 801...   \n",
       "2  [80122, 80121, 80120, 80119, 80118, 80117, 801...   \n",
       "3  [80118, 80117, 80116, 80115, 80114, 80113, 801...   \n",
       "4  [80108, 80107, 80106, 80105, 80154, 80153, 80101]   \n",
       "\n",
       "                                       stop_sequence  \n",
       "0    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  \n",
       "1  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...  \n",
       "2  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...  \n",
       "3  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...  \n",
       "4                              [1, 2, 3, 4, 5, 6, 7]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_me2.sort_values(\n",
    "    [\"shape_array_key\", \"trip_id\", \"stop_sequence\"]\n",
    ").groupby(\n",
    "    [\"shape_array_key\", \"trip_id\", \"name\"]\n",
    ").agg({\n",
    "    \"stop_id\": lambda x: list(x),\n",
    "    \"stop_sequence\": lambda x: list(x),\n",
    "}).reset_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcbb2e2-8e23-48fc-b983-3093f809baa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
