{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91650562-357e-465f-9912-09e8a2e574aa",
   "metadata": {},
   "source": [
    "# Refactor bus corridors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d229973-9381-4177-9a23-7e07b9d041d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/geopandas/_compat.py:111: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.date(2022, 6, 15)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CALITP_BQ_MAX_BYTES\"] = str(900_000_000_000) ## 800GB?\n",
    "\n",
    "import datetime as dt\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import zlib\n",
    "\n",
    "from siuba import *\n",
    "\n",
    "import utilities\n",
    "import A1_rail_ferry_brt as rail_ferry_brt\n",
    "\n",
    "from shared_utils import rt_utils\n",
    "\n",
    "GCS_FILE_PATH = utilities.GCS_FILE_PATH\n",
    "\n",
    "analysis_date = rail_ferry_brt.analysis_date\n",
    "analysis_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d65db0-c8df-4c16-9490-0f0514b12776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calitp-analytics-data/data-analyses/high_quality_transit_areas/bus_corridors/182_bus.parquet\n",
    "bus_corridor = gpd.read_parquet(f\"{GCS_FILE_PATH}bus_corridors/182_bus.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6527720a-d514-474a-9127-e6c3c7192e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bus_corridor2 = gpd.read_parquet(\"./data/182_bus2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aba8372-d0d1-43d0-bcc2-b5dbdd9b34de",
   "metadata": {},
   "outputs": [],
   "source": [
    "itp_id = 182\n",
    "date_str = analysis_date.strftime(rt_utils.FULL_DATE_FMT)\n",
    "\n",
    "# Skip writing geoparquet again for now \n",
    "# TODO: tweak rt_utils to overwrite export? \n",
    "# Overwriting while testing this is not ideal, don't want to mess it up\n",
    "\n",
    "#routelines = rt_utils.get_routelines(itp_id, analysis_date)\n",
    "#routelines = gpd.read_parquet(f\"{rt_utils.GCS_FILE_PATH}\"\n",
    "#                             f\"cached_views/routelines_{itp_id}_{date_str}.parquet\" \n",
    "#                            )\n",
    "\n",
    "#routelines.to_parquet(f\"./data/routelines_{itp_id}_{date_str}.parquet\")\n",
    "\n",
    "## force clear to ensure route type data present\n",
    "#trips = rt_utils.get_trips(itp_id, analysis_date, force_clear=True, route_types = ['3'])\n",
    "#trips.to_parquet(f\"./data/trips_{itp_id}_{date_str}.parquet\")\n",
    "\n",
    "#stop_times = rt_utils.get_stop_times(itp_id, analysis_date)\n",
    "#stop_times.to_parquet(f\"./data/st_{itp_id}_{date_str}.parquet\")\n",
    "\n",
    "#stops = rt_utils.get_stops(itp_id, analysis_date)\n",
    "#stops.to_parquet(f\"./data/stops_{itp_id}_{date_str}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f924152-711f-4967-96dd-c413a051045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "routelines = gpd.read_parquet(f\"./data/routelines_{itp_id}_{date_str}.parquet\")\n",
    "trips = pd.read_parquet(f\"./data/trips_{itp_id}_{date_str}.parquet\")\n",
    "stop_times = pd.read_parquet(f\"./data/st_{itp_id}_{date_str}.parquet\")\n",
    "stops = gpd.read_parquet(f\"./data/stops_{itp_id}_{date_str}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4958923-8f38-4d4a-8bd8-fc86293dd495",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7126eec-c23b-4314-892d-fa3f854498ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "\n",
    "\n",
    "ddf = dd.read_parquet(f\"{rt_utils.GCS_FILE_PATH}\"\n",
    "                             f\"cached_views/st_{itp_id}_{date_str}.parquet\")\n",
    "stop_times = pd.read_parquet(f\"{rt_utils.GCS_FILE_PATH}\"\n",
    "                             f\"cached_views/st_{itp_id}_{date_str}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd47cbc6-7622-402c-a6f8-d0ab3a5b4664",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = dd.read_parquet(f\"{rt_utils.GCS_FILE_PATH}\"\n",
    "                             f\"cached_views/st_{itp_id}_{date_str}.parquet\")\n",
    "\n",
    "#https://stackoverflow.com/questions/45428292/how-to-convert-pandas-str-split-call-to-to-dask\n",
    "ddf = ddf.assign(\n",
    "    **{\"departure_hour\": ddf.departure_time.str.partition(\":\")[0].astype(int)}\n",
    ")\n",
    "\n",
    "#https://stackoverflow.com/questions/54955833/apply-a-lambda-function-to-a-dask-dataframe\n",
    "ddf[\"departure_hour\"] = ddf.departure_hour.map(lambda x: x-24 if x >=24 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdb2a44d-b1dc-4be5-bbc5-2cbac0ed158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_per_hour = (ddf.groupby([\"calitp_itp_id\", \"stop_id\", \"departure_hour\"])\n",
    "                  .agg({'trip_id': 'count'})\n",
    "                  .reset_index()\n",
    "                  .rename(columns = {\"trip_id\": \"n_trips\"})\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8aa99f2-3cf7-4850-a4a1-08b5984e25a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.dataframe.core.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trips_per_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef6bfaf-768e-48e1-a9bc-21c59a66654a",
   "metadata": {},
   "source": [
    "## All shapes for operator\n",
    "* Dissolve by length, and generate segments at once\n",
    "* Join stops once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07a6b95-5ce2-45be-a883-f5d13227fc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_times.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715b1539-1d51-409b-b6e9-f43983f7a319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
