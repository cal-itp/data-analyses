{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e37ce21c-ae28-4359-89b8-f628f852c489",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edasmalchi/anaconda3/envs/pd1/lib/python3.9/site-packages/google/auth/_default.py:68: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import calitp\n",
    "from calitp.tables import tbl\n",
    "from siuba import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "\n",
    "from ipyleaflet import Map, GeoJSON, projections, basemaps, GeoData, LayersControl, WidgetControl, GeoJSON\n",
    "from ipywidgets import Text, HTML\n",
    "\n",
    "import shapely\n",
    "from shapely.geometry import LineString, MultiPoint\n",
    "from shapely.ops import split, substring\n",
    "\n",
    "import zlib\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c50342-09f6-4d18-96fb-d950a304d0e1",
   "metadata": {},
   "source": [
    "### High Quality Transit Areas Relevant Statutes\n",
    "\n",
    "[PRC 21155](https://leginfo.legislature.ca.gov/faces/codes_displaySection.xhtml?sectionNum=21155.&lawCode=PRC)\n",
    "* Major transit stop definition: _A major transit stop is as defined in Section 21064.3, except that, for purposes of this section, it also includes major transit stops that are included in the applicable regional transportation plan_\n",
    "* High-quality transit corridor definition: _For purposes of this section, a high-quality transit corridor means a corridor with fixed route bus service with service intervals no longer than 15 minutes during peak commute hours._\n",
    "    * Unable to locate definition of \"peak commute hours\"\n",
    "\n",
    "[PRC 21064.3](https://leginfo.legislature.ca.gov/faces/codes_displaySection.xhtml?sectionNum=21064.3.&lawCode=PRC)\n",
    "* _Major transit stop means a site containing any of the following:\n",
    "(a) An existing rail or bus rapid transit station.\n",
    "(b) A ferry terminal served by either a bus or rail transit service.\n",
    "(c) The intersection of two or more major bus routes with a frequency of service interval of 15 minutes or less during the morning and afternoon peak commute periods._\n",
    "    * \"Intersection\" may not be sufficiently well-defined for this analysis\n",
    "\n",
    "[PRC 21060.2](https://leginfo.legislature.ca.gov/faces/codes_displaySection.xhtml?lawCode=PRC&sectionNum=21060.2.&highlight=true&keyword=bus%20rapid%20transit)\n",
    "* _(a) “Bus rapid transit” means a public mass transit service provided by a public agency or by a public-private partnership that includes all of the following features:\n",
    "(1) Full-time dedicated bus lanes or operation in a separate right-of-way dedicated for public transportation with a frequency of service interval of 15 minutes or less during the morning and afternoon peak commute periods.\n",
    "(2) Transit signal priority.\n",
    "(3) All-door boarding.\n",
    "(4) Fare collection system that promotes efficiency.\n",
    "(5) Defined stations._\n",
    "    * Unlikely to determine if a service qualifies as BRT under this definition using GTFS alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25b4b77d-3d2e-4ecc-a6db-fa27aecf71db",
   "metadata": {},
   "outputs": [],
   "source": [
    "##definition of \"peak\" pending\n",
    "am_peak = range(6, 9)\n",
    "pm_peak = range(16, 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed58ef3a-f454-4f00-9202-bae1dc82f92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_commute_hours = list(am_peak)\n",
    "pm_commute_hours = list(pm_peak)\n",
    "commute_hours = am_commute_hours + pm_commute_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0377ee1-4bc3-4010-ad1f-2318072a5c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 7, 8, 16, 17, 18]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commute_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d8165e1-492a-4013-bb1f-de1b252fa5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_segments(geometry, prior_operators_hqta):\n",
    "    '''Splits a Shapely LineString into smaller LineStrings. If a MultiLineString passed,\n",
    "    splits each LineString in that collection. \n",
    "    '''\n",
    "    ##TODO clip prior operator geometry to this linestring, preserve those geoms+ids before calculating new segments\n",
    "    ##TODO keep full prior operator segments only, otherwise calculate new\n",
    "    \n",
    "    lines = []\n",
    "    segment_distance_meters = 1500\n",
    "    geometry = geometry.iloc[0]\n",
    "    if hasattr(geometry, 'geoms'): ##check if MultiLineString\n",
    "        linestrings = geometry.geoms\n",
    "    else:\n",
    "        linestrings = [geometry]\n",
    "    for linestring in linestrings:\n",
    "        for i in range(0, int(linestring.length), segment_distance_meters):\n",
    "            lines.append(substring(linestring, i, i+segment_distance_meters))\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b0552f1-5ad4-4f50-a63e-76116b788f26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_stop_with_most_routes(segment, stops, route_count_by_stop):\n",
    "    '''Given a shape segment, finds the stop serving the most routes within that segment.\n",
    "    Adds that stop's stop_id to segment data (a row).\n",
    "    '''\n",
    "    # print(segment.hqta_segment_id)\n",
    "    # display(segment.geometry)\n",
    "    stops_in_seg = gpd.clip(stops, segment.geometry)\n",
    "    if stops_in_seg.size == 0:\n",
    "        return segment\n",
    "    # display(stops_in_seg)\n",
    "    debug_dict['stops_in_seg'] = stops_in_seg\n",
    "    max_routes_stop = (stops_in_seg\n",
    "                   >> inner_join(_, route_count_by_stop, on = \"stop_id\")\n",
    "                   >> filter(_.n_routes == _.n_routes.max())\n",
    "                  ).iloc[[0]]\n",
    "    segment['stop_id'] = max_routes_stop['stop_id'].iloc[0]\n",
    "    segment['n_routes'] = max_routes_stop['n_routes'].iloc[0]\n",
    "    return segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c84d2291-d9fb-4945-b59c-d5070ecc6eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_trips_in_segments(segments, stops, stop_times):\n",
    "    stops_in_seg = gpd.sjoin(segments, stops, how='inner')\n",
    "    if stops_in_seg.size == 0:\n",
    "        print('uh-oh')\n",
    "        return\n",
    "    stop_times_in_seg = stops_in_seg >> inner_join(_, stop_times, on = 'stop_id')\n",
    "    trip_count_by_stop = stop_times_in_seg >> count(_.stop_id) >> arrange(-_.n) >> rename(n_trips = _.n)\n",
    "    top_3_stops = trip_count_by_stop.stop_id.iloc[:3]\n",
    "    stop_times_in_seg >> filter(_.stop_id.isin(top_3_stops))\n",
    "    return stop_times_in_seg.drop_duplicates(subset=['trip_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65c74fbd-059f-4df8-a3a1-e6c1361489b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_operator_views(itp_id):\n",
    "    '''Returns relevant views from the data warehouse for a single transit operator.\n",
    "    '''\n",
    "    shapes = tbl.gtfs_schedule.shapes() >> filter(_.calitp_itp_id == int(itp_id)) >> collect()\n",
    "    shapes = gpd.GeoDataFrame(shapes, \n",
    "                              geometry = gpd.points_from_xy(shapes.shape_pt_lon, shapes.shape_pt_lat),\n",
    "                              crs = 'EPSG:4326').to_crs('EPSG:6414') ## https://epsg.io/6414 (meters)\n",
    "    print('loaded shapes')\n",
    "\n",
    "    cal_wednesdays = (tbl.gtfs_schedule.calendar()\n",
    "                      >> filter(_.calitp_itp_id == int(itp_id))\n",
    "                      >> filter(_.wednesday == '1')\n",
    "                      >> collect())\n",
    "    bus_routes = (tbl.gtfs_schedule.routes()\n",
    "                    >> filter(_.calitp_itp_id == int(itp_id))\n",
    "                    >> filter(_.route_type.isin(['3', '11'])) ## bus and trolleybus\n",
    "                    >> select(_.route_id) >> collect())\n",
    "    print('loaded bus routes')\n",
    "    trips = (tbl.gtfs_schedule.trips()\n",
    "             >> filter(_.calitp_itp_id == int(itp_id))\n",
    "             >> filter(_.service_id.isin(cal_wednesdays.service_id))\n",
    "             >> filter(_.route_id.isin(bus_routes.route_id))\n",
    "             >> collect())\n",
    "    print('loaded trips')\n",
    "    stop_times = (tbl.gtfs_schedule.stop_times()\n",
    "                  >> filter(_.calitp_itp_id == int(itp_id))\n",
    "                  >> collect())\n",
    "    stop_times =  (stop_times >> filter(_.trip_id.isin(trips.trip_id))\n",
    "                  >> select(-_.calitp_itp_id, -_.calitp_extracted_at))\n",
    "    print('loaded stop times')\n",
    "\n",
    "    stops = (tbl.gtfs_schedule.stops() \n",
    "             >> filter(_.calitp_itp_id == itp_id)\n",
    "             >> select(_.stop_id, _.stop_lat, _.stop_lon)\n",
    "             >> collect())\n",
    "    stops = gpd.GeoDataFrame(stops,\n",
    "                     geometry = gpd.points_from_xy(stops.stop_lon, stops.stop_lat),\n",
    "                     crs = 'EPSG:4326').to_crs('EPSG:6414') ## https://epsg.io/6414 (meters)\n",
    "    print('loaded stops')\n",
    "\n",
    "    return shapes, trips, stop_times, stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1049eee5-d4d9-43a1-9a84-c3bd3687f6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_arrival_time(gtfs_timestring):\n",
    "    '''Reformats a GTFS timestamp (which allows the hour to exceed 24 to mark service day continuity)\n",
    "    to standard 24-hour time.\n",
    "    '''\n",
    "    split = gtfs_timestring.split(':')\n",
    "    hour = int(split[0])\n",
    "    if hour >= 24:\n",
    "        split[0] = str(hour - 24)\n",
    "        corrected = (':').join(split)\n",
    "        return corrected\n",
    "    else:\n",
    "        return gtfs_timestring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d3207be-d38f-4f17-a97f-0f84cae25d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_shape_hqta(shapes, trips, stop_times, stops, route_count_by_stop, shape_id, hqta, prior_operators_hqta=None):\n",
    "    '''Starting with a single GTFS shape, split that shape into segments and determine if each segment qualifies\n",
    "    as an HQTA. Existing segments within a shape are dropped for that shape, since their peak frequency and \n",
    "    HQTA status would have already been calculated for a previous shape.\n",
    "    '''\n",
    "\n",
    "    \n",
    "    single_shape = (shapes\n",
    "         >> filter(_.shape_id == shape_id)\n",
    "         >> mutate(shape_pt_sequence = _.shape_pt_sequence.astype('int64'))\n",
    "         >> arrange(_.shape_pt_sequence) ##arrange, then convert to line to preserve order...\n",
    "        )\n",
    "    \n",
    "    route_line = LineString(list(single_shape['geometry']))\n",
    "    single_line = single_shape[['calitp_itp_id', 'shape_id', 'calitp_extracted_at']].iloc[[0]] ##preserve info cols\n",
    "    single_line['geometry'] = route_line\n",
    "    single_line = gpd.GeoDataFrame(single_line, crs='EPSG:6414')\n",
    "    \n",
    "    if shape_id in debug_ids:\n",
    "        print(f'***debug shape*** {shape_id}')\n",
    "        debug_dict[f'{shape_id}_single_line'] = single_line\n",
    "        debug_dict[f'{shape_id}_hqta'] = hqta\n",
    "\n",
    "        ## test a shapes df split into segments\n",
    "    if hqta.size != 0:\n",
    "        already_calculated = hqta.dissolve(by='calitp_itp_id') ## get single polygon of HQTA calculation complete area\n",
    "        single_line = single_line.overlay(already_calculated, how='difference') ## drop calculation complete area from current shape\n",
    "        if single_line.size == 0:\n",
    "            segments_with_max_stop = None\n",
    "            print(f'no line for shape {shape_id}')\n",
    "            return\n",
    "\n",
    "    segmented = pd.DataFrame()\n",
    "    for segment in create_segments(single_line.geometry, prior_operators_hqta):\n",
    "        to_append = single_line.drop(columns=['geometry'])\n",
    "        to_append['geometry'] = segment\n",
    "        segmented = segmented.append(to_append)\n",
    "        \n",
    "    segmented = segmented.reset_index()\n",
    "    segmented['segment_sequence'] = segmented.index.astype(str)\n",
    "    segmented = segmented.astype({'calitp_itp_id': str})\n",
    "    \n",
    "    ## compute (hopefully unique) hash of segment id that can be used across routes/operators\n",
    "    segmented['hqta_segment_id'] = segmented.apply(lambda x:\n",
    "                zlib.crc32((x.calitp_itp_id + x.shape_id + x.segment_sequence).encode('utf-8')), axis=1)\n",
    "    \n",
    "    segmented.geometry = segmented.buffer(50) ##generous buffer for street/sidewalk width? Required to spatially find stops within each segment\n",
    "\n",
    "    if shape_id in debug_ids:\n",
    "        debug_dict[f'{shape_id}_segmented'] = segmented\n",
    "        debug_dict[f'{shape_id}_stops'] = stops\n",
    "        debug_dict[f'{shape_id}_route_ct_by_stop'] = route_count_by_stop\n",
    "    \n",
    "    # try:\n",
    "    segments_with_max_stop = segmented.apply(find_stop_with_most_routes, axis=1,\n",
    "                                             args = (stops, route_count_by_stop))\n",
    "    if not 'stop_id' in segments_with_max_stop.columns:\n",
    "        segments_with_max_stop = None\n",
    "        print(f'no stops for shape {shape_id}')\n",
    "        return ## no stops within segment\n",
    "\n",
    "    max_stop_times = (stop_times \n",
    "                 >> select(_.stop_id, _.trip_id, _.departure_time)\n",
    "                 >> inner_join(_, segments_with_max_stop, on = \"stop_id\")\n",
    "                ) ## filter stop_times to the key stops in each segment\n",
    "    \n",
    "    if shape_id in debug_ids:\n",
    "        debug_dict[f'{shape_id}_max_stop0'] = max_stop_times\n",
    "    \n",
    "    max_stop_times['departure_time'] = max_stop_times['departure_time'].apply(fix_arrival_time) ## reformat GTFS time to a format datetime can ingest\n",
    "    max_stop_times['departure_hour'] = max_stop_times['departure_time'].apply(lambda x:\n",
    "                                                                    dt.datetime.strptime(x, '%H:%M:%S').hour)\n",
    "    \n",
    "    max_stop_times = max_stop_times >> filter(_.departure_hour.isin(commute_hours))\n",
    "    \n",
    "    if max_stop_times.size == 0:\n",
    "        print(f'no commute hour trips for shape {shape_id}')\n",
    "        return\n",
    "    \n",
    "    if shape_id in debug_ids:\n",
    "        debug_dict[f'{shape_id}_max_stop'] = max_stop_times\n",
    "        \n",
    "    max_stop_times['am_peak'] = max_stop_times['departure_hour'].apply(lambda x: x in am_commute_hours)\n",
    "    max_stop_times['pm_peak'] = ~max_stop_times['am_peak']\n",
    "    \n",
    "    segment_peak_service = max_stop_times.groupby(['hqta_segment_id'])[['am_peak', 'pm_peak']].sum() ## count total trips at stop during each peak period\n",
    "    \n",
    "    ## convert to trips per hour\n",
    "    segment_peak_service['am_peak'] = (segment_peak_service['am_peak'] / len(am_commute_hours)).round(1)\n",
    "    segment_peak_service['pm_peak'] = (segment_peak_service['pm_peak'] / len(pm_commute_hours)).round(1)\n",
    "    \n",
    "    if shape_id in debug_ids:\n",
    "        debug_dict[f'{shape_id}_segment_peak'] = segment_peak_service\n",
    "\n",
    "    ## consider segment HQTA if stop within segment has at least 4 trips/hour in both peaks\n",
    "    segment_peak_service['hq_transit_corr'] = segment_peak_service.apply(lambda x:\n",
    "                              True if x.am_peak >= 4 and x.pm_peak >= 4 else False, axis=1)\n",
    "    \n",
    "    segment_peak_service = segment_peak_service.reset_index()\n",
    "    segment_peak_service['last_seg_hqta'] = segment_peak_service['hq_transit_corr'].shift(1)\n",
    "    segment_peak_service['next_seg_hqta'] = segment_peak_service['hq_transit_corr'].shift(-1)\n",
    "    \n",
    "    ## consider segment not HQTA if both the prior and next segements are not HQTAs\n",
    "    segment_peak_service['hq_transit_corr'] = segment_peak_service.apply(\n",
    "            lambda x: False if x.hq_transit_corr == False else x.last_seg_hqta or x.next_seg_hqta, axis = 1)\n",
    "    segment_peak_service['hq_transit_corr'] = segment_peak_service['hq_transit_corr'].fillna(True)\n",
    "    \n",
    "    single_hqta = segments_with_max_stop >> inner_join(_, segment_peak_service, on = 'hqta_segment_id')\n",
    "    single_hqta.drop(columns=['calitp_extracted_at', 'next_seg_hqta', 'last_seg_hqta'], inplace=True)\n",
    "    \n",
    "    if shape_id in debug_ids:\n",
    "        debug_dict[f'{shape_id}_single_hqta'] = single_hqta\n",
    "    \n",
    "    return single_hqta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9483141f-c197-4fc8-80f0-4efa8d2b44c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_operator_hqta(views, hqta_df=None):  \n",
    "    \n",
    "    global debug_dict\n",
    "    debug_dict = {}\n",
    "    \n",
    "    shapes, trips, stop_times, stops = views\n",
    "    \n",
    "    if hqta_df and hqta_df.size > 0:\n",
    "        prior_operators_hqta = hqta_df\n",
    "    else:\n",
    "        prior_operators_hqta = None\n",
    "    \n",
    "    distinct_routes = (trips\n",
    "                   >> distinct(_.route_id, _.shape_id, _.direction_id, _keep_all = True)\n",
    "                   >> select(_.calitp_itp_id, _.route_id, _.shape_id, _.direction_id, _.trip_id))\n",
    "    \n",
    "    route_count_by_stop = (stop_times\n",
    "                         >> select(_.stop_id, _.trip_id)\n",
    "                         >> inner_join(_, distinct_routes, on = \"trip_id\")\n",
    "                         >> count(_.stop_id)\n",
    "                         >> rename(n_routes = _.n)\n",
    "                         >> arrange(-_.n_routes))    \n",
    "    \n",
    "    hqta = gpd.GeoDataFrame()\n",
    "    ## start with shapes including the highest number of trips\n",
    "    shapes_sorted = trips.groupby('shape_id').count().sort_values(by='trip_id', ascending=False).index\n",
    "    shapes_sorted = pd.Series(shapes_sorted)\n",
    "    total_shapes = len(shapes_sorted)\n",
    "    print(f'there are {total_shapes} shapes total')\n",
    "    for ix, shape_id in shapes_sorted.items():\n",
    "        print(f'calculating for shape_id {shape_id}')\n",
    "        if ix % 25 == 0:\n",
    "            print(f'progress: {ix}/{total_shapes} shapes ({round(((ix/total_shapes)*100), 2)}%)')\n",
    "        # try:\n",
    "        _result = single_shape_hqta(shapes, trips, stop_times, stops, route_count_by_stop,\n",
    "                                    shape_id, hqta, prior_operators_hqta)\n",
    "        hqta = hqta.append(_result)\n",
    "        # except:\n",
    "        #     print(f'unable to calculate HQTA for shape_id {shape_id}')\n",
    "        try:\n",
    "            hqta = hqta.set_crs('EPSG:6414')\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    return hqta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9d94df4-21cd-46d6-a8ab-fe4d4c01d728",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_ids = ['shp-6-21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ccf77c1-c8c6-4076-8b9a-c59eb5163030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded shapes\n",
      "loaded bus routes\n",
      "loaded trips\n",
      "loaded stop times\n",
      "loaded stops\n"
     ]
    }
   ],
   "source": [
    "bbb_views = get_operator_views(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85ca7d2d-c9d6-445c-a89d-1aba76c19b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 66 shapes total\n",
      "calculating for shape_id 25351\n",
      "progress: 0/66 shapes (0.0%)\n",
      "calculating for shape_id 25352\n",
      "calculating for shape_id 25315\n",
      "calculating for shape_id 25325\n",
      "calculating for shape_id 25331\n",
      "calculating for shape_id 25314\n",
      "calculating for shape_id 25326\n",
      "calculating for shape_id 25333\n",
      "calculating for shape_id 25354\n",
      "calculating for shape_id 25358\n",
      "calculating for shape_id 25365\n",
      "calculating for shape_id 25368\n",
      "calculating for shape_id 25382\n",
      "calculating for shape_id 25400\n",
      "no stops for shape 25400\n",
      "calculating for shape_id 25399\n",
      "no stops for shape 25399\n",
      "calculating for shape_id 25320\n",
      "calculating for shape_id 25323\n",
      "calculating for shape_id 25376\n",
      "no stops for shape 25376\n",
      "calculating for shape_id 25380\n",
      "no stops for shape 25380\n",
      "calculating for shape_id 25340\n",
      "calculating for shape_id 25337\n",
      "calculating for shape_id 25363\n",
      "calculating for shape_id 25369\n",
      "calculating for shape_id 25372\n",
      "no stops for shape 25372\n",
      "calculating for shape_id 25343\n",
      "calculating for shape_id 25346\n",
      "progress: 25/66 shapes (37.88%)\n",
      "calculating for shape_id 25364\n",
      "calculating for shape_id 25374\n",
      "no stops for shape 25374\n",
      "calculating for shape_id 25370\n",
      "calculating for shape_id 25385\n",
      "calculating for shape_id 25384\n",
      "no line for shape 25384\n",
      "calculating for shape_id 25361\n",
      "calculating for shape_id 25313\n",
      "no line for shape 25313\n",
      "calculating for shape_id 25362\n",
      "calculating for shape_id 25318\n",
      "calculating for shape_id 25327\n",
      "calculating for shape_id 25332\n",
      "no line for shape 25332\n",
      "calculating for shape_id 25328\n",
      "calculating for shape_id 25375\n",
      "no line for shape 25375\n",
      "calculating for shape_id 25336\n",
      "no line for shape 25336\n",
      "calculating for shape_id 25402\n",
      "no line for shape 25402\n",
      "calculating for shape_id 25379\n",
      "no line for shape 25379\n",
      "calculating for shape_id 25357\n",
      "calculating for shape_id 25321\n",
      "no stops for shape 25321\n",
      "calculating for shape_id 25359\n",
      "calculating for shape_id 25339\n",
      "no line for shape 25339\n",
      "calculating for shape_id 25398\n",
      "no line for shape 25398\n",
      "calculating for shape_id 25349\n",
      "calculating for shape_id 25348\n",
      "calculating for shape_id 25342\n",
      "no line for shape 25342\n",
      "calculating for shape_id 25371\n",
      "progress: 50/66 shapes (75.76%)\n",
      "no stops for shape 25371\n",
      "calculating for shape_id 25311\n",
      "no line for shape 25311\n",
      "calculating for shape_id 25367\n",
      "no line for shape 25367\n",
      "calculating for shape_id 25356\n",
      "calculating for shape_id 25355\n",
      "no stops for shape 25355\n",
      "calculating for shape_id 25335\n",
      "calculating for shape_id 25322\n",
      "no line for shape 25322\n",
      "calculating for shape_id 25319\n",
      "no stops for shape 25319\n",
      "calculating for shape_id 25403\n",
      "no line for shape 25403\n",
      "calculating for shape_id 25353\n",
      "no line for shape 25353\n",
      "calculating for shape_id 25334\n",
      "no line for shape 25334\n",
      "calculating for shape_id 25330\n",
      "no line for shape 25330\n",
      "calculating for shape_id 25329\n",
      "no stops for shape 25329\n",
      "calculating for shape_id 25324\n",
      "no stops for shape 25324\n",
      "calculating for shape_id 25317\n",
      "no line for shape 25317\n",
      "calculating for shape_id 25316\n",
      "no line for shape 25316\n"
     ]
    }
   ],
   "source": [
    "bbb_hqta = single_operator_hqta(bbb_views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc21e894-3e26-4677-9106-86b9872cd94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ccb_views = get_operator_views(87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fd76833-26d7-47d6-aa6d-0781ce6c2413",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ccb_hqta = single_operator_hqta(ccb_views)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ff47bb-276b-4f0c-8635-e3ceb108010c",
   "metadata": {},
   "source": [
    "### Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "979e15cf-6887-4b7a-ae5d-a6efcd02a667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_hqta(hqta):\n",
    "    \n",
    "    x = hqta['geometry'].to_crs('EPSG:4326').iloc[0].centroid.x\n",
    "    y = hqta['geometry'].to_crs('EPSG:4326').iloc[0].centroid.y\n",
    "    \n",
    "    m = Map(basemap=basemaps.CartoDB.Positron, center=[y, x], zoom=11)\n",
    "    geo_data_hq = GeoData(geo_dataframe = hqta[hqta['hq_transit_corr']].to_crs('EPSG:4326'),\n",
    "                           style={'color': 'black', 'fillColor': '#3366cc',\n",
    "                                        'opacity':0.3, 'weight':.5, 'dashArray':'2', 'fillOpacity':0.3},\n",
    "                           hover_style={'fillColor': 'red' , 'fillOpacity': 0.2},\n",
    "                           name = 'HQTA')\n",
    "\n",
    "    geo_data_not_hq = GeoData(geo_dataframe = hqta[~hqta['hq_transit_corr']].to_crs('EPSG:4326'),\n",
    "                           style={'color': 'black', 'fillColor': '#fec44f',\n",
    "                                        'opacity':0.3, 'weight':.5, 'dashArray':'2', 'fillOpacity':0.3},\n",
    "                           hover_style={'fillColor': 'red' , 'fillOpacity': 0.2},\n",
    "                           name = 'non-HQTA')\n",
    "\n",
    "    m.add_layer(geo_data_hq)\n",
    "    m.add_layer(geo_data_not_hq)\n",
    "    m.add_control(LayersControl())\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5af9f8ac-4bca-482b-89ca-406fefe1f5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef93d4ca56054aa2981c138526b80972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[34.024461994324184, -118.41142785170783], controls=(ZoomControl(options=['position', 'zoom_in_text…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "map_hqta(bbb_hqta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35149ab8-21da-4bb2-91ff-48262357efc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# act_hqta.to_file('./ac_transit_test.geojson', driver='GeoJSON')\n",
    "# bbb_hqta.to_file('./smbbb_test.geojson', driver='GeoJSON')\n",
    "# lbt.to_file('./lbt_test.geojson', driver='GeoJSON')\n",
    "# lacmta.to_file('./lacmta_test.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c83d4a-17d5-4c76-ab1e-35547c909284",
   "metadata": {},
   "source": [
    "## AC Transit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dea4ada3-c0fd-4d54-a798-83e8826d23b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9129bbb9b96e4303a266abb46abe801f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[37.80464236021857, -122.27063925338948], controls=(ZoomControl(options=['position', 'zoom_in_text'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "map_hqta(act_hqta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce92081-2e3e-4cf6-a679-cdd8f216a3e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### AC Transit Map Image\n",
    "\n",
    "![map](img/act.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8416814c-1c4d-4b18-8ac1-546c27751b7b",
   "metadata": {},
   "source": [
    "## Santa Monica Big Blue Bus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10ee235f-695b-46f3-bfcb-bada1b0e0613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeee5b4a3f324052a95009dfac330ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[34.01444675024602, -118.49077832945909], controls=(ZoomControl(options=['position', 'zoom_in_text'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "map_hqta(bbb_hqta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8a7aa9-049a-4c06-9e0a-1f646e9a2cc6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Santa Monica Big Blue Bus Map Image\n",
    "\n",
    "![map](img/bbb.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f596f03-dfbc-44a4-9be9-86d2f83995f6",
   "metadata": {},
   "source": [
    "## Long Beach Transit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8795c627-70fa-4e0d-9262-30ae47c49f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad97d722e4934841930e7daf34130807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[33.767382163422255, -118.18711911176604], controls=(ZoomControl(options=['position', 'zoom_in_text…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "map_hqta(lbt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b53c13-c126-453b-8b03-925c207e012e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Long Beach Transit Map Image\n",
    "\n",
    "![map](img/lbt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f44db1-ec48-4333-b972-64e5671088b5",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "* Tested on several operators, provides an approximation of high-quality transit corridors but still incomplete\n",
    "    * Segments not containing stops will not appear as HQTA-- may need to interpolate (e.g., freeway segments)\n",
    "    * Various questionable short segments\n",
    "    * HQTA classification questionable for some routes, will investigate\n",
    "* Working on improving/documenting code, and towards a statewide proof of concept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37c7411-8ea1-48c2-b42a-b437cdef7eaa",
   "metadata": {},
   "source": [
    "## Multiple Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2e6dcb-256c-4a9b-b90e-90b43fe38346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_operator_hqta(itp_ids):\n",
    "    \n",
    "    hqta = pd.DataFrame()\n",
    "    for itp_id in itp_ids:\n",
    "        hqta = hqta.append(single_operator_hqta(get_operator_views(itp_id), hqta)\n",
    "        \n",
    "    return hqta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb833b1-b591-47d9-9e26-7d9ab6d9bd7c",
   "metadata": {},
   "source": [
    "## Sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1da3078-e396-41b1-b5f7-1167a7e15b31",
   "metadata": {},
   "source": [
    "shapes, trips, stop_times, stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7bbb8cf6-19ad-4f2f-8b0c-5709719fa925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_map(gdf, mouseover=None):\n",
    "    if 'calitp_extracted_at' in gdf.columns:\n",
    "        gdf = gdf.drop(columns='calitp_extracted_at')\n",
    "        gdf.geometry = gdf.geometry.buffer(50)\n",
    "    \n",
    "    m = Map(basemap=basemaps.CartoDB.Positron, center=[34, -118.34], zoom=11)\n",
    "\n",
    "    if mouseover:\n",
    "        html = HTML(f'hover to see {mouseover}')\n",
    "        html.layout.margin = '0px 20px 20px 20px'\n",
    "        control = WidgetControl(widget=html, position='topright')\n",
    "        m.add_control(control)\n",
    "\n",
    "        def update_html(feature,  **kwargs):\n",
    "            html.value = '''\n",
    "                <h3><b>{}</b></h3>\n",
    "            '''.format(feature['properties'][mouseover])\n",
    "    if 'hq_transit_corr' in gdf.columns:\n",
    "        geo_data_hq = GeoData(geo_dataframe = gdf[gdf['hq_transit_corr']].to_crs('EPSG:4326'),\n",
    "                               style={'color': 'black', 'fillColor': '#3366cc',\n",
    "                                            'opacity':0.3, 'weight':.5, 'dashArray':'2', 'fillOpacity':0.3},\n",
    "                               hover_style={'fillColor': 'red' , 'fillOpacity': 0.2},\n",
    "                               name = 'HQTA')\n",
    "\n",
    "        geo_data_not_hq = GeoData(geo_dataframe = gdf[~gdf['hq_transit_corr']].to_crs('EPSG:4326'),\n",
    "                               style={'color': 'black', 'fillColor': '#fec44f',\n",
    "                                            'opacity':0.3, 'weight':.5, 'dashArray':'2', 'fillOpacity':0.3},\n",
    "                               hover_style={'fillColor': 'red' , 'fillOpacity': 0.2},\n",
    "                               name = 'non-HQTA')\n",
    "\n",
    "        m.add_layer(geo_data_hq)\n",
    "        m.add_layer(geo_data_not_hq)\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        geo_data_hq = GeoData(geo_dataframe = gdf.to_crs('EPSG:4326'),\n",
    "                               style={'color': 'black', 'fillColor': '#3366cc',\n",
    "                                            'opacity':0.3, 'weight':.5, 'dashArray':'2', 'fillOpacity':0.3},\n",
    "                               hover_style={'fillColor': 'red' , 'fillOpacity': 0.2},\n",
    "                               name = 'gdf')\n",
    "        m.add_layer(geo_data_hq)\n",
    "    \n",
    "    if mouseover:\n",
    "        geo_data_hq.on_hover(update_html)\n",
    "\n",
    "    m.add_control(LayersControl())\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "782a14b7-b0df-4fbe-9e6e-bcadc5a3fc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f51fdea1c8cb4149b55b8cb29f9dcc7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[34, -118.34], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoom_ou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simple_map(debug_dict['shp-3-01_single_hqta'], 'stop_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2cbd07-4258-499a-9ed0-76d1e239659d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
