{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91650562-357e-465f-9912-09e8a2e574aa",
   "metadata": {},
   "source": [
    "# Refactor bus corridors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d229973-9381-4177-9a23-7e07b9d041d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/geopandas/_compat.py:111: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from siuba import *\n",
    "\n",
    "import B1_bus_corridors as bus_corridors\n",
    "from A1_rail_ferry_brt import analysis_date\n",
    "from utilities import GCS_FILE_PATH\n",
    "from shared_utils import rt_utils\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import dask_geopandas\n",
    "import dask_utils\n",
    "\n",
    "date_str = analysis_date.strftime(rt_utils.FULL_DATE_FMT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e121e898-f334-47ab-87a4-40c738c98b58",
   "metadata": {},
   "source": [
    "## Debug ValueError\n",
    "\n",
    "`merged = merge_routes_to_trips(routelines, trips)` throwing error\n",
    "\n",
    "`ValueError: You are trying to merge on object and int32 columns. If you wish to proceed you should use pd.concat (one of them is empty)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f924152-711f-4967-96dd-c413a051045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "itp_id = 323\n",
    "\n",
    "FILE_PATH = f\"{rt_utils.GCS_FILE_PATH}cached_views/\"\n",
    "        \n",
    "routelines = dask_geopandas.read_parquet(f\"{FILE_PATH}routelines_{itp_id}_{date_str}.parquet\")\n",
    "trips = dd.read_parquet(f\"{FILE_PATH}trips_{itp_id}_{date_str}.parquet\")\n",
    "stop_times = dd.read_parquet(f\"{FILE_PATH}st_{itp_id}_{date_str}.parquet\")\n",
    "stops = dask_geopandas.read_parquet(f\"{FILE_PATH}stops_{itp_id}_{date_str}.parquet\")\n",
    "\n",
    "#gdf = bus_corridors.single_operator_hqta(routelines, trips, stop_times, stops)\n",
    "#gdf.to_parquet(\"./data/182_bus2.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131f9034-1247-4224-8a2b-11255a13ab64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b3a154-cba9-4cdf-8ca1-56d41f3fb5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/71688126/groupby-map-partitions-in-dask\n",
    "trips_by_stop_hour = stop_times.map_partitions(\n",
    "    lambda df: df.groupby([\"calitp_itp_id\", \"stop_id\"], as_index=False)\n",
    "        .agg({\"trip_id\": \"count\"}), meta={\"calitp_itp_id\": int,\n",
    "                                          \"stop_id\": str,\n",
    "                                          \"trip_id\": int\n",
    "                                         }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d569acb-c263-4dc8-98b4-07f6df068388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d62be8-1661-4840-95f6-01261e636347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f448206e-0fd2-4f32-9fc6-9f5d141dea55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78908669-6855-46e1-b244-ef36c31c0634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d6c072-9255-4588-b954-a65d42f54cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d65db0-c8df-4c16-9490-0f0514b12776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calitp-analytics-data/data-analyses/high_quality_transit_areas/bus_corridors/182_bus.parquet\n",
    "eric = gpd.read_parquet(f\"{GCS_FILE_PATH}bus_corridors/182_bus.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a927f45f-f7c2-4e6a-9b11-f5697b4b7172",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff = gpd.read_parquet(f\"./data/182_bus2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a29aa60-6e58-410c-8cc1-2a24cd336bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(df):\n",
    "    print(df.columns)\n",
    "    print(df.dtypes)\n",
    "    print(f\"# obs: {len(df)}\")\n",
    "    print(f\"# unique stops: {df.stop_id.nunique()}\")\n",
    "    print(f\"sum am_max stops: {df.am_max_trips.sum()}\")\n",
    "    print(f\"sum pm_max stops: {df.am_max_trips.sum()}\")\n",
    "    print(f\"# unique hqta_segment_id: {df.hqta_segment_id.nunique()}\")\n",
    "\n",
    "    \n",
    "def compare(eric, tiff):\n",
    "    print(\"***********Eric************\")\n",
    "    stats(eric)\n",
    "    print(\"***********Tiff************\")\n",
    "    stats(tiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474532e1-8e64-4519-9850-6456edaa3ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(eric, tiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2e9a68-4e24-46f0-9f49-8c5d88abd4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = [\"stop_id\", \"am_max_trips\", \"pm_max_trips\"]\n",
    "eric2 = eric[keep_cols].drop_duplicates()\n",
    "tiff2 = tiff[keep_cols].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce28775-8b27-4a43-8ca2-db6f04d9a204",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = pd.merge(eric2, tiff2,\n",
    "         on = \"stop_id\",\n",
    "         how = \"outer\",\n",
    "         validate = \"1:1\",\n",
    "         indicator=True\n",
    ")\n",
    "\n",
    "m1._merge.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370a3680-9729-476c-b316-0a7cd8af84ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the ones that are in both, generated the same number of trips\n",
    "m1[m1._merge==\"both\"][m1.am_max_trips_x != m1.am_max_trips_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e152d78c-62d2-491b-a9a0-dd7ae1150bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1[m1._merge==\"both\"][m1.pm_max_trips_x != m1.pm_max_trips_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c44183f-e13c-4665-944b-266e23624bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b0a4fa-20c5-4d5f-94cc-c7de137dbdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove trips that only run during AM/PM peak, because those don't qualify as HQTA\n",
    "def invalid_trips_only_peak_hours(df):\n",
    "    trip_cols = [\"calitp_itp_id\", \"trip_id\"]\n",
    "    \n",
    "    df = df.assign(\n",
    "        is_am_peak = df.time_of_day.map(lambda x: 1 if x==\"AM Peak\" \n",
    "                                          else 0),\n",
    "        is_pm_peak = df.time_of_day.map(lambda x: 1 if x==\"PM Peak\"\n",
    "                                          else 0),\n",
    "        is_other = df.time_of_day.map(lambda x: 1 if ((x != \"AM Peak\") and \n",
    "                                                        (x != \"PM Peak\"))\n",
    "                                        else 0),\n",
    "    )\n",
    "    \n",
    "    df2 = (df.groupby(trip_cols)\n",
    "           .agg({\"is_am_peak\": np.max, \n",
    "                 \"is_pm_peak\": np.max,\n",
    "                 \"is_other\": np.max,})\n",
    "           .reset_index()\n",
    "          )\n",
    "    \n",
    "    # Drop trips that only run AM/PM\n",
    "    only_peak = df2[(df2.is_am_peak==1) & \n",
    "              (df2.is_pm_peak==1) & \n",
    "              (df2.is_other==0)].trip_id.compute()\n",
    "        \n",
    "    # Return list of trip_ids that are invalid\n",
    "    return list(only_peak.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396496be-8a65-432f-b1da-ee199f0562f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_trips = invalid_trips_only_peak_hours(trip_stops_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d419219-9256-4f00-9863-96448a160ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41691421-82d5-4227-8dcf-a3e15a327c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
