{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbb6e02b-aa46-4143-96fc-1d3c9df1000d",
   "metadata": {},
   "source": [
    "## Error when running `gtfs_digest/merge_segment_data.py`\n",
    "`Traceback (most recent call last):\n",
    "  File \"/opt/conda/lib/python3.11/site-packages/dask/dataframe/utils.py\", line 195, in raise_on_meta_error\n",
    "    yield\n",
    "  File \"/opt/conda/lib/python3.11/site-packages/dask/dataframe/core.py\", line 7175, in _emulate\n",
    "    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n",
    "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "  File \"/home/jovyan/data-analyses/_shared_utils/shared_utils/dask_utils.py\", line 134, in import_df_func\n",
    "    df = pd.read_parquet(\n",
    "         ^^^^^^^^^^^^^^^^\n",
    "  File \"/opt/conda/lib/python3.11/site-packages/pandas/io/parquet.py\", line 503, in read_parquet\n",
    "    return impl.read(\n",
    "           ^^^^^^^^^^\n",
    "  File \"/opt/conda/lib/python3.11/site-packages/pandas/io/parquet.py\", line 251, in read\n",
    "    result = self.api.parquet.read_table(\n",
    "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "  File \"/opt/conda/lib/python3.11/site-packages/pyarrow/parquet/core.py\", line 1793, in read_table\n",
    "    dataset = ParquetDataset(\n",
    "              ^^^^^^^^^^^^^^^\n",
    "  File \"/opt/conda/lib/python3.11/site-packages/pyarrow/parquet/core.py\", line 1371, in __init__\n",
    "    self._dataset = ds.dataset(path_or_paths, filesystem=filesystem,\n",
    "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "  File \"/opt/conda/lib/python3.11/site-packages/pyarrow/dataset.py\", line 794, in dataset\n",
    "    return _filesystem_dataset(source, **kwargs)\n",
    "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "  File \"/opt/conda/lib/python3.11/site-packages/pyarrow/dataset.py\", line 476, in _filesystem_dataset\n",
    "    fs, paths_or_selector = _ensure_single_source(source, filesystem)\n",
    "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "  File \"/opt/conda/lib/python3.11/site-packages/pyarrow/dataset.py\", line 441, in _ensure_single_source\n",
    "    raise FileNotFoundError(path)\n",
    "FileNotFoundError: calitp-analytics-data/data-analyses/rt_segment_speeds/rollup_singleday/speeds_route_dir_segments_2024-01-17.parquet\n",
    "\n",
    "The above exception was the direct cause of the following exception:\n",
    "\n",
    "Traceback (most recent call last):\n",
    "  File \"/home/jovyan/data-analyses/gtfs_digest/merge_segment_data.py\", line 93, in <module>\n",
    "    segment_speeds = concatenate_segment_speeds_by_route_direction(\n",
    "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "  File \"/home/jovyan/data-analyses/gtfs_digest/merge_segment_data.py\", line 40, in concatenate_segment_speeds_by_route_direction\n",
    "    df = time_series_utils.concatenate_datasets_across_dates(\n",
    "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "  File \"/home/jovyan/data-analyses/rt_segment_speeds/segment_speed_utils/time_series_utils.py\", line 30, in concatenate_datasets_across_dates\n",
    "    df = dask_utils.get_ddf(\n",
    "         ^^^^^^^^^^^^^^^^^^^\n",
    "  File \"/home/jovyan/data-analyses/_shared_utils/shared_utils/dask_utils.py\", line 183, in get_ddf\n",
    "    ddf = dd.from_map(import_df_func, paths, date_list, data_type=data_type, **kwargs).drop_duplicates()\n",
    "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "  File \"/opt/conda/lib/python3.11/site-packages/dask/dataframe/io/io.py\", line 1028, in from_map\n",
    "    meta = _emulate(\n",
    "           ^^^^^^^^^\n",
    "  File \"/opt/conda/lib/python3.11/site-packages/dask/dataframe/core.py\", line 7174, in _emulate\n",
    "    with raise_on_meta_error(funcname(func), udf=udf), check_numeric_only_deprecation():\n",
    "  File \"/opt/conda/lib/python3.11/contextlib.py\", line 155, in __exit__\n",
    "    self.gen.throw(typ, value, traceback)\n",
    "  File \"/opt/conda/lib/python3.11/site-packages/dask/dataframe/utils.py\", line 216, in raise_on_meta_error\n",
    "    raise ValueError(msg) from e\n",
    "ValueError: Metadata inference failed in `import_df_func`.\n",
    "\n",
    "You have supplied a custom function and Dask is unable to \n",
    "determine the type of output that that function returns. \n",
    "\n",
    "To resolve this please provide a meta= keyword.\n",
    "The docstring of the Dask function you ran should have more information.\n",
    "\n",
    "Original error is below:\n",
    "------------------------\n",
    "FileNotFoundError('calitp-analytics-data/data-analyses/rt_segment_speeds/rollup_singleday/speeds_route_dir_segments_2024-01-17.parquet')\n",
    "\n",
    "Traceback:\n",
    "---------\n",
    "  File \"/opt/conda/lib/python3.11/site-packages/dask/dataframe/utils.py\", line 195, in raise_on_meta_error\n",
    "    yield\n",
    "  File \"/opt/conda/lib/python3.11/site-packages/dask/dataframe/core.py\", line 7175, in _emulate\n",
    "    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n",
    "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "  File \"/home/jovyan/data-analyses/_shared_utils/shared_utils/dask_utils.py\", line 134, in import_df_func\n",
    "    df = pd.read_parquet(\n",
    "         ^^^^^^^^^^^^^^^^\n",
    "  File \"/opt/conda/lib/python3.11/site-packages/pandas/io/parquet.py\", line 503, in read_parquet\n",
    "    return impl.read(\n",
    "           ^^^^^^^^^^\n",
    "  File \"/opt/conda/lib/python3.11/site-packages/pandas/io/parquet.py\", line 251, in read\n",
    "    result = self.api.parquet.read_table(\n",
    "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "  File \"/opt/conda/lib/python3.11/site-packages/pyarrow/parquet/core.py\", line 1793, in read_table\n",
    "    dataset = ParquetDataset(\n",
    "              ^^^^^^^^^^^^^^^\n",
    "  File \"/opt/conda/lib/python3.11/site-packages/pyarrow/parquet/core.py\", line 1371, in __init__\n",
    "    self._dataset = ds.dataset(path_or_paths, filesystem=filesystem,\n",
    "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "  File \"/opt/conda/lib/python3.11/site-packages/pyarrow/dataset.py\", line 794, in dataset\n",
    "    return _filesystem_dataset(source, **kwargs)\n",
    "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "  File \"/opt/conda/lib/python3.11/site-packages/pyarrow/dataset.py\", line 476, in _filesystem_dataset\n",
    "    fs, paths_or_selector = _ensure_single_source(source, filesystem)\n",
    "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "  File \"/opt/conda/lib/python3.11/site-packages/pyarrow/dataset.py\", line 441, in _ensure_single_source\n",
    "    raise FileNotFoundError(path)\n",
    "\n",
    "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
    "E0000 00:00:1739983694.449132     625 init.cc:232] grpc_wait_for_shutdown_with_timeout() timed out.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d70f4c3-3572-4d2e-b588-226709d48e25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import _section1_utils as section1\n",
    "import geopandas as gpd\n",
    "import merge_data\n",
    "import merge_operator_data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from segment_speed_utils import gtfs_schedule_wrangling, helpers\n",
    "from shared_utils import portfolio_utils\n",
    "from update_vars import GTFS_DATA_DICT, RT_SCHED_GCS, SCHED_GCS, SEGMENT_GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adfc13e3-098e-41e8-883a-497f85afbea5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58095cec-ca10-40e4-9605-51626170f32a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FileNotFoundError: \n",
    "# calitp-analytics-data/data-analyses/rt_segment_speeds/rollup_singleday/speeds_route_dir_segments_2024-01-17.parquet\n",
    "# gs://calitp-analytics-data/data-analyses/rt_segment_speeds/rollup_singleday/speeds_route_dir_2024-01-17.parquet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
