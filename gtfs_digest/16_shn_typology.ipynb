{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcff88ab-e6fe-4d33-bc26-6381f3e700d5",
   "metadata": {},
   "source": [
    "# SHN and Route Typology\n",
    "* https://docs.google.com/spreadsheets/d/1gmRmVC4phwA3EunOhI4-aJ7uF5R2nZhIhPV2h3FM25w/edit?gid=0#gid=0\n",
    "\n",
    "## Questions\n",
    "* Is `route_typology` refreshed January of each year?\n",
    "* Do I need to go back to 2023 and add back the route typologies? Or can I just add route typologies from August onward?\n",
    "* Best way to troubleshoot why a dataframe increases in rows after a merge?\n",
    "* What's the difference between `shape_id` in `open_data/create_routes` vs `common_shape_id` in `route_typology_df?`\n",
    "\n",
    "## Steps\n",
    "1. start with: open data routes (1 day? most recent date...for the most part, operator-service_date-route-shape). \n",
    "bring in route typology (which is a route's designation for that year) can be merged onto open data, needs an aggregation here to operator-route. this should be merged onto open data routes with a m:1 merge  (open data routes on left, route typology on right, merge on route)\n",
    "2. to the above, you want to be able to tag those routes as being on shn or not. open data routes will have columns for is_on_shn, route_typology (is_express, is_rapid, is_rail, etc).\n",
    "3. newer research task: the comparison of \"what do you miss when you only sample Wed) is using merge_data.concatenate_schedule_data_by_route_direction(use a week here, instead of Wed), and you're doing this at some point, and this is when you start with gtfs_digest/merge_dataand this stuff is exploratory in a notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef73c496-a633-47fc-8953-8005239865e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import google.auth\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "credentials, project = google.auth.default()\n",
    "\n",
    "import gcsfs\n",
    "\n",
    "fs = gcsfs.GCSFileSystem()\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7195d5e7-f8aa-47bf-a5ef-df9e1ec83fc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from calitp_data_analysis import geography_utils, utils\n",
    "from segment_speed_utils import gtfs_schedule_wrangling, helpers, time_series_utils\n",
    "from shared_utils import (\n",
    "    catalog_utils,\n",
    "    dask_utils,\n",
    "    gtfs_utils_v2,\n",
    "    portfolio_utils,\n",
    "    publish_utils,\n",
    "    rt_dates,\n",
    "    rt_utils,\n",
    ")\n",
    "from update_vars import GTFS_DATA_DICT, RT_SCHED_GCS, SCHED_GCS, SEGMENT_GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e8839bd-caef-413a-9cc5-b1fcf9869b4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAFFIC_OPS_GCS = f\"{GTFS_DATA_DICT.gcs_paths.GCS}traffic_ops/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9142e68b-dadb-4382-9830-2c38d5447a03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7039e0d-31da-40e7-8839-385b86e1f95a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bart_org_name = \"San Francisco Bay Area Rapid Transit District\"\n",
    "bart_gtfs_dataset_name = \"Bay Area 511 BART Schedule\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdcab468-84e5-4bdc-a72c-0c7f7762d221",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analysis_date = rt_dates.DATES[\"jul2025\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc24207-9c7d-4f9e-85ba-afe5047d1214",
   "metadata": {},
   "source": [
    "### Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ace0392b-8c8a-44a6-a49d-3ff83022b6a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "og_url = \"gs://calitp-analytics-data/data-analyses/traffic_ops/ca_transit_routes.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84ee5b01-5293-47ec-bc83-439ce92c7ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "og_gdf = gpd.read_parquet(og_url,\n",
    "    storage_options={\"token\": credentials.token},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2db6d62c-8e3c-40cf-9a98-b6ac5cbf803f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_url = \"gs://calitp-analytics-data/data-analyses/ah_testing/ca_transit_routes.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a74ff092-3840-4889-b98b-ffc226a71307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_gdf = gpd.read_parquet(test_url,\n",
    "    storage_options={\"token\": credentials.token},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5ae47d0-4dd5-4411-bf69-f7dafa737489",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Int64Index: 8101 entries, 0 to 14479\n",
      "Data columns (total 20 columns):\n",
      " #   Column                             Non-Null Count  Dtype   \n",
      "---  ------                             --------------  -----   \n",
      " 0   agency                             8101 non-null   object  \n",
      " 1   route_id                           8101 non-null   object  \n",
      " 2   route_type                         8101 non-null   object  \n",
      " 3   route_name                         8101 non-null   object  \n",
      " 4   route_length_feet                  8101 non-null   float64 \n",
      " 5   shape_id                           8101 non-null   object  \n",
      " 6   n_trips                            8101 non-null   int64   \n",
      " 7   base64_url                         8101 non-null   object  \n",
      " 8   shn_route                          6128 non-null   object  \n",
      " 9   on_shs                             8101 non-null   int64   \n",
      " 10  shn_districts                      6128 non-null   object  \n",
      " 11  pct_route_on_hwy_across_districts  8101 non-null   float64 \n",
      " 12  is_express                         7234 non-null   float64 \n",
      " 13  is_ferry                           7234 non-null   float64 \n",
      " 14  is_rail                            7234 non-null   float64 \n",
      " 15  is_coverage                        7234 non-null   float64 \n",
      " 16  is_local                           7234 non-null   float64 \n",
      " 17  is_downtown_local                  7234 non-null   float64 \n",
      " 18  is_rapid                           7234 non-null   float64 \n",
      " 19  geometry                           8101 non-null   geometry\n",
      "dtypes: float64(9), geometry(1), int64(2), object(8)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "test_gdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "907f7fcd-7833-4749-a441-7028bf4f1ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency</th>\n",
       "      <th>route_id</th>\n",
       "      <th>route_type</th>\n",
       "      <th>route_name</th>\n",
       "      <th>route_length_feet</th>\n",
       "      <th>shape_id</th>\n",
       "      <th>n_trips</th>\n",
       "      <th>base64_url</th>\n",
       "      <th>shn_route</th>\n",
       "      <th>on_shs</th>\n",
       "      <th>shn_districts</th>\n",
       "      <th>pct_route_on_hwy_across_districts</th>\n",
       "      <th>is_express</th>\n",
       "      <th>is_ferry</th>\n",
       "      <th>is_rail</th>\n",
       "      <th>is_coverage</th>\n",
       "      <th>is_local</th>\n",
       "      <th>is_downtown_local</th>\n",
       "      <th>is_rapid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5534</th>\n",
       "      <td>Mountain Area Regional Transit Authority</td>\n",
       "      <td>240</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>107404.92</td>\n",
       "      <td>p_1439418</td>\n",
       "      <td>4</td>\n",
       "      <td>aHR0cHM6Ly9kYXRhLnRyaWxsaXVtdHJhbnNpdC5jb20vZ3Rmcy9iaWdiZWFyLWNhLXVzL2JpZ2JlYXItY2EtdXMuemlw</td>\n",
       "      <td>18, 189, 138, 173</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>55.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        agency route_id route_type route_name  \\\n",
       "5534  Mountain Area Regional Transit Authority      240          3          2   \n",
       "\n",
       "      route_length_feet   shape_id  n_trips  \\\n",
       "5534          107404.92  p_1439418        4   \n",
       "\n",
       "                                                                                        base64_url  \\\n",
       "5534  aHR0cHM6Ly9kYXRhLnRyaWxsaXVtdHJhbnNpdC5jb20vZ3Rmcy9iaWdiZWFyLWNhLXVzL2JpZ2JlYXItY2EtdXMuemlw   \n",
       "\n",
       "              shn_route  on_shs shn_districts  \\\n",
       "5534  18, 189, 138, 173       1             8   \n",
       "\n",
       "      pct_route_on_hwy_across_districts  is_express  is_ferry  is_rail  \\\n",
       "5534                              55.90        0.00      0.00     0.00   \n",
       "\n",
       "      is_coverage  is_local  is_downtown_local  is_rapid  \n",
       "5534         1.00      1.00               0.00      0.00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gdf.drop(columns = [\"geometry\"]).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b17f881-c7a3-40c9-bdfc-374dfd6fcdfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list(test_gdf.columns)) - set(list(og_gdf.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a16f8e-2394-4fe4-85ce-4a742640ec9b",
   "metadata": {},
   "source": [
    "* Insert route typology before organization name is merged in. \n",
    "* When I'm still working with feed key/gtfs schedule that's when I want to start adding things. \n",
    "* Move my merge to just name and route_id that will be a lot cleaner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4232592c-0c0e-4e8e-8e59-9b5c58fec747",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ca_transit_routes = gpd.read_parquet(\n",
    "    f\"gs://calitp-analytics-data/data-analyses/traffic_ops/ca_transit_routes.parquet\",\n",
    "    filters=[[(\"agency\", \"==\", bart_org_name)]],\n",
    "    storage_options={\"token\": credentials.token},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1f4ec0-fc93-4601-a087-4a6aaaf87afb",
   "metadata": {},
   "source": [
    "* Make sure the year is something I consider.\n",
    "* Can concat all of the year to see which ones can merge on. \n",
    "* Because we patch previous dates in, we might be missing stuff if we only grab 2025. \n",
    "* After dataframe has been patched with `patch_previous_dates`, see what's left.\n",
    "* `standardize_operator_info_for_exports` needs to be moved out and added on after I add in the SHN and route typologies. \n",
    "* All organization name renaming stuff needs to move to the end. \n",
    "* Read only what I need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730cfdca-f1f5-4a1c-8d2f-1d5c3bd07d44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "year = \"2025\"\n",
    "route_typologies = pd.read_parquet(\n",
    "    \"gs://calitp-analytics-data/data-analyses/gtfs_schedule/\"\n",
    "    f\"nacto_typologies/route_typologies_{year}.parquet\",\n",
    "    filters=[[(\"name\", \"==\", bart_gtfs_dataset_name)]],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b97dacc-3a93-4ebf-b17c-367bc6930dde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ca_transit_routes.head(1).drop(columns=[\"geometry\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b49cd6a-4609-4abe-9e0f-0c15c4d5db05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "route_typologies.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282582e1-3446-4a05-b5ea-6454dac36256",
   "metadata": {},
   "source": [
    "* Always use `name` and `route_id`\n",
    "* `route_typologies` is not always filled in for everythign we have.\n",
    "* There are a number of reasons, Tiffany samples the dates and only runs it quarterly.\n",
    "* Merging something daily to quarterly doesn't always work the best.\n",
    "* Don't use organization_name. \n",
    "* Get rid of all the shape_id variations for intersecting.\n",
    "    * WE just have to publish all of the `shape_id` because there are truly different variations.\n",
    "    * \n",
    "\n",
    "Steps\n",
    "1. Patch missing data\n",
    "2. Merge `route_typologies` with `open_data` on the left\n",
    "3. Check that I'm not missing too many.\n",
    "4. Add in SHN stuff.\n",
    "    * Can dedup `name, route_id,` keep one `shape_id` with the longest route length in a separate dataframe as the \"representative\" shape. \n",
    "    * Use that `shape_id` for doing the intersection between transit route x SHN to determine the column we are creating.\n",
    "    * Merge this new dataframe back to the original dataframe. \n",
    "5. Add in `standardize_org_name` function\n",
    "6. Add in `finalize_export_df` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fc8634-19ab-4c50-ad2c-ef7afe237183",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_m1 = pd.merge(\n",
    "    ca_transit_routes.assign(name=bart_gtfs_dataset_name),\n",
    "    route_typologies,\n",
    "    on=[\"name\", \"route_id\"],\n",
    "    how=\"left\",\n",
    "    indicator=True,\n",
    ")\n",
    "test_m1._merge.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1aa5bf7-c1ba-405b-98b5-4dee0caef194",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_m1.loc[test_m1.route_id.isin([\"Grey-N\", \"Grey-S\"])].drop(\n",
    "    columns=[\"geometry\", \"base64_url\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5867b384-f859-499d-8812-65bd0a02bb1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_m1.loc[test_m1._merge == \"left_only\"].drop(columns=[\"geometry\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba6a078-b958-49ca-805f-c83ce4493b22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_m2 = pd.merge(\n",
    "    ca_transit_routes.assign(name=bart_gtfs_dataset_name),\n",
    "    route_typologies,\n",
    "    on=[\"name\", \"route_id\", \"route_type\"],\n",
    "    how=\"left\",\n",
    "    indicator=True,\n",
    ")\n",
    "test_m2._merge.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae41410e-3d8b-449a-976a-d4ff713a61bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(ca_transit_routes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfd6a01-71c1-4733-a193-546b49662c30",
   "metadata": {},
   "source": [
    "## Step 1: Concat all the years for `route_typologies`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bee7b0-94e1-4f03-b7ee-46a21e7cfc07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_route_typologies() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Concatenate the years available for\n",
    "    route typologies on the operator-route_id\n",
    "    grain.\n",
    "    \"\"\"\n",
    "    ROUTE_TYPOLOGIES_FILE = GTFS_DATA_DICT.schedule_tables.route_typologies\n",
    "\n",
    "    route_typology_paths = [\n",
    "        f\"{SCHED_GCS}{ROUTE_TYPOLOGIES_FILE}\" for year in rt_dates.years_available\n",
    "    ]\n",
    "    route_typology_df = dask_utils.get_ddf(\n",
    "        route_typology_paths,\n",
    "        rt_dates.years_available,\n",
    "        data_type=\"df\",\n",
    "        get_pandas=True,\n",
    "        columns=[\n",
    "            \"name\",\n",
    "            \"route_id\",\n",
    "            \"is_express\",\n",
    "            \"is_ferry\",\n",
    "            \"is_rail\",\n",
    "            \"is_coverage\",\n",
    "            \"is_local\",\n",
    "            \"is_downtown_local\",\n",
    "            \"is_rapid\",\n",
    "        ],\n",
    "        add_date=False,\n",
    "        add_year=True,\n",
    "    )\n",
    "\n",
    "    # Drop duplicates of operator-route_id to keep only the\n",
    "    # row with the most current year.\n",
    "    route_typology_df2 = route_typology_df.sort_values(\n",
    "        by=[\"name\", \"route_id\", \"year\"], ascending=[True, True, False]\n",
    "    ).drop_duplicates(\n",
    "        subset=[\n",
    "            \"name\",\n",
    "            \"route_id\",\n",
    "        ]\n",
    "    )\n",
    "    return route_typology_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d47fa0a-2419-454d-a111-12258633ee2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROUTE_TYPOLOGIES_FILE = GTFS_DATA_DICT.schedule_tables.route_typologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b407f2-2f86-4ea9-b2ac-4b9c46eff149",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "route_typology_df = add_route_typologies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f9c605-610a-435c-ab97-17288b8adb83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "route_typology_df.loc[route_typology_df.name == \"Yolobus Schedule\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5abad8d-0059-4819-aa41-a72220f3aa63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# route_typology_paths = [\n",
    "#    f\"{SCHED_GCS}{ROUTE_TYPOLOGIES_FILE}\" for year in rt_dates.years_available\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfcad16-28f6-4a39-a9d0-6c006ca6c490",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# route_typology_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d0ac1e-6b3c-463d-a9bf-4c84c4bd6cad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# route_typology_df.sort_values(\n",
    "#    by=[\"name\", \"route_id\", \"year\"], ascending=[True, True, False]\n",
    "# ).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45ebc52-fca7-4c57-a748-827fbf0d05b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# route_typology_df2 = route_typology_df.sort_values(\n",
    "#    by=[\"name\", \"route_id\", \"year\"], ascending=[True, True, False]\n",
    "# ).drop_duplicates(\n",
    "#    subset=[\n",
    "#        \"name\",\n",
    "#        \"route_id\",\n",
    "#    ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c4aed6-3c86-49d9-9ba1-ffcf5a73a59d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# route_typology_df2.year.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cec21e-711c-48f7-8a43-035a76b33e30",
   "metadata": {},
   "source": [
    "## Step 2: Patch missing data (remove `standardize org name`) function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244b099d-aec9-4993-9703-3eee8374aae5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_erroneous_shapes(\n",
    "    shapes_with_route_info: gpd.GeoDataFrame,\n",
    ") -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Check if line is simple for Amtrak. If it is, keep.\n",
    "    If it's not simple (line crosses itself), drop.\n",
    "\n",
    "    In Jun 2023, some Amtrak shapes appeared to be funky,\n",
    "    but in prior months, it's been ok.\n",
    "    Checking for length is fairly time-consuming.\n",
    "    \"\"\"\n",
    "    amtrak = \"Amtrak Schedule\"\n",
    "\n",
    "    possible_error = shapes_with_route_info[shapes_with_route_info.name == amtrak]\n",
    "    ok = shapes_with_route_info[shapes_with_route_info.name != amtrak]\n",
    "\n",
    "    # Check if the line crosses itself\n",
    "    ok_amtrak = (\n",
    "        possible_error.assign(simple=possible_error.geometry.is_simple)\n",
    "        .query(\"simple == True\")\n",
    "        .drop(columns=\"simple\")\n",
    "    )\n",
    "\n",
    "    ok_shapes = pd.concat([ok, ok_amtrak], axis=0).reset_index(drop=True)\n",
    "\n",
    "    return ok_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09ca700-3a49-4101-8304-f776c38082ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_routes_file_for_export(date: str) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Create a shapes (with associated route info) file for export.\n",
    "    This allows users to plot the various shapes,\n",
    "    transit path options, and select between variations for\n",
    "    a given route.\n",
    "    \"\"\"\n",
    "    # Read in local parquets\n",
    "    trips = helpers.import_scheduled_trips(\n",
    "        date,\n",
    "        columns=[\n",
    "            \"name\",\n",
    "            \"gtfs_dataset_key\",\n",
    "            \"route_id\",\n",
    "            \"route_type\",\n",
    "            \"shape_id\",\n",
    "            \"shape_array_key\",\n",
    "            \"route_long_name\",\n",
    "            \"route_short_name\",\n",
    "            \"route_desc\",\n",
    "        ],\n",
    "        get_pandas=True,\n",
    "    ).dropna(subset=\"shape_array_key\")\n",
    "\n",
    "    shapes = helpers.import_scheduled_shapes(\n",
    "        date,\n",
    "        columns=[\"shape_array_key\", \"n_trips\", \"geometry\"],\n",
    "        get_pandas=True,\n",
    "        crs=geography_utils.WGS84,\n",
    "    ).dropna(subset=\"shape_array_key\")\n",
    "\n",
    "    df = (\n",
    "        pd.merge(shapes, trips, on=\"shape_array_key\", how=\"inner\")\n",
    "        .drop_duplicates(subset=\"shape_array_key\")\n",
    "        .drop(columns=\"shape_array_key\")\n",
    "    )\n",
    "\n",
    "    drop_cols = [\"route_short_name\", \"route_long_name\", \"route_desc\"]\n",
    "    route_shape_cols = [\"schedule_gtfs_dataset_key\", \"route_id\", \"shape_id\"]\n",
    "\n",
    "    routes_assembled = (\n",
    "        portfolio_utils.add_route_name(df)\n",
    "        .drop(columns=drop_cols)\n",
    "        .sort_values(route_shape_cols)\n",
    "        .drop_duplicates(subset=route_shape_cols)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    routes_assembled = routes_assembled.pipe(remove_erroneous_shapes)\n",
    "\n",
    "    routes_assembled = routes_assembled.assign(\n",
    "        route_length_feet=routes_assembled.geometry.to_crs(\n",
    "            geography_utils.CA_NAD83Albers_ft\n",
    "        ).length\n",
    "    )\n",
    "    return routes_assembled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7a63aa-9eaa-485b-bec2-f3e58fb8e39d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "routes = create_routes_file_for_export(analysis_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49442166-684f-4686-baf2-c6e06354869f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def patch_previous_dates(\n",
    "    current_routes: gpd.GeoDataFrame,\n",
    "    current_date: str,\n",
    "    published_operators_yaml: str = \"../gtfs_funnel/published_operators.yml\",\n",
    ") -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Compare to the yaml for what operators we want, and\n",
    "    patch in previous dates for the 10 or so operators\n",
    "    that do not have data for this current date.\n",
    "    \"\"\"\n",
    "    # Read in the published operators file\n",
    "    with open(published_operators_yaml) as f:\n",
    "        published_operators_dict = yaml.safe_load(f)\n",
    "\n",
    "    # Convert the published operators file into a dict mapping dates to an iterable of operators\n",
    "    patch_operators_dict = {\n",
    "        str(date): operator_list\n",
    "        for date, operator_list in published_operators_dict.items()\n",
    "        if str(date)\n",
    "        != current_date  # Exclude the current (analysis) date, since that does not need to be patched\n",
    "    }\n",
    "\n",
    "    partial_dfs = []\n",
    "\n",
    "    # For each date and corresponding iterable of operators, get the data from the last time they appeared\n",
    "    for one_date, operator_list in patch_operators_dict.items():\n",
    "        df_to_add = publish_utils.subset_table_from_previous_date(\n",
    "            gcs_bucket=TRAFFIC_OPS_GCS,\n",
    "            filename=f\"ca_transit_routes\",\n",
    "            operator_and_dates_dict=patch_operators_dict,\n",
    "            date=one_date,\n",
    "            crosswalk_col=\"schedule_gtfs_dataset_key\",\n",
    "            data_type=\"gdf\",\n",
    "        )\n",
    "\n",
    "        partial_dfs.append(df_to_add)\n",
    "\n",
    "    patch_routes = pd.concat(partial_dfs, axis=0, ignore_index=True)\n",
    "\n",
    "    # Concat the current data to the \"backfill\" data\n",
    "    published_routes = pd.concat(\n",
    "        [current_routes, patch_routes], axis=0, ignore_index=True\n",
    "    )\n",
    "\n",
    "    # Drop Duplicates\n",
    "    published_routes = published_routes.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    return published_routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710f12e9-ce3c-444e-b676-69fb956a7bfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "routes.sample().drop(columns=[\"geometry\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f53edc8-a918-436a-b6dd-962afa7dd237",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b619db5-bb6c-438e-8b49-2e81a515e340",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "published_routes = patch_previous_dates(\n",
    "    routes,\n",
    "    analysis_date,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2262232-3839-4485-a3b3-8cc1113c8c73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(published_routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c019c4-7cc0-4c18-a06e-2f0c4acf2d7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(published_routes.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a362b3e3-6705-4520-9ad5-f3281fc0a1c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(published_routes.drop_duplicates(subset=[\"schedule_gtfs_dataset_key\", \"route_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4c5b49-53ec-431c-af9e-fcc0daf4adb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "published_routes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defc7d74-c827-4b8f-9566-9c89c1272646",
   "metadata": {},
   "source": [
    "## Step 3: Merge `route_typologies` with `open_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e1a9a2-eaac-4ec3-a6ca-b2c97393d52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_route_typologies(gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Concatenate the years available for\n",
    "    route typologies on the operator-route_id\n",
    "    grain.\n",
    "    \"\"\"\n",
    "    ROUTE_TYPOLOGIES_FILE = GTFS_DATA_DICT.schedule_tables.route_typologies\n",
    "\n",
    "    route_typology_paths = [\n",
    "        f\"{SCHED_GCS}{ROUTE_TYPOLOGIES_FILE}\" for year in rt_dates.years_available\n",
    "    ]\n",
    "    route_typology_df = dask_utils.get_ddf(\n",
    "        route_typology_paths,\n",
    "        rt_dates.years_available,\n",
    "        data_type=\"df\",\n",
    "        get_pandas=True,\n",
    "        columns=[\n",
    "            \"name\",\n",
    "            \"route_id\",\n",
    "            \"is_express\",\n",
    "            \"is_ferry\",\n",
    "            \"is_rail\",\n",
    "            \"is_coverage\",\n",
    "            \"is_local\",\n",
    "            \"is_downtown_local\",\n",
    "            \"is_rapid\",\n",
    "        ],\n",
    "        add_date=False,\n",
    "        add_year=True,\n",
    "    )\n",
    "\n",
    "    # Drop duplicates of operator-route_id to keep only the\n",
    "    # row with the most current year.\n",
    "    route_typology_df2 = route_typology_df.sort_values(\n",
    "        by=[\"name\", \"route_id\", \"year\"], ascending=[True, True, False]\n",
    "    ).drop_duplicates(\n",
    "        subset=[\n",
    "            \"name\",\n",
    "            \"route_id\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    m1 = pd.merge(\n",
    "        gdf,\n",
    "        route_typology_df2,\n",
    "        on=[\"name\", \"route_id\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "    return m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7761d57b-3b47-490a-81d4-c5aa9b9ad9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = add_route_typologies(published_routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b53e4b4-e468-4e79-8ea7-55d8d34d32b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# m1 = pd.merge(\n",
    "#    published_routes,\n",
    "#   route_typology_df,\n",
    "#   on=[\"name\", \"route_id\"],\n",
    "#  how=\"left\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70172c49-15be-42c8-8729-a93957815b2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc4c6fa-9d76-41e8-a138-cf3824e97ef8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(published_routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05edae29-08f0-445b-a254-c9c219b85180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(published_routes.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8a7817-b515-4a3f-ae9a-08c9ea72971e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(m1.drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f593d91f-7b41-49e5-bca1-c36a7aa5c34d",
   "metadata": {},
   "source": [
    "## Step 4: Add in SHN \n",
    "* <s>Keep only the `shape_id` with the longest length</s> joining on all the rows works pretty quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbf36cb-cd21-4074-a101-29c5c6b09068",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def routes_shn_intersection(\n",
    "    routes_gdf: gpd.GeoDataFrame, buffer_amount: int\n",
    ") -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Overlay the most recent transit routes with a buffered version\n",
    "    of the SHN\n",
    "    \"\"\"\n",
    "    GCS_FILE_PATH = \"gs://calitp-analytics-data/data-analyses/shared_data/\"\n",
    "\n",
    "    # Read in buffered shn here or re buffer if we don't have it available.\n",
    "    HWY_FILE = f\"{GCS_FILE_PATH}shn_buffered_{buffer_amount}_ft_shn_dissolved_by_ct_district_route.parquet\"\n",
    "\n",
    "    if fs.exists(HWY_FILE):\n",
    "        shn_routes_gdf = gpd.read_parquet(\n",
    "            HWY_FILE, storage_options={\"token\": credentials.token}\n",
    "        )\n",
    "    else:\n",
    "        shn_routes_gdf = shared_data.buffer_shn(buffer_amount)\n",
    "\n",
    "    # Process the most recent transit route geographies and ensure the\n",
    "    # CRS matches the SHN routes' GDF so the overlay doesn't go wonky.\n",
    "    routes_gdf = routes_gdf.to_crs(shn_routes_gdf.crs)\n",
    "\n",
    "    # Overlay transit routes with the SHN geographies.\n",
    "    gdf = gpd.overlay(\n",
    "        routes_gdf, shn_routes_gdf, how=\"intersection\", keep_geom_type=True\n",
    "    )\n",
    "\n",
    "    # Calcuate the percent of the transit route that runs on a highway, round it up and\n",
    "    # multiply it by 100. Drop the geometry because we want the original transit route\n",
    "    # shapes.\n",
    "    gdf = gdf.assign(\n",
    "        pct_route_on_hwy=(gdf.geometry.length / gdf.route_length_feet).round(3) * 100,\n",
    "    )\n",
    "    # Subset\n",
    "    gdf2 = gdf[\n",
    "        [\n",
    "            \"name\",\n",
    "            \"pct_route_on_hwy\",\n",
    "            \"route_id\",\n",
    "            \"shape_id\",  # maybe comment out later\n",
    "            \"district\",\n",
    "            \"shn_route\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # Clean up\n",
    "    gdf2.district = gdf2.district.fillna(0).astype(int)\n",
    "\n",
    "    gdf2 = gdf2.rename(\n",
    "        columns={\n",
    "            \"pct_route_on_hwy\": \"pct_route_on_hwy_across_districts\",\n",
    "            \"district\": \"shn_districts\",\n",
    "        }\n",
    "    )\n",
    "    return gdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aa589d-078d-4472-87f0-8a5e21dc5300",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shn_routes = routes_shn_intersection(m1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686b77de-dc4d-4f4c-88e7-b713e72fdd2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shn_routes.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d32eb36-cb09-416e-a3e9-70a1185e2d1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shn_routes.pct_route_on_hwy_across_districts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10cfe73-0fac-4c42-8465-8ca9cb45d8af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def group_route_district(df: pd.DataFrame, pct_route_on_hwy_agg: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregate by adding all the districts and SHN to a single row, rather than\n",
    "    multiple and sum up the total % of SHN a transit route intersects with.\n",
    "\n",
    "    df: the dataframe you want to aggregate\n",
    "    pct_route_on_hwy_agg: whether you want to find the max, min, sum, etc on the column\n",
    "    \"pct_route_on_hwy_across_districts\"\n",
    "    \"\"\"\n",
    "\n",
    "    agg1 = (\n",
    "        df.groupby(\n",
    "            [\"name\", \"route_id\", \"shape_id\"],  # maybe comment out later\n",
    "            as_index=False,\n",
    "        )[[\"shn_route\", \"shn_districts\", \"pct_route_on_hwy_across_districts\"]]\n",
    "        .agg(\n",
    "            {\n",
    "                \"shn_route\": lambda x: \", \".join(set(x.astype(str))),\n",
    "                \"shn_districts\": lambda x: \", \".join(set(x.astype(str))),\n",
    "                \"pct_route_on_hwy_across_districts\": pct_route_on_hwy_agg,\n",
    "            }\n",
    "        )\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Clean up\n",
    "    agg1.pct_route_on_hwy_across_districts = (\n",
    "        agg1.pct_route_on_hwy_across_districts.astype(float).round(2)\n",
    "    )\n",
    "\n",
    "    return agg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249a3728-e3f9-4b3b-a199-64be83b1c4da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# grouped = group_route_district(shn_routes, \"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27788cb4-ef5e-4c63-81b3-da2c380f9066",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# grouped.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818d3997-8180-4ebe-acb5-0a800e91a3ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# grouped.pct_route_on_hwy_across_districts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc552614-844c-416a-a559-22d7418886d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# m1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc952556-999f-4e3f-a91a-4e80632d6287",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# grouped.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69357d49-b333-49cb-99a1-c488b28c71f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cee0fd0-7d7a-47f3-9381-0bad534998b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge back with the original dataframe\n",
    "# shn_typology = pd.merge(m1, grouped, on=[\"route_id\", \"name\", \"shape_id\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3e50fb-09f6-4b3b-83bd-c71147f6daf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(shn_typology), len(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fad1a06-3170-468e-b24b-d1846ca745c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_shn_information(gdf: gpd.GeoDataFrame, buffer_amt: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepare the gdf to join with the existing transit_routes\n",
    "    dataframe that is published on the Open Data Portal\n",
    "    \"\"\"\n",
    "    # Retain only the longest shape for each name-route_id combo\n",
    "    # so finding the intersection with SHN won't take as long\n",
    "    \"\"\"\n",
    "    gdf = gdf.sort_values(\n",
    "        by=[\"name\", \"route_id\", \"route_length_feet\"], ascending=[True, True, False]\n",
    "    )[[\"name\", \"route_id\", \"route_length_feet\", \"geometry\"]].drop_duplicates(\n",
    "        subset=[\"name\", \"route_id\"]\n",
    "    )\n",
    "    \"\"\"\n",
    "    # Overlay\n",
    "    intersecting = routes_shn_intersection(gdf, buffer_amt)\n",
    "\n",
    "    # Group the dataframe so that one route only has one\n",
    "    # row instead of multiple rows after finding its\n",
    "    # intersection with any SHN routes.\n",
    "    # print(intersecting.columns)\n",
    "    agg1 = group_route_district(intersecting, \"sum\")\n",
    "\n",
    "    # Merge the dataframe with all the SHS info with the original\n",
    "    # gdf so we can get the original transit route geometries &\n",
    "    # any routes that don't intersect with the state highway routes.\n",
    "    m1 = pd.merge(gdf, agg1, on=[\"route_id\", \"name\", \"shape_id\"], how=\"left\")\n",
    "\n",
    "    # Add yes/no column to signify if a transit route intersects\n",
    "    # with a SHN route\n",
    "    m1.pct_route_on_hwy_across_districts = m1.pct_route_on_hwy_across_districts.fillna(\n",
    "        0\n",
    "    )\n",
    "    m1[\"on_shs\"] = np.where(m1[\"pct_route_on_hwy_across_districts\"] == 0, 0, 1)\n",
    "\n",
    "    # Clean up rows that are tagged as \"on_shs==N\" but still have values\n",
    "    # that appear.\n",
    "    m1.loc[\n",
    "        (m1[\"on_shs\"] == \"N\") & (m1[\"shn_districts\"] != \"0\"),\n",
    "        [\"shn_districts\", \"shn_route\"],\n",
    "    ] = np.nan\n",
    "\n",
    "    return m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a6595e-1226-4788-b98f-c94480a39b9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shn_typology = add_shn_information(m1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1bcf65-c142-4aaf-a8d2-4d2ecef29e38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(shn_typology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ce8c9e-51e0-4130-a69b-375e297c670e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(shn_typology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00584e70-904f-41e4-bd1f-bff684696750",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb56550-7726-46c1-8646-449aa2a8664c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shn_typology.on_shs.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41d0d39-9b7c-498a-ae18-ee1c876f363b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shn_typology.loc[\n",
    "    (shn_typology.name == \"Antelope Valley Transit Authority Schedule\")\n",
    "    & (shn_typology.route_id == \"50\")\n",
    "].drop(columns=[\"geometry\", \"schedule_gtfs_dataset_key\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3139230c-ca02-446e-abed-9b9e67478db5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shn_typology.drop(columns=[\"geometry\", \"schedule_gtfs_dataset_key\"]).sample(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914acc99-ae5d-4620-9ada-42db594d117a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shn_typology.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765ea2b6-48ce-41fa-8f59-2d24a7abd33e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 5: Edit `standardize_org_name` to be on `portfolio_organization_grain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ade62c3-eac8-4f7b-b9e1-b08cd1f00d7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def standardize_operator_info_for_exports(df: pd.DataFrame, date: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Use our crosswalk file created in gtfs_funnel\n",
    "    and add in the organization columns we want to\n",
    "    publish on.\n",
    "    \"\"\"\n",
    "\n",
    "    CROSSWALK_FILE = GTFS_DATA_DICT.schedule_tables.gtfs_key_crosswalk\n",
    "\n",
    "    public_feeds = gtfs_utils_v2.filter_to_public_schedule_gtfs_dataset_keys()\n",
    "\n",
    "    # Get the crosswalk file\n",
    "    crosswalk = pd.read_parquet(\n",
    "        f\"{SCHED_GCS}{CROSSWALK_FILE}_{date}.parquet\",\n",
    "        columns=[\n",
    "            \"schedule_gtfs_dataset_key\",\n",
    "            \"name\",\n",
    "            \"base64_url\",\n",
    "            \"caltrans_district\",\n",
    "        ],\n",
    "        filters=[[(\"schedule_gtfs_dataset_key\", \"in\", public_feeds)]],\n",
    "    )\n",
    "\n",
    "    # Add portfolio_organization_name\n",
    "    crosswalk = (\n",
    "        crosswalk.assign(\n",
    "            caltrans_district=crosswalk.caltrans_district.map(\n",
    "                portfolio_utils.CALTRANS_DISTRICT_DICT\n",
    "            )\n",
    "        )\n",
    "        .pipe(\n",
    "            portfolio_utils.standardize_portfolio_organization_names,\n",
    "            PORTFOLIO_ORGANIZATIONS_DICT,\n",
    "        )\n",
    "        .drop_duplicates(\n",
    "            subset=[\"schedule_gtfs_dataset_key\", \"name\", \"portfolio_organization_name\"]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Checked whether we need a left merge to keep stops outside of CA\n",
    "    # that may not have caltrans_district\n",
    "    # and inner merge is fine. All operators are assigned a caltrans_district\n",
    "    # so Amtrak / FlixBus stops have values populated\n",
    "\n",
    "    # Merge the crosswalk and the input DF\n",
    "    crosswalk_input_merged = pd.merge(\n",
    "        df,\n",
    "        crosswalk,\n",
    "        on=[\"schedule_gtfs_dataset_key\"],\n",
    "        suffixes=[\n",
    "            \"_original\",\n",
    "            None,\n",
    "        ],  # Keep the source record id from the crosswalk as the \"definitive\" version\n",
    "        how=\"inner\",\n",
    "    )\n",
    "\n",
    "    # Drop dups\n",
    "    crosswalk_input_merged = crosswalk_input_merged.drop_duplicates()\n",
    "    return crosswalk_input_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62879b1-2e61-49d6-9ab4-1488ffc2f636",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CROSSWALK_FILE = GTFS_DATA_DICT.schedule_tables.gtfs_key_crosswalk\n",
    "\n",
    "public_feeds = gtfs_utils_v2.filter_to_public_schedule_gtfs_dataset_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b30b61-3cd7-451e-b408-2406dca5d023",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(public_feeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0869f2c6-925b-40b2-aede-7f80774d4d43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the crosswalk file\n",
    "crosswalk = pd.read_parquet(\n",
    "    f\"{SCHED_GCS}{CROSSWALK_FILE}_{analysis_date}.parquet\",\n",
    "    columns=[\n",
    "        \"schedule_gtfs_dataset_key\",\n",
    "        \"name\",\n",
    "        \"base64_url\",\n",
    "        \"organization_source_record_id\",\n",
    "        \"organization_name\",\n",
    "        \"caltrans_district\",\n",
    "    ],\n",
    "    filters=[[(\"schedule_gtfs_dataset_key\", \"in\", public_feeds)]],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1493d9-0112-4d80-8d72-01e05cfbba36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "crosswalk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f170d4e-95de-4fd9-a364-4368314175d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"../_shared_utils/shared_utils/portfolio_organization_name.yml\", \"r\") as f:\n",
    "    PORTFOLIO_ORGANIZATIONS_DICT = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984f60c1-a4e4-4686-a3d8-b06e7509e72a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "crosswalk = crosswalk.assign(\n",
    "    caltrans_district=crosswalk.caltrans_district.map(\n",
    "        portfolio_utils.CALTRANS_DISTRICT_DICT\n",
    "    )\n",
    ").pipe(\n",
    "    portfolio_utils.standardize_portfolio_organization_names,\n",
    "    PORTFOLIO_ORGANIZATIONS_DICT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a99e609-c5fd-4763-a979-5efec9252554",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "crosswalk.sort_values(by=[\"caltrans_district\", \"portfolio_organization_name\"]).drop(\n",
    "   columns=[\"base64_url\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6483a90f-9e69-450d-ad6b-54cd37d88f18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(crosswalk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c27a05-e415-49cd-94ed-ae7896aff02d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(crosswalk.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad63507b-2c71-4715-997f-b90e7b218148",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "crosswalk.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5375e137-f10c-41d9-9a06-a40a9ea588e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(crosswalk.drop_duplicates(subset=[\"portfolio_organization_name\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f5ded4-4442-4150-8c50-43725759b23f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(crosswalk.drop_duplicates(subset=[\"schedule_gtfs_dataset_key\", \"name\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cee438-8e76-4bb9-9c99-29815ffde22b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(\n",
    "    crosswalk.drop_duplicates(\n",
    "        subset=[\"schedule_gtfs_dataset_key\", \"name\", \"portfolio_organization_name\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918897c9-9c50-4e84-a390-923bc1ea1621",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(crosswalk.drop_duplicates(subset=[\"name\", \"portfolio_organization_name\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300463e3-c3e0-42d3-83f5-73db3277b1e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shn_typology2 = standardize_operator_info_for_exports(shn_typology, analysis_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07c7b1d-5bc9-4455-aae5-b89e0da57768",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(shn_typology2), len(shn_typology)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c04691-df8e-4c9a-8e07-6ae71e421c73",
   "metadata": {},
   "source": [
    "## Step 6: Add in `finalize_export_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff2c11c-249c-4caf-9039-15e399148773",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shn_typology2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2943e97f-4d83-4423-aaa3-c8d0baa8405a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "STANDARDIZED_COLUMNS_DICT = {\n",
    "    \"caltrans_district\": \"district_name\",\n",
    "    \"organization_source_record_id\": \"org_id\",\n",
    "    \"organization_name\": \"agency\",\n",
    "    \"agency_name_primary\": \"agency_primary\",\n",
    "    \"agency_name_secondary\": \"agency_secondary\",\n",
    "    \"route_name_used\": \"route_name\",\n",
    "    \"route_types_served\": \"routetypes\",\n",
    "    \"meters_to_shn\": \"meters_to_ca_state_highway\",\n",
    "    \"portfolio_organization_name\": \"agency\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d1f645-bfd9-402f-9f78-d44abafa89b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def finalize_export_df(df: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Suppress certain columns used in our internal modeling for export.\n",
    "    \"\"\"\n",
    "    # Change column order\n",
    "    route_cols = [\n",
    "        \"portfolio_organization_name\",\n",
    "        \"route_id\",\n",
    "        \"route_type\",\n",
    "        \"route_name_used\",\n",
    "        \"route_length_feet\",\n",
    "    ]\n",
    "    shape_cols = [\"shape_id\", \"n_trips\"]\n",
    "    agency_ids = [\"base64_url\"]\n",
    "    shn_cols = [\n",
    "        \"shn_route\",\n",
    "        \"on_shs\",\n",
    "        \"shn_districts\",\n",
    "        \"pct_route_on_hwy_across_districts\",\n",
    "    ]\n",
    "\n",
    "    route_typology = [\n",
    "        \"is_express\",\n",
    "        \"is_ferry\",\n",
    "        \"is_rail\",\n",
    "        \"is_coverage\",\n",
    "        \"is_local\",\n",
    "        \"is_downtown_local\",\n",
    "        \"is_rapid\",\n",
    "    ]\n",
    "    col_order = (\n",
    "        route_cols + shape_cols + agency_ids + shn_cols + route_typology + [\"geometry\"]\n",
    "    )\n",
    "\n",
    "    df2 = (\n",
    "        df[col_order]\n",
    "        .reindex(columns=col_order)\n",
    "        .rename(columns=STANDARDIZED_COLUMNS_DICT)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a772bed0-40ba-4b4c-ab76-ff5bfb8a8868",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shn_typology2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e052c9c-5fea-4551-9290-eb394dc131c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shn_typology3 = shn_typology2.pipe(finalize_export_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e830636-eeeb-4b1c-9747-9d4898695b05",
   "metadata": {},
   "source": [
    "## Check #1: There are many more rows after piping?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef8eb2a-af1c-49c9-a327-97b28deca56b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shn_typology3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda705b3-b958-496c-8918-e7d444c238f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shn_typology3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e389c622-c3ea-477b-9380-4e8da8677e52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shn_typology3.drop(columns=[\"geometry\", \"base64_url\"]).sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915b82e4-ece7-4e8d-9c67-1506d135ce58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shn_typology3.pct_route_on_hwy_across_districts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e6e042-46e1-4a03-be0a-52a24f163c61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shn_typology3.agency.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e7a008-5319-4254-8ba6-c8517d2aa73d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shn_typology2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48a30cf-3159-4f19-a946-9fff06d080eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(shn_typology2.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c66d1d-f4ee-421e-90c4-b55ff2a3a094",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shn_typology.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f082c49-6b4b-4476-bdcb-bfd7d075ba8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shn_typology.route_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2534440-4cf3-448c-8621-81f2578bb133",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shn_typology3.route_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97abc320-fb90-4ec6-96de-77e42d9094bf",
   "metadata": {},
   "source": [
    "### Check original dataframes and see if this is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee4e3e0-62b2-48a1-b1d4-31b6d3063263",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "published_transit_routes = gpd.read_parquet(\n",
    "    \"gs://calitp-analytics-data/data-analyses/traffic_ops/ca_transit_routes.parquet\",\n",
    "    storage_options={\"token\": credentials.token},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237cd507-3b6a-4d55-b7b0-e617eab4add8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "july_16_routes = gpd.read_parquet(\n",
    "    \"gs://calitp-analytics-data/data-analyses/traffic_ops/ca_transit_routes_2025-07-16.parquet\",\n",
    "    storage_options={\"token\": credentials.token},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f875f3-b40d-4a54-aea6-76c3afa1b9e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(published_transit_routes) - len(july_16_routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d25c965-60b6-4993-b50a-b097944b1a51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(published_transit_routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55aa6212-919d-4a01-986b-b21effba85eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(published_transit_routes.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffa396c-7a81-4cb1-9fd8-43f9bd2ae12e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(july_16_routes.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70f422d-fb73-477a-a51a-61bc633a0e89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "july_16_routes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6c3e14-d3d2-4d11-ab3d-f7b9bbcdcd44",
   "metadata": {},
   "source": [
    "## Check 2: Make sure `create_routes_data` works with my newly added lines\n",
    "* Missing a lot of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901a1b93-526f-444f-ac2e-a00b4685de3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ah_ca_transit_routes = gpd.read_parquet(\n",
    "    \"gs://calitp-analytics-data/data-analyses/ah_testing/ca_transit_routes.parquet\",\n",
    "    storage_options={\"token\": credentials.token},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c118e49-bb59-465b-bf4f-be0b3254bafc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ah_ca_transit_routes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd935768-07ff-44c4-80f6-e9060649a0ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ah_ca_july_routes = gpd.read_parquet(\n",
    "    \"gs://calitp-analytics-data/data-analyses/ah_testing/ca_transit_routes_2025-07-16.parquet\",\n",
    "    storage_options={\"token\": credentials.token},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93636c6e-ca96-4860-ab13-3cae2fadda3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ah_ca_july_routes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c92391c-ad36-493b-80b9-e6c02ef3cdf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "july_16_routes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4119b434-4ab6-493d-a1b1-e6bebd63950e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ah_ca_transit_routes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad89b9c-b176-4080-b818-ae5d9bc3c0e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ah_ca_transit_routes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821effa3-0182-4eef-9ef7-ae64903a5ada",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shn_typology3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8292bb03-a285-47e7-b192-afed85191308",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shn_typology3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae43c3e-a3c2-4681-9f55-563c80557d42",
   "metadata": {},
   "source": [
    "## Tiffany Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7630af4-ffc7-4693-88e2-817e9f7f2580",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analysis_date = rt_dates.DATES[\"jul2025\"]\n",
    "\n",
    "public_feeds = gtfs_utils_v2.filter_to_public_schedule_gtfs_dataset_keys()\n",
    "print(f\"# of public schedule_gtfs_dataset_keys {len(public_feeds)}\")\n",
    "\n",
    "CROSSWALK_FILE = GTFS_DATA_DICT.schedule_tables.gtfs_key_crosswalk\n",
    "\n",
    "crosswalk = pd.read_parquet(\n",
    "    f\"{SCHED_GCS}{CROSSWALK_FILE}_{analysis_date}.parquet\",\n",
    "    columns=[\n",
    "        \"schedule_gtfs_dataset_key\",\n",
    "        \"name\",\n",
    "        \"base64_url\",\n",
    "        \"organization_source_record_id\",\n",
    "        \"organization_name\",\n",
    "        \"caltrans_district\",\n",
    "    ],\n",
    "    # filters = [[(\"schedule_gtfs_dataset_key\", \"in\", public_feeds)]]\n",
    ")\n",
    "\n",
    "\n",
    "crosswalk2 = pd.read_parquet(\n",
    "    f\"{SCHED_GCS}{CROSSWALK_FILE}_{analysis_date}.parquet\",\n",
    "    columns=[\n",
    "        \"schedule_gtfs_dataset_key\",\n",
    "        \"name\",\n",
    "        \"base64_url\",\n",
    "        \"organization_source_record_id\",\n",
    "        \"organization_name\",\n",
    "        \"caltrans_district\",\n",
    "    ],\n",
    "    filters=[[(\"schedule_gtfs_dataset_key\", \"in\", public_feeds)]],\n",
    ")\n",
    "print(f\"no filter: {crosswalk.shape}\")\n",
    "\n",
    "print(f\"filtered: {crosswalk2.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
