{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89ff1e91-b200-4c3e-a3dc-bff57cdf8b76",
   "metadata": {},
   "source": [
    "# Transit Service Density\n",
    "\n",
    "## Conceptually, these all sound similar\n",
    "1. Transit service density\n",
    "1. Find and assess key transfers\n",
    "1. Regional connections\n",
    "1. Parallel routes\n",
    "\n",
    "Parallel routes are where transit routes across operators are running over the same corridor. Spatial join to get a \"service density\" over a road corridor.\n",
    "\n",
    "Within these corridors, if there are certain stops where they are co-located, we might want to focus there too (aka, near rail, etc). These stops are both key transfers regionally or key transfers to other local destinations.\n",
    "\n",
    "## Stops (point geometry)\n",
    "\n",
    "* Use GTFS `stops` and count trips per hour\n",
    "* Consider whether `stops` (point geometry) would be the best for pairing this analysis with accessibility. \n",
    "   * Is accessibility also number of jobs reachable from a given stop? \n",
    "* This aggregation is the easiest to get, entirely derived from GTFS schedule tables. We'd only want to use this aggregation if there were other analyses using point data.\n",
    "\n",
    "## Tracts (polygon geometry)\n",
    "\n",
    "* Transit service increase analysis aggregated stops per hour to census tract. Census tract gave us CalEnviroScreen designations and categorizing of transit route into urban/suburban/rural.\n",
    "* The aggregation is simple enough, but it's the visualization that comes after that's more challenging to interpret.\n",
    "   * Are we saying something about tracts at the urban/suburban/rural or CalEnviroScreen high/moderate/low equity groups? \n",
    "   * If we're not, doing this aggregation is not ideal because we almost always having to figure out how to combine tract-level stats to points or lines or even larger polygons (Caltrans districts).\n",
    "\n",
    "## Road segments (line geometry)\n",
    "* We have roads now, but haven't really put it through heavy use yet, even road segments cut by 1 km segments.\n",
    "* If we can aggregate arrivals to road segments, this gives us the strongest tie to the other issues:\n",
    "   * Key transfer points - lots of operators and routes and stops served along the road segment\n",
    "   * Parallel routes - multiple operators and multiple routes within same corridor\n",
    "   * Regional connections - zero in on where these road segments come within certain buffer of freeway exit or rail station?\n",
    "   * Transit service density - how many daily / peak trips travel along this corridor, how many arrivals are taking place along this corridor, how many operators / routes along this corridor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c93c7b-37e8-437b-9e49-9eb7dbb809ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import intake\n",
    "import pandas as pd\n",
    "\n",
    "from shared_utils import rt_dates, rt_utils\n",
    "from segment_speed_utils import helpers\n",
    "from segment_speed_utils.project_vars import (RT_SCHED_GCS, \n",
    "                                              SHARED_GCS)\n",
    "                                             \n",
    "\n",
    "catalog = intake.open_catalog(\n",
    "    \"../_shared_utils/shared_utils/shared_data_catalog.yml\")\n",
    "\n",
    "analysis_date = rt_dates.DATES[\"sep2023\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3423fb-1ced-44c7-ad46-eae71aad6c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_times_with_dir = gpd.read_parquet(\n",
    "    f\"{RT_SCHED_GCS}stop_times_direction_{analysis_date}.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a2b60b-807e-44e5-bd81-8782f77512a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need trip_instance_key to merge to stop_times\n",
    "# grab arrival_hour from stop_times...categorize as peak/offpeak\n",
    "trips = helpers.import_scheduled_trips(\n",
    "    analysis_date,\n",
    "    columns = [\"trip_instance_key\", \"trip_id\", \"feed_key\"]\n",
    ")\n",
    "\n",
    "stop_times = helpers.import_scheduled_stop_times(\n",
    "    analysis_date,\n",
    "    columns = [\"feed_key\", \"trip_id\", \"stop_id\", \"stop_sequence\", \n",
    "               \"arrival_hour\"]\n",
    ").merge(\n",
    "    trips,\n",
    "    on = [\"feed_key\", \"trip_id\"],\n",
    "    how = \"inner\"\n",
    ")[[\"trip_instance_key\", \"stop_id\", \n",
    "   \"stop_sequence\", \"arrival_hour\"]].query('arrival_hour.notnull()').compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2feeae-8d15-4721-b004-2b7674632fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = pd.merge(\n",
    "    stop_times_with_dir,\n",
    "    stop_times,\n",
    "    on = [\"trip_instance_key\", \"stop_id\", \"stop_sequence\"],\n",
    "    how = \"inner\"\n",
    ").astype({\"arrival_hour\": \"int64\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b533cbf5-0dcf-4f62-a354-d25ba789baf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf.assign(\n",
    "    time_of_day = gdf.apply(\n",
    "        lambda x:\n",
    "        rt_utils.categorize_time_of_day(x.arrival_hour), \n",
    "        axis=1)\n",
    ")\n",
    "\n",
    "gdf.time_of_day.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbeafc0-0aac-4037-b29e-c541bef68da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf.assign(\n",
    "    peak_category = gdf.apply(\n",
    "        lambda x: \"peak\" if x.time_of_day in [\"AM Peak\", \"PM Peak\"]\n",
    "        else \"offpeak\", axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ced63bc-8b82-4ffb-83a4-5714ac08edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.peak_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b5d398-9cba-406a-bf33-6cf06da6905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_cols = [\"schedule_gtfs_dataset_key\", \"stop_id\"]\n",
    "\n",
    "peak_st = gdf[gdf.peak_category==\"peak\"]\n",
    "\n",
    "arrivals_by_stop = (gdf.groupby(stop_cols, \n",
    "                                observed=True, group_keys=False)\n",
    "                    .agg({\"arrival_hour\": \"count\"})\n",
    "                    .reset_index()\n",
    "                    .rename(columns = {\"arrival_hour\": \"all_arrivals\"})\n",
    "                   )\n",
    "\n",
    "peak_arrivals_by_stop = (peak_st.groupby(stop_cols, \n",
    "                                         observed=True, group_keys=False)\n",
    "                    .agg({\"arrival_hour\": \"count\"})\n",
    "                    .reset_index()\n",
    "                    .rename(columns = {\"arrival_hour\": \"peak_arrivals\"})\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6f8a7b-9bb8-4fc1-bbb6-553f13501210",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_arrivals_gdf = pd.merge(\n",
    "    stop_times_with_dir[stop_cols + [\"geometry\"]].drop_duplicates(),\n",
    "    arrivals_by_stop,\n",
    "    on = stop_cols,\n",
    "    how = \"inner\"\n",
    ").merge(\n",
    "    peak_arrivals_by_stop,\n",
    "    on = stop_cols,\n",
    "    how = \"left\"\n",
    ").astype({\n",
    "    \"all_arrivals\": \"int64\",\n",
    "    \"peak_arrivals\": \"Int64\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ef0b46-04be-4277-948b-fa493200c731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disneyland shuttle in Toy Story lot has 6_000 arrivals a day\n",
    "stop_arrivals_gdf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900ca8fa-baac-4bac-b559-0cc9d086d9c1",
   "metadata": {},
   "source": [
    "## Census Tracts\n",
    "\n",
    "We would use the CalEnviroScreen 4.0 + LEHD stats by census tract dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e60bc4-6259-4379-b1af-b69404f449eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts = catalog.calenviroscreen_lehd_by_tract.read()\n",
    "tracts.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6570090-3456-4a9a-9f43-a57b2515457c",
   "metadata": {},
   "source": [
    "## Road Segments\n",
    "\n",
    "* We should focus on primary / secondary roads only. If we skip most of the local roads, then we don't even need date-specific road segments, since primary / secondary roads are cut into 1 km segments already.\n",
    "* Maybe we should include local roads, see what comes up in the sjoin? Primary / secondary roads are looking a little sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10dd750-d214-414c-8841-cd1282165648",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_segments = gpd.read_parquet(\n",
    "    f\"{SHARED_GCS}segmented_roads_2020_primarysecondary.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9699d8-2820-4158-828f-11b0d6a9177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_segments.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d03546-faed-4c9f-9420-5eaa879ed616",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_segments_buff = road_segments.assign(\n",
    "    geometry = road_segments.geometry.buffer(35)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ae3425-1ae5-4010-9059-3ec3f22c77f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_arrivals_by_segment_sjoin = gpd.sjoin(\n",
    "    road_segments_buff,\n",
    "    stop_arrivals_gdf,    \n",
    "    how = \"inner\",\n",
    "    predicate = \"intersects\"\n",
    ").drop(columns = \"index_right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d116b0ae-21ea-4300-b5a7-63b9e1296b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_cols = [\"linearid\", \"mtfcc\", \"fullname\", \n",
    "             \"segment_sequence\", \"primary_direction\"]\n",
    "\n",
    "# We might be overcounting here, since\n",
    "# roads show up in both directions, and while a 35m buffer is intended\n",
    "# to catch stops on the sidewalk, we might catch the other direction too\n",
    "stop_arrivals_by_segment = (stop_arrivals_by_segment_sjoin\n",
    "                            .groupby(road_cols, \n",
    "                                     observed=True, group_keys=False)\n",
    "                            .agg({\n",
    "                                \"all_arrivals\": \"sum\",\n",
    "                                \"peak_arrivals\": \"sum\",\n",
    "                                \"stop_id\": \"count\",\n",
    "                                \"schedule_gtfs_dataset_key\": \"nunique\",\n",
    "                            }).reset_index()\n",
    "                            .rename(columns = {\n",
    "                                \"stop_id\": \"n_stops\",\n",
    "                                \"schedule_gtfs_dataset_key\": \"n_operators\",\n",
    "                            })\n",
    "                           )\n",
    "                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fbd88c-b2a4-4585-bcec-85635f2875d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach road segment geometry\n",
    "stop_arrivals_by_segment = (road_segments[road_cols + [\"geometry\"]]\n",
    "                            .merge(\n",
    "                                stop_arrivals_by_segment,\n",
    "                                on = road_cols,\n",
    "                                how = \"inner\"\n",
    "                            )\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622502f2-f08d-495b-b158-f08ef6c39170",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_arrivals_by_segment.all_arrivals.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a247130-02a5-4ebd-83bf-195ae2d75a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_arrivals_by_segment = stop_arrivals_by_segment.assign(\n",
    "    all_arrivals_quartile = pd.qcut(\n",
    "        stop_arrivals_by_segment.all_arrivals,\n",
    "        4, labels=False) + 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c606837d-2d61-4477-a7cb-2e5febf798f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_arrivals_by_segment.explore(\n",
    "    \"all_arrivals_quartile\", \n",
    "    tiles = \"CartoDB Positron\",\n",
    "    categorical = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e34478-825e-4b92-ae7e-c64797d771b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
