{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdbd0a4a-fb4a-4b8c-ab23-47b7c07f614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from siuba import *\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "import download_data\n",
    "import conveyal_vars\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83b31583-0603-4118-a70b-4ed58da92455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from calitp_data_analysis.tables import tbls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0f17681-dba8-4114-b223-9adb8da60a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255a49f8-7acb-47af-ac70-989aa473a0a0",
   "metadata": {},
   "source": [
    "# Matching our warehouse to Conveyal's feed ids..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d377df0-0c70-4c15-b865-e5bc3079a735",
   "metadata": {},
   "source": [
    "## Conveyal Naming Convention\n",
    "\n",
    "* https://github.com/conveyal/r5/blob/v7.2/src/main/java/com/conveyal/analysis/models/Bundle.java#L117-L152\n",
    "* rewrote Conveyal Java code with help of ChatGPT (lol), hence the OO structure for now\n",
    "* ideally this would be cleanly done from our warehouse, but Conveyal relys on unofficial feed_info.feed_id field which we don't ingest (not in GTFS spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26741c0f-0516-4a78-9791-33c71efc96ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df_from_zipped_folder(zip_file_path, filename):\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        if filename in zip_ref.namelist():\n",
    "            with zip_ref.open(filename, 'r') as file:\n",
    "                df = pd.read_csv(file)\n",
    "                df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "                df = df.replace(np.nan, None)\n",
    "            return df\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "955ce3da-6a7d-4480-ba3d-4061a6b92768",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feed:\n",
    "    \n",
    "    def __init__(self, feed_info, agency):\n",
    "        self.feed_info = feed_info\n",
    "        if isinstance(self.feed_info, pd.DataFrame):\n",
    "            self.feed_info = self.feed_info.to_dict(orient='list')\n",
    "        self.agency = agency\n",
    "        if isinstance(self.agency, pd.DataFrame):\n",
    "            self.agency = self.agency.to_dict(orient='list')\n",
    "        \n",
    "    def create_feed_namepart(self):\n",
    "        '''\n",
    "        feed_info based component of conveyal name only, rest gets added in next script\n",
    "        '''\n",
    "        name = None\n",
    "        starting_date = None\n",
    "        ending_date = None\n",
    "\n",
    "        if self.feed_info:\n",
    "            if 'feed_id' in self.feed_info.keys() and self.feed_info['feed_id'][0]:\n",
    "                name = self.feed_info['feed_id'][0]\n",
    "            if 'feed_start_date' in self.feed_info.keys() and self.feed_info['feed_start_date'][0]:\n",
    "                starting_date = self.feed_info['feed_start_date'][0]\n",
    "                starting_date = dt.datetime.strptime(str(starting_date), \"%Y%m%d\").date()\n",
    "            if 'feed_end_date' in self.feed_info.keys() and self.feed_info['feed_end_date'][0]:\n",
    "                ending_date = self.feed_info['feed_end_date'][0]\n",
    "                ending_date = dt.datetime.strptime(str(ending_date), \"%Y%m%d\").date()\n",
    "        # if not name:\n",
    "        #     display(self.agency)\n",
    "        if not name and self.agency and 'agency_name' in self.agency.keys() and self.agency['agency_name'][0]:\n",
    "            # display(self.agency)\n",
    "            n_agencies = len(self.agency['agency_name'])\n",
    "            if n_agencies > 0:\n",
    "                limit = 3\n",
    "                agency_names = \", \".join(self.agency['agency_name'][:limit])\n",
    "                if n_agencies > limit:\n",
    "                    agency_names += f\", +{n_agencies - limit} more\"\n",
    "                name = agency_names\n",
    "\n",
    "        if not name:\n",
    "            name = \"(unknown)\"\n",
    "\n",
    "        self.namestr = name + ': '\n",
    "        self.feed_info_stdate = starting_date\n",
    "        self.feed_info_enddate = ending_date\n",
    "    \n",
    "        return (f\"{self.namestr}{self.feed_info_stdate} to {self.feed_info_enddate}\")\n",
    "    \n",
    "    def from_feed_path(path):\n",
    "        \n",
    "        feed_info = read_df_from_zipped_folder(path, 'feed_info.txt')\n",
    "        agency = read_df_from_zipped_folder(path, 'agency.txt')\n",
    "        return Feed(feed_info, agency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e5c9f70-e7ed-4c4d-8daa-5476f74e75d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yubasutter-ca-us: 2022-11-21 to 2024-01-31'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_feed = Feed.from_feed_path('feeds_2023-10-18/norcal/Yuba-Sutter_Schedule_8417613331f75be671e07037e7cc2a5d_gtfs.zip')\n",
    "my_feed.create_feed_namepart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "deec5968-10aa-43bf-8e22-897f442e2b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "## can't query directly since Hub instance won't be authenticated...\n",
    "\n",
    "# bundle_url = 'https://analysis.conveyal.com/api/db/bundles'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12d4d1d-53e6-43e4-b6ec-acbbb05bef95",
   "metadata": {},
   "source": [
    "### Download in another tab and upload here as bundles.json: https://analysis.conveyal.com/api/db/bundles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eed635ba-0133-4bef-93a8-ec248dad510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conveyal_region_ids = {'central': '6354939b305024caa2c50d7d',\n",
    "                      'norcal': '6352a1d5e1a8e551137301aa',\n",
    "                      'socal': '635602532d6ff920d83ff32a',\n",
    "                      'mojave': '639387380ef4e9793d1e86d3'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fde8700f-1108-4d10-9cae-6d03b0c05b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  must now specify region, bundle name manually to capture possible revisions\n",
    "\n",
    "def import_conveyal_bundle_data(path, bundle_name, region, conveyal_region_ids = conveyal_region_ids):\n",
    "    region_id = conveyal_region_ids[region]\n",
    "    with open(path) as file:\n",
    "        bundles = json.load(file)\n",
    "    current_bundle = [bundle for bundle in bundles\n",
    "        if bundle['name'] == bundle_name and bundle['regionId'] == region_id][0]\n",
    "    feeds = [\n",
    "        {key:val for key, val in bundle_feed.items() if key != 'errors'}\n",
    "        for bundle_feed in current_bundle['feeds']\n",
    "    ]\n",
    "    df = pd.DataFrame(feeds)\n",
    "    df['bundle_name'] = bundle_name\n",
    "    df['bundle_id'] = current_bundle['_id']\n",
    "    df['region_name'] = region\n",
    "    df['region_id'] = region_id\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aed3c88-4c64-428f-9e98-6843b7035ac9",
   "metadata": {},
   "source": [
    "## Deriving start and end dates from one of our feeds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b550cd42-fea0-4b0b-9287-5ad7738be136",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_and_feeds = download_data.regions_and_feeds >> distinct(_.region, _.feed_key, _keep_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e90e0d5e-bbd7-4071-a0bc-66155efb6fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>feed_key</th>\n",
       "      <th>gtfs_dataset_name</th>\n",
       "      <th>base64_url</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>norcal</td>\n",
       "      <td>7bd3d8c32eda4869c4d7f8bf2aec5bb0</td>\n",
       "      <td>Flixbus Schedule</td>\n",
       "      <td>aHR0cDovL2d0ZnMuZ2lzLmZsaXgudGVjaC9ndGZzX2dlbm...</td>\n",
       "      <td>2023-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>central</td>\n",
       "      <td>7bd3d8c32eda4869c4d7f8bf2aec5bb0</td>\n",
       "      <td>Flixbus Schedule</td>\n",
       "      <td>aHR0cDovL2d0ZnMuZ2lzLmZsaXgudGVjaC9ndGZzX2dlbm...</td>\n",
       "      <td>2023-10-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    region                          feed_key gtfs_dataset_name  \\\n",
       "0   norcal  7bd3d8c32eda4869c4d7f8bf2aec5bb0  Flixbus Schedule   \n",
       "1  central  7bd3d8c32eda4869c4d7f8bf2aec5bb0  Flixbus Schedule   \n",
       "\n",
       "                                          base64_url       date  \n",
       "0  aHR0cDovL2d0ZnMuZ2lzLmZsaXgudGVjaC9ndGZzX2dlbm... 2023-10-18  \n",
       "1  aHR0cDovL2d0ZnMuZ2lzLmZsaXgudGVjaC9ndGZzX2dlbm... 2023-10-18  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions_and_feeds >> head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f67cd8f9-a7da-40cd-82f1-96b8c157de19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calendar_min_max_from_warehouse(regions_feeds_df: pd.DataFrame, region: str):\n",
    "    '''\n",
    "    using combined span of calendar and calendar_dates,\n",
    "    get each feed's first and last service date.\n",
    "    useful for matching with Conveyal bundle feed_ids\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    region_filtered = regions_feeds_df >> filter(_.region == region)\n",
    "    filter_feeds = filter(_.feed_key.isin(region_filtered.feed_key))\n",
    "    \n",
    "    dim_cd = (tbls.mart_gtfs.dim_calendar_dates()\n",
    "              >> select(_.feed_key, _.date)\n",
    "              >> filter_feeds\n",
    "              >> group_by(_.feed_key)\n",
    "              >> summarize(min_cd = _.date.min(), max_cd = _.date.max())\n",
    "             )\n",
    "\n",
    "    dim_cal = (tbls.mart_gtfs.dim_calendar()\n",
    "               >> select(_.feed_key, _.start_date, _.end_date)\n",
    "               >> filter_feeds\n",
    "               >> group_by(_.feed_key)\n",
    "               >> summarize(min_cal = _.start_date.min(), max_cal = _.end_date.max())\n",
    "              )\n",
    "    \n",
    "    joined = (dim_cal\n",
    "               >> full_join(_, dim_cd, on = 'feed_key')\n",
    "               # >> inner_join(_, dim_agency, on = 'feed_key')\n",
    "               >> collect()\n",
    "             )\n",
    "    \n",
    "    joined = (joined >> collect()\n",
    "              >> inner_join(_, region_filtered, on = 'feed_key')\n",
    "             )\n",
    "    \n",
    "    #  cross-fill na calendar and calendar_dates values (only one is required)\n",
    "    joined.min_cal = joined.min_cal.fillna(joined.min_cd)\n",
    "    joined.max_cal = joined.max_cal.fillna(joined.max_cd)\n",
    "    joined.min_cd = joined.min_cd.fillna(joined.min_cal)\n",
    "    joined.max_cd = joined.max_cd.fillna(joined.max_cal)\n",
    "\n",
    "    joined['min_combined'] = joined[['min_cal', 'max_cal', 'max_cd', 'min_cd']].values.min(axis=1)\n",
    "    joined['max_combined'] = joined[['min_cal', 'max_cal', 'max_cd', 'min_cd']].values.max(axis=1)\n",
    "    \n",
    "    joined = joined >> select(-_.min_cal, -_.max_cal, -_.min_cd,\n",
    "                             -_.max_cd)\n",
    "    return joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab4eb04b-7201-4d6f-a4f6-aab1a1484aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feed_key</th>\n",
       "      <th>region</th>\n",
       "      <th>gtfs_dataset_name</th>\n",
       "      <th>base64_url</th>\n",
       "      <th>date</th>\n",
       "      <th>min_combined</th>\n",
       "      <th>max_combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7b523354fae424de5845d3e5f12da59a</td>\n",
       "      <td>norcal</td>\n",
       "      <td>Curry Public Transit Schedule</td>\n",
       "      <td>aHR0cHM6Ly9vcmVnb24tZ3Rmcy50cmlsbGl1bXRyYW5zaX...</td>\n",
       "      <td>2023-10-18</td>\n",
       "      <td>2022-01-22</td>\n",
       "      <td>2023-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8417613331f75be671e07037e7cc2a5d</td>\n",
       "      <td>norcal</td>\n",
       "      <td>Yuba-Sutter Schedule</td>\n",
       "      <td>aHR0cHM6Ly9kYXRhLnRyaWxsaXVtdHJhbnNpdC5jb20vZ3...</td>\n",
       "      <td>2023-10-18</td>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>2024-01-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           feed_key  region              gtfs_dataset_name  \\\n",
       "0  7b523354fae424de5845d3e5f12da59a  norcal  Curry Public Transit Schedule   \n",
       "1  8417613331f75be671e07037e7cc2a5d  norcal           Yuba-Sutter Schedule   \n",
       "\n",
       "                                          base64_url       date min_combined  \\\n",
       "0  aHR0cHM6Ly9vcmVnb24tZ3Rmcy50cmlsbGl1bXRyYW5zaX... 2023-10-18   2022-01-22   \n",
       "1  aHR0cHM6Ly9kYXRhLnRyaWxsaXVtdHJhbnNpdC5jb20vZ3... 2023-10-18   2020-05-01   \n",
       "\n",
       "  max_combined  \n",
       "0   2023-11-01  \n",
       "1   2024-01-31  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_spans_norcal = calendar_min_max_from_warehouse(regions_and_feeds, 'norcal')\n",
    "feed_spans_norcal >> head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b02a522a-275b-4fcf-8532-e100042f0396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conveyal_name_lookup(row):\n",
    "    # print(row.gtfs_dataset_name)\n",
    "    gtfs_path = f'feeds_{conveyal_vars.target_date}/{row.region}/{row.gtfs_dataset_name.replace(\" \", \"_\")}_{row.feed_key}_gtfs.zip'\n",
    "    my_feed = Feed.from_feed_path(gtfs_path)\n",
    "    my_feed.create_feed_namepart()\n",
    "    \n",
    "    row['conveyal_namestr'] = my_feed.namestr\n",
    "    if my_feed.feed_info_stdate:\n",
    "        row['min_combined'] = my_feed.feed_info_stdate\n",
    "    if my_feed.feed_info_enddate:\n",
    "        row['max_combined'] = my_feed.feed_info_enddate\n",
    "    \n",
    "    row['conveyal_name'] = f\"{row['conveyal_namestr']}{row['min_combined']} to {row['max_combined']}\"\n",
    "    \n",
    "    return row\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d0863a78-f52a-4c7c-a0fb-6636140d3d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feed_key</th>\n",
       "      <th>region</th>\n",
       "      <th>gtfs_dataset_name</th>\n",
       "      <th>base64_url</th>\n",
       "      <th>date</th>\n",
       "      <th>min_combined</th>\n",
       "      <th>max_combined</th>\n",
       "      <th>conveyal_namestr</th>\n",
       "      <th>conveyal_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7b523354fae424de5845d3e5f12da59a</td>\n",
       "      <td>norcal</td>\n",
       "      <td>Curry Public Transit Schedule</td>\n",
       "      <td>aHR0cHM6Ly9vcmVnb24tZ3Rmcy50cmlsbGl1bXRyYW5zaX...</td>\n",
       "      <td>2023-10-18</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>currypublictransit-brookings-or-us:</td>\n",
       "      <td>currypublictransit-brookings-or-us: 2023-08-23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8417613331f75be671e07037e7cc2a5d</td>\n",
       "      <td>norcal</td>\n",
       "      <td>Yuba-Sutter Schedule</td>\n",
       "      <td>aHR0cHM6Ly9kYXRhLnRyaWxsaXVtdHJhbnNpdC5jb20vZ3...</td>\n",
       "      <td>2023-10-18</td>\n",
       "      <td>2022-11-21</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>yubasutter-ca-us:</td>\n",
       "      <td>yubasutter-ca-us: 2022-11-21 to 2024-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>748268ad11a5e83db5e4782e822e5998</td>\n",
       "      <td>norcal</td>\n",
       "      <td>Sage Stage Schedule</td>\n",
       "      <td>aHR0cHM6Ly9kYXRhLnRyaWxsaXVtdHJhbnNpdC5jb20vZ3...</td>\n",
       "      <td>2023-10-18</td>\n",
       "      <td>2023-09-08</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>sagestage-ca-us:</td>\n",
       "      <td>sagestage-ca-us: 2023-09-08 to 2024-02-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           feed_key  region              gtfs_dataset_name  \\\n",
       "0  7b523354fae424de5845d3e5f12da59a  norcal  Curry Public Transit Schedule   \n",
       "1  8417613331f75be671e07037e7cc2a5d  norcal           Yuba-Sutter Schedule   \n",
       "2  748268ad11a5e83db5e4782e822e5998  norcal            Sage Stage Schedule   \n",
       "\n",
       "                                          base64_url       date min_combined  \\\n",
       "0  aHR0cHM6Ly9vcmVnb24tZ3Rmcy50cmlsbGl1bXRyYW5zaX... 2023-10-18   2023-08-23   \n",
       "1  aHR0cHM6Ly9kYXRhLnRyaWxsaXVtdHJhbnNpdC5jb20vZ3... 2023-10-18   2022-11-21   \n",
       "2  aHR0cHM6Ly9kYXRhLnRyaWxsaXVtdHJhbnNpdC5jb20vZ3... 2023-10-18   2023-09-08   \n",
       "\n",
       "  max_combined                      conveyal_namestr  \\\n",
       "0   2023-11-01  currypublictransit-brookings-or-us:    \n",
       "1   2024-01-31                    yubasutter-ca-us:    \n",
       "2   2024-02-01                     sagestage-ca-us:    \n",
       "\n",
       "                                       conveyal_name  \n",
       "0  currypublictransit-brookings-or-us: 2023-08-23...  \n",
       "1         yubasutter-ca-us: 2022-11-21 to 2024-01-31  \n",
       "2          sagestage-ca-us: 2023-09-08 to 2024-02-01  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_spans_norcal.apply(conveyal_name_lookup, axis=1) >> head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e6c1a328-bef7-4486-a900-8555c793e883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude_feeds = ['c7cea554a5e958c1a6dae5d4f6ccdd6a',  # lassen flex\n",
    "#                 'b17c3a5b12a0f35116fc1ccbfe3f7377',  # covina go west\n",
    "#                 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353d9ac2-7189-4094-b12d-0810c2c08583",
   "metadata": {},
   "source": [
    "## Exports\n",
    "\n",
    "* by conveyal region with full detail\n",
    "* simplified and deduped file for matching any feed across regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f321f910-26dc-47cf-9e94-acf8b85e015e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  socal has revised bundle, will likely require manual handling\n",
    "conveyal_socal = import_conveyal_bundle_data('./bundles.json', '2023-10-18a', 'socal')\n",
    "conveyal_norcal = import_conveyal_bundle_data('./bundles.json', '2023-10-18', 'norcal')\n",
    "conveyal_central = import_conveyal_bundle_data('./bundles.json', '2023-10-18', 'central')\n",
    "conveyal_mojave = import_conveyal_bundle_data('./bundles.json', '2023-10-18', 'mojave')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "831bab96-cbd9-4747-a994-9787ac5fc394",
   "metadata": {},
   "outputs": [],
   "source": [
    "bundles_regions = [('2023-10-18a', 'socal'),\n",
    "                  ('2023-10-18', 'norcal'),\n",
    "                  ('2023-10-18', 'central'),\n",
    "                  ('2023-10-18', 'mojave')\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5f369630-b307-4698-943e-2eeb48888400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_warehouse_conveyal_by_region(bundles_regions, conveyal_json_path = './bundles.json'):\n",
    "    '''\n",
    "    bundles_regions: list of tuples (bundle name, region name)\n",
    "    \n",
    "    bundles_regions date must currently match conveyal_vars date\n",
    "    \n",
    "    seperate list of bundles_regions allows changing the bundle name for bundles\n",
    "    updated after this process, such as socal which has 2023-10-18a in Conveyal...\n",
    "    \n",
    "    saves both regional (full detail) and simplified (unique feeds with joining ids)\n",
    "    parquets to gcs\n",
    "    '''\n",
    "    regions_and_feeds = download_data.regions_and_feeds >> distinct(_.region, _.feed_key, _keep_all=True)\n",
    "    \n",
    "    regional_joins = {}\n",
    "    for bundle, region in bundles_regions:\n",
    "        conveyal_regional_bundle = import_conveyal_bundle_data(conveyal_json_path, bundle, region)\n",
    "        warehouse_regional = calendar_min_max_from_warehouse(regions_and_feeds, region)\n",
    "        names_added = warehouse_regional.apply(conveyal_name_lookup, axis=1)\n",
    "        print(f'pre-join: conveyal: {conveyal_regional_bundle.shape}, warehouse: {names_added.shape}')\n",
    "        regional_joined = conveyal_regional_bundle >> inner_join(_, names_added, on = {'name': 'conveyal_name'})\n",
    "        print(f'joined: {regional_joined.shape}')\n",
    "        regional_joins[region] = regional_joined\n",
    "    \n",
    "    return regional_joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0ef14e87-5896-411c-b115-73a648007afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-join: conveyal: (85, 10), warehouse: (84, 9)\n",
      "joined: (79, 19)\n",
      "pre-join: conveyal: (24, 10), warehouse: (25, 9)\n",
      "joined: (23, 19)\n",
      "pre-join: conveyal: (82, 10), warehouse: (82, 9)\n",
      "joined: (80, 19)\n",
      "pre-join: conveyal: (6, 10), warehouse: (6, 9)\n",
      "joined: (5, 19)\n"
     ]
    }
   ],
   "source": [
    "regional_joins = join_warehouse_conveyal_by_region(bundles_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb995485-442f-45fa-ab7f-f29777d56ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
