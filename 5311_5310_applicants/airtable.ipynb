{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "546ac1d1-a11f-47d6-b8b3-5e74cb2f5ab1",
   "metadata": {},
   "source": [
    "# 5311 and 5310 Applicants\n",
    "* [Research Request](https://github.com/cal-itp/data-analyses/issues/333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169bb990-b266-4ccb-9d38-0fe7b98a397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages to import\n",
    "# Pandas is the full name of the package but call it pd for short.\n",
    "import pandas as pd\n",
    "from calitp import *\n",
    "\n",
    "# You only need to import these if you want to use something from the warehouse\n",
    "from calitp.tables import tbl\n",
    "from calitp import query_sql\n",
    "from siuba import *\n",
    "import calitp.magics\n",
    "\n",
    "# Formatting the notebook\n",
    "# The max columns to display will be 100\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "# There will allow you to print all the rows in your data\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "# This will prevent columns from being truncated\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3990900-449b-4e01-8991-5b53f1c6aa78",
   "metadata": {},
   "source": [
    "## Load the Excel Sheet\n",
    "* Can read the original Excel workbook by the specific sheet you want. \n",
    "* Save your sheet as a Pandas dataframe - it can be called anything, but usually it's <i>something_df</i>. \n",
    "    * Dataframe = basically jsut a table of data. \n",
    "    * If you want to open multiple sheets, you'd assign them to different objects and different names. \n",
    "* \"to_snakecase\" changes the column names to all lowercases and replaces any spaces with underescores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d6fb2f-e483-4405-92fb-1cd826fedc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = to_snakecase(\n",
    "#    pd.read_excel(\"gs://calitp-analytics-data/data-analyses/grants/Grant+Projects_7_30_2022.xlsx\", sheet_name=\"Grant Projects\")\n",
    "#)\n",
    "\n",
    "df = pd.read_excel(\"./Grant+Projects_7_30_2022.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad206f7-5652-43a6-b779-31b7373aada9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"./Grant+Projects_7_30_2022.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b83096-fe5c-4d19-9412-2c4f91370192",
   "metadata": {},
   "source": [
    "## Explore the data \n",
    "* Let's check out our data by answering questions such as\n",
    "    * How many columns and rows does it have? \n",
    "    * How many missing values are there? \n",
    "    * What are the mean/median? \n",
    "* Any time you want to do something to your data, chain the function after the object.\n",
    "    * In Excel, you'd do SUM(column you want)\n",
    "    * In Pandas, you'd do df['column you want'].sum()\n",
    "* [Resource](https://pandas.pydata.org/docs/user_guide/basics.html)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb34614-8bb8-4076-a511-2bae65ac4842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the first five rows\n",
    "# Any line with a pound symbol in front is a comment and won't be rendered\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038eac2d-4e92-4438-b8cf-d7f7a7e6a2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the last five rows\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4209ccb-4557-4e65-b90d-222ebb615fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out how many rows and columns, # of null values in each column, and the data type of each column\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68ec0bc-ef4c-4df9-bf3b-5c5b2449ced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data goes spans between 2011 to 2022. Check out how many projects were funded by year.\n",
    "df[\"column 1\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aad591f-6266-4519-9f90-cec0a0e1da89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not sure what a function does: use help\n",
    "help(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a682b9-7b50-45ce-bcbe-61b745e5e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some basic stats\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dee0166-6091-4393-a287-b7f453439a67",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "* [Tutorial](https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html)\n",
    "\n",
    "### Data type is important. \n",
    "* If you have a column of monetary values presented as $139, 293.92 and you want to find the mean, this won't work. \n",
    "* This column is considered an \"object\" column due to the dollar sign and comma - same way as if you typed \"caltrans\".\n",
    "    * You'll have make sure it's an integer.\n",
    "* Based on df.info() clean up other columns that aren't the right data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693e0fac-963c-4d29-ac29-3c30769722ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "If there are columns that SHOULD be an integer but isn't: input them into the list\n",
    "after this for loop. This strips empty $ and commas from columns, \n",
    "then changes them to the data type of int.\n",
    "\"\"\"\n",
    "for c in [\"column_one\", \"column_two\", \"column_three\"]:\n",
    "    df[c] = df[c].str.replace(\"$\", \"\").str.replace(\",\", \"\").astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6326c7-638c-4651-9b5c-1aa4530482a0",
   "metadata": {},
   "source": [
    "### Beware of duplicate values\n",
    "* Grants data might be manually entered by multiple people. As such, values can be inconsistent. \n",
    "* BART, Bay Area Rapid Transit, and Bay Area Rapid Transit (BART) are all the same agency. \n",
    "* However, if you are counting the number of unique agencies, these would be counted as 3 different agencies, which is inaccurate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c919a9fa-98c7-4437-95a8-0086cc7db447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out your agencies and see if there are any duplicates by\n",
    "# sorting your column of agencies from A-Z and seeing only unique ones\n",
    "df[\"column\"].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3ff722-b0e8-419e-9d64-d1f0058a18f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out total nunique values\n",
    "df[\"column\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00b5798-3958-4830-af13-aed51ef9e6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "If there are duplicate values, you can replace them with an existing one with a dictionary\n",
    "If this cell is irrelevant,  go up to the top where it says \"code\" and change it to \"markdown\". \n",
    "You can also move the three quotation marks at the bottom of this cell to comment out the code.\n",
    "If all the agencies are only listed once.\n",
    "\"\"\"\n",
    "df[\"column\"] = df[\"column\"].replace(\n",
    "    {\"old value 1\": \"correct value 1\", \"old value 2\": \"correct value 2\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf99e5cf-cc3f-4dfe-88bc-a15a43af4744",
   "metadata": {},
   "source": [
    "## Filter what you want\n",
    "* You don't necessarily want all the years, all the programs, etc. \n",
    "* Filter out what you are interested in.\n",
    "\n",
    "### Grants you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53102841-09ba-4f81-a3bf-abcb86ede07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a list that contains the grants you are interested in. \n",
    "A list is great because you can go in and delete/add items. \n",
    "Line below makes it easy to grab the values.\n",
    "\"\"\"\n",
    "df[\"column 1\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c767700f-1f17-4b72-b544-57b8aeb3c4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste whatever values you want between the brckets.\n",
    "# The values need to be in quotes.\n",
    "grants_wanted = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc528005-0ad5-4eb9-920a-7b18c3310370",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Keep only the grants in my list and create a NEW variable.\n",
    "It's best to create new variables when you make changes, so you can always reference\n",
    "the original variable. \n",
    "\"\"\"\n",
    "df2 = df2[df2[\"column\"].isin([grants_wanted])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339b7dbd-2e3f-4305-bd56-403ed5768a63",
   "metadata": {},
   "source": [
    "### Columns you want\n",
    "* Drop irrelvant columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3c2e5c-419b-4f52-959d-ca651a0029cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List out all your columns\n",
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a8ab7f-d3a7-4d2e-859a-40a2ecc91a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy and paste the irrelevant ones into this list below\n",
    "unwanted_columns = [\"column 1\", \"column 2\", \"column 3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b92403-85c4-4666-ba78-5e684a69d607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop them - assign to a new dataframe if you wish\n",
    "df2 = df2.drop(columns=unwanted_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f499ef-48ac-4bc5-97a5-2f8fa3470931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out your hard work with 5 random rows. Is this what you want?\n",
    "df2.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cda8c02-d0e9-4f0b-b9ad-992d4543bd7d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Insights\n",
    "* Now that you have a clean data frame, it's time to get some insights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f663f539-2a1c-4c0c-bbb3-00444bcad175",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Do these organizations overlap between 5310 and 5311?\n",
    "* For Airtable\n",
    "* Currently our dataframe contains both 5311 and 5310. \n",
    "* To compare the agencies, we need to break apart the dataframe so each grant will have its own dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1052396-fc60-4619-bb1f-46d2c0634ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Filter out for years. Check the data type of the column you are filtering on. \n",
    "Perhaps years will need quotes because it's an object or maybe it's an integer, so \n",
    "no quotes are necessary.\n",
    "\"\"\"\n",
    "df3 = df2[df2[\"column\"] > year_you_want]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5ef04-8c87-4182-ac78-3315d3235219",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Filter out for only 5311. \n",
    "This ignores the case, so 'ac transit' and 'AC TRANSIT' will show up.\n",
    "\"\"\"\n",
    "df_5311 = df3[(df3.column.str.contains(\"5311\", case=False))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3b9cdf-a637-4678-8171-2da05f8aae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the length, aka # of rows after filtering\n",
    "len(df_5311)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebdffbc-6d37-4241-9159-1056835dda52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat same steps for 5310, make sure to cast this into a different dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facad834-8913-4854-af3c-2625226cce13",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Merge the two split dataframes together\n",
    "* Merging = joining two data sets on any columns they have in common.\n",
    "* [Merge types & tutorials](https://www.datasciencemadesimple.com/join-merge-data-frames-pandas-python/)\n",
    "* Merge agency_info table below and merge it with our df\n",
    "* Now that you have 2 dataframes, compare them with an outer merge.\n",
    "     * By using an outer merge, we can find out whether an agency appears in both 5311 and 5310, only the 5311, or only the 5310 through the indicator column that we turned out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d02a8aa-899d-47a1-abce-661e482c9a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Save your merge results into a new dataframe called m1.\n",
    "FYI: you can merge on more than one column! \n",
    "\"\"\"\n",
    "m2 = m2.merge(\n",
    "    your_df1,\n",
    "    your_df2,\n",
    "    how=\"outer\",\n",
    "    on=[\"ALL the columns they have in common\"],\n",
    "    indicator=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb307012-04ca-4914-a1b9-e362ebb17cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Indicator values are both/left/only. You can \n",
    "change the values to something like 'both 5310 and 5311',\n",
    "'5311 only', etc. Scroll back up to the 'duplicate values'\n",
    "section to change these values with a dictionary.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a669cab4-b4f9-4e73-92f2-15f3eb80cb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Query agency info from our warehouse\n",
    "\"\"\"\n",
    "agency_info = (\n",
    "    tbl.gtfs_schedule.agency() \n",
    "    >> collect()\n",
    "    >> distinct()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46cbcee-e68b-4699-b802-a7c38169a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = m1.merge(\n",
    "    agency_info,\n",
    "    df3,\n",
    "    how=\"outer\",\n",
    "    on=[\"ALL the columns they have in common\"],\n",
    "    indicator=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9ba485-7483-4e4d-a3d2-d2625a120dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Once you are happy with your analysis, assign it to a \n",
    "new variable such as agg1 = df3.groupby().\n",
    "When you don't assign something to a variable, the results\n",
    "aren't saved.\n",
    "\"\"\"\n",
    "m1.groupby([\"column 1\", \"column 2\"]).agg({\"column 3\": \"mean/nunique/count/sum/etc\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54e0507-9298-4ed8-98a2-d782599eb403",
   "metadata": {},
   "source": [
    "## Save your work\n",
    "* You can save all your hardwork into a single Excel workbook to our [Google Cloud Storage](https://console.cloud.google.com/storage/browser/calitp-analytics-data/data-analyses/grants;tab=objects?project=cal-itp-data-infra&prefix=&forceOnObjectsSortingFiltering=false)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89dd04a-0d26-48a5-9782-b7c73a380421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be saved to our GCS bucket.\n",
    "with pd.ExcelWriter(\n",
    "    \"gs://calitp-analytics-data/data-analyses/grants/put your file name here.xlsx\"\n",
    ") as writer:\n",
    "    your_df1.to_excel(writer, sheet_name=\"your name\", index=False)\n",
    "    your_df2.to_excel(writer, sheet_name=\"your name\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
