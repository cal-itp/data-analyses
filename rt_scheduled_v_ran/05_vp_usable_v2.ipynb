{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7030d65c-ea3f-4ee7-a6cd-9ed8267bd74e",
   "metadata": {},
   "source": [
    "## Improving on Script\n",
    "* Feedback: https://github.com/cal-itp/data-analyses/pull/961"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5aa8180f-9df6-4dad-a13e-7dfeb60f4fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from calitp_data_analysis.geography_utils import WGS84\n",
    "from scripts import vp_spatial_accuracy\n",
    "from segment_speed_utils import helpers\n",
    "from segment_speed_utils import wrangle_shapes\n",
    "from segment_speed_utils.project_vars import (\n",
    "    GCS_FILE_PATH,\n",
    "    PROJECT_CRS,\n",
    "    SEGMENT_GCS,\n",
    "    analysis_date,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e64d4bd2-73ed-4636-9067-a459d1ead87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803ca629-4e90-49fc-a2d6-793a600d1ef4",
   "metadata": {},
   "source": [
    "### Filter columns \n",
    "* ['trip_instance_key', 'location_timestamp_local', 'x','y','vp_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cdc3d25e-b9a0-436e-9556-9fbbc1e0c5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = \"Bay Area 511 Muni VehiclePositions\"\n",
    "gtfs_key = \"7cc0cb1871dfd558f11a2885c145d144\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4ba298df-5f05-4840-9258-34e78da24468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vp_usable(analysis_date):\n",
    "    df = dd.read_parquet(f\"{SEGMENT_GCS}vp_usable_{analysis_date}\",\n",
    "    columns=['trip_instance_key', 'location_timestamp_local', 'x','y','vp_idx'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1dafdbaa-b4ec-4674-85b5-ca33883db605",
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_usable = load_vp_usable(analysis_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66a0806-a9a4-4075-a300-b2d924fda0ed",
   "metadata": {},
   "source": [
    "### Total Trip Time\n",
    "* Addresses \"<i>in this function, min_time, max_time are created on the grouped df (vp_usable grouped by trip and binned minute)...I think to be safer, it should be created on vp_usable grouped by trip.</i>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0eec9521-7049-4c91-9371-6198d0362c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_trip_time(vp_usable_df:pd.DataFrame):\n",
    "    \"\"\"\n",
    "    For each trip: find the total service minutes\n",
    "    recorded in real time data so we can compare it with\n",
    "    scheduled service minutes.\n",
    "    \"\"\"\n",
    "    subset = ['location_timestamp_local','trip_instance_key']\n",
    "    vp_usable_df = vp_usable_df[subset]\n",
    "    \n",
    "    # Need an extra copy of the column to find the max\n",
    "    vp_usable_df['max_time'] = vp_usable_df.location_timestamp_local\n",
    "    \n",
    "    # Find the max and the min time based on location timestamp \n",
    "    df = (vp_usable_df.groupby(['trip_instance_key'])\n",
    "       .agg({'location_timestamp_local':'min', 'max_time':'max'})\n",
    "       .reset_index()\n",
    "       .rename(columns = {'location_timestamp_local':'min_time'})\n",
    "      )\n",
    "    \n",
    "    # Find total rt service mins and add an extra minute\n",
    "    df[\"rt_service_minutes\"] = (df.max_time - df.min_time) / pd.Timedelta(minutes=1) + 1\n",
    "    \n",
    "    # Return only one row per trip with the total trip time\n",
    "    df = df.drop(columns = ['max_time', 'min_time'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6939e3ba-348f-4dbb-af87-c2fbd25aab5c",
   "metadata": {},
   "source": [
    "### Update Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5227d5df-573e-449a-8fe1-90c8e965446f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_pings_per_min(vp_usable_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each trip: find the median GTFS pings per minute, \n",
    "    the total minutes with at least 1 GTFS ping per minute,\n",
    "    and total minutes with at least 2 GTFS pings per minute.\n",
    "    \"\"\"\n",
    "    subset = ['location_timestamp_local','trip_instance_key', 'vp_idx']\n",
    "    vp_usable_df = vp_usable_df[subset]\n",
    "\n",
    "    # Find number of pings each minute\n",
    "    df = (\n",
    "        vp_usable_df.groupby(\n",
    "            [\n",
    "                \"trip_instance_key\",\n",
    "                pd.Grouper(key=\"location_timestamp_local\", freq=\"1Min\"),\n",
    "            ]\n",
    "        )\n",
    "        .vp_idx.count()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"vp_idx\": \"number_of_pings_per_minute\"})\n",
    "    )\n",
    "    \n",
    "    # Determine which rows have 2+ pings per minute\n",
    "    df = df.assign(\n",
    "        min_w_atleast2_trip_updates=df.apply(\n",
    "            lambda x: 1 if x.number_of_pings_per_minute >= 2 else 0, axis=1\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Need a copy of numer of pings per minute to count for total minutes w gtfs\n",
    "    df[\"total_minute_w_gtfs\"] = df.number_of_pings_per_minute\n",
    "\n",
    "    # Find the total min with at least 2 pings per min\n",
    "    df = (\n",
    "        df.groupby([\"trip_instance_key\"])\n",
    "        .agg(\n",
    "            {\n",
    "                \"min_w_atleast2_trip_updates\": \"sum\",\n",
    "                \"number_of_pings_per_minute\": \"median\",\n",
    "                \"total_minute_w_gtfs\": \"count\",\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "        .rename(\n",
    "            columns={\n",
    "                \"number_of_pings_per_minute\": \"median_pings_per_min\",\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dc6c1a7f-de46-4b16-afc2-7d1951dae768",
   "metadata": {},
   "outputs": [],
   "source": [
    "update = two_pings_per_min(vp_usable_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e39d975-ef55-4ea8-b5ff-e5d5c3e8ff08",
   "metadata": {},
   "source": [
    "### Spatial Accuracy\n",
    "* Addresses \"<i>in next draft, work on grouping functions that belong together, such as this one. total_counts and total_counts_by_trip sound basically equivalent, and they are nearly doing the same thing, except total_counts actually creates 2 columns. work on logically grouping or absorbing functions or rewriting functions so the same function can now be used twice.\n",
    "Adapt this function to be used twice\n",
    "Compare it to this to find where they have stuff in common and which part should be removed from the generic function</i>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a8096485-4962-4dde-8909-9d1ea9bb127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_shape_keys_in_vp(vp_usable: dd.DataFrame, analysis_date: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Subset raw vp and find unique trip_instance_keys.\n",
    "    Create crosswalk to link trip_instance_key to shape_array_key.\n",
    "    \"\"\"\n",
    "    vp_usable = (vp_usable[[\"trip_instance_key\"]]\n",
    "                 .drop_duplicates()\n",
    "                 .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    trips_with_shape = helpers.import_scheduled_trips(\n",
    "        analysis_date,\n",
    "        columns=[\"trip_instance_key\", \"shape_array_key\"],\n",
    "        get_pandas=True,\n",
    "    )\n",
    "\n",
    "    # Only one row per trip/shape\n",
    "    # trip_instance_key and shape_array_key are the only 2 cols left\n",
    "    m1 = dd.merge(vp_usable, trips_with_shape, on=\"trip_instance_key\", how=\"inner\")\n",
    "\n",
    "    return m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "54ef16ff-03a2-402e-a67b-a510dea4f0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buffer_shapes(\n",
    "    trips_with_shape: pd.DataFrame,\n",
    "    analysis_date: str,\n",
    "    buffer_meters: int = 35,\n",
    "):\n",
    "    \"\"\"\n",
    "    Filter scheduled shapes down to the shapes that appear in vp.\n",
    "    Buffer these.\n",
    "\n",
    "    Attach the shape geometry for a subset of shapes or trips.\n",
    "    \"\"\"\n",
    "    subset = trips_with_shape.shape_array_key.unique().compute().tolist()\n",
    "\n",
    "    shapes = helpers.import_scheduled_shapes(\n",
    "        analysis_date,\n",
    "        columns=[\"shape_array_key\", \"geometry\"],\n",
    "        filters=[[(\"shape_array_key\", \"in\", subset)]],\n",
    "        crs=PROJECT_CRS,\n",
    "        get_pandas=False,\n",
    "    ).pipe(helpers.remove_shapes_outside_ca)\n",
    "\n",
    "    # to_crs takes awhile, so do a filtering on only shapes we need\n",
    "    shapes = shapes.assign(geometry=shapes.geometry.buffer(buffer_meters))\n",
    "\n",
    "    trips_with_shape_geom = dd.merge(\n",
    "        shapes, trips_with_shape, on=\"shape_array_key\", how=\"inner\"\n",
    "    )\n",
    "\n",
    "    trips_with_shape_geom = trips_with_shape_geom.compute()\n",
    "    return trips_with_shape_geom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cb56d65d-471a-414b-8fe2-d8aade972ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vp_in_shape(\n",
    "    vp_usable: dd.DataFrame, trips_with_buffered_shape: gpd.GeoDataFrame\n",
    ") -> gpd.GeoDataFrame:\n",
    "\n",
    "    keep = [\"trip_instance_key\", \"x\", \"y\", \"location_timestamp_local\"]\n",
    "    vp_usable = vp_usable[keep]\n",
    "    \n",
    "    gdf = wrangle_shapes.vp_as_gdf(gdf)\n",
    "    \n",
    "    gdf = pd.merge(\n",
    "        vp_gdf, trips_with_buffered_shape, on=\"trip_instance_key\", how=\"inner\"\n",
    "    )\n",
    "    \n",
    "    gdf = gdf.assign(is_within=gdf.geometry_x.within(gdf.geometry_y))\n",
    "    gdf = gdf[[\"trip_instance_key\", \"location_timestamp_local\", \"is_within\"]]\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd996bc1-ccf5-4bcf-9ce9-807e936913e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8c1051e-af7b-490d-8b09-b5044bd7fa7a",
   "metadata": {},
   "source": [
    "#### Adapt this to be used in multiple places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8736a406-abc1-4331-a350-598cda6c5e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_vp_counts_by_trip(vp: gpd.GeoDataFrame, new_col_title:str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get a count of vp for each trip, whether or not those fall \n",
    "    within buffered shape or not\n",
    "    \"\"\"\n",
    "    count_vp = (\n",
    "        vp.groupby(\"trip_instance_key\", \n",
    "                   observed=True, group_keys=False)\n",
    "        .agg({\"location_timestamp_local\": \"count\"})\n",
    "        .reset_index()\n",
    "        .rename(columns={\"location_timestamp_local\": new_col_title})\n",
    "    )\n",
    "    \n",
    "    return count_vp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3f7ecadb-ef13-4035-a7b7-fed2fc9ab15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_counts(result: dd.DataFrame):\n",
    "    \n",
    "    # Find the total number of vps for each route\n",
    "    total_vp = total_vp_counts_by_trip(result, \"total_vps_for_route\")\n",
    "    \n",
    "    # Find the total number of vps that actually fall within the  route shape\n",
    "    result2 = result.loc[result.is_within == True].reset_index(drop = True)\n",
    "    subset = [\"trip_instance_key\", \"location_timestamp_local\"]\n",
    "    result2 = result2[subset]    \n",
    "    \n",
    "    vps_in_shape = total_vp_counts_by_trip(result, \"vp_in_shape\")\n",
    "\n",
    "    # Count total vps for the trip\n",
    "    count_df = pd.merge(total_vp, vps_in_shape, on=\"trip_instance_key\", how=\"left\")\n",
    "\n",
    "    count_df = count_df.assign(\n",
    "        vp_in_shape=count_df.vp_in_shape.fillna(0).astype(\"int32\"),\n",
    "        total_vp=count_df.total_vp.fillna(0).astype(\"int32\"),\n",
    "    )\n",
    "    \n",
    "    return count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64895df8-ab55-4251-a245-26b2f3e1808c",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
