{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3055b228-034e-4812-a3fc-3b847afb3dec",
   "metadata": {},
   "source": [
    "## Update `trips`\n",
    "* cd rt_segment_speeds && pip install -r requirements.txt && cd ../_shared_utils && make setup_env\n",
    "* https://github.com/cal-itp/data-analyses/pull/1016\n",
    "    * Keep source data + metrics tightly defined with GCS bucket organization.\n",
    "    * vp_usable is source data for rt_vs_sched metrics, do not merge in schedule data until gtfs_digest report. Only bring in schedule_gtfs_dataset_key column in * * vp_usable + route_id-direction_id for trips also present in schedule. If not in schedule, fill it with route_id = Unknown and direction_id as Int64\n",
    "    * Add function to concatenate trip file, enable us to put in 1 day or 7 days for aggregation\n",
    "    * A single function for normalized metrics (percent, per min, etc)\n",
    "    * A single function for aggregation (summing up numerator / denominator)\n",
    "    \n",
    "* https://github.com/cal-itp/data-analyses/issues/989\n",
    "\n",
    "* Notes 2/6\n",
    "    * GTFS digest creates four datasets: schedule, average speeds, segment speeds, and rt vs schedule\n",
    "    * Currently, merging is challenging.\n",
    "    * Time categories are not necessarily the same (peak/offpeak/all-day)\n",
    "    * Want all datasets to merge on the same set of columns (schedule gtfs key, route id, dir id, service date, and time categories) because `shapes` are unstable.\n",
    "    * `Route ID` has been stabilized by Tiffany \n",
    "    * Update work from `rt_v_scheduled.py` (steps already outlined in `scripts/route_aggregation.ipynb`)\n",
    "        * Do steps up until row 339 when the % are calculated. \n",
    "        * Take away `speeds`.\n",
    "        * Save this \"pre-metric\" data somewhere since it takes so long to run?\n",
    "        * Bring in schedule gtfs key, trip instance key, route id, direction id either at the beginning or the end using `helpers.import_scheduled_trips`\n",
    "        * Coerce DIR ID to Int64, don't fill it in with 0. It's not 0, it's Nan\n",
    "        * Save files with the analysis date at the end instead of the beginning.\n",
    "        * Split off the workstream -> one for trip level and one for route level\n",
    "            * Use the config.yml to save the trips and routes stuff into their own folder.\n",
    "            * Routes:\n",
    "                * For routes, the minutes/pings should be totalled up. Currently, just taking the average of an average isn't really accurate.\n",
    "                * The route level should be able to take multiple days of data and concatenate so we can get metrics for a week/2 weeks/etc instead of for a single day. [Done here](https://github.com/cal-itp/data-analyses/blob/main/rt_segment_speeds/scripts/average_speeds.py)\n",
    "                * Add the route frequency as well?\n",
    "           * Trips:\n",
    "               * Do up to step 339 in `rt_v_scheduled.py`\n",
    "               * Write a new generalized function to create all the % \n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
