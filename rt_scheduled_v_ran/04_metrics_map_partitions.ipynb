{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9a00431-464f-42f1-8778-3654457da5d7",
   "metadata": {},
   "source": [
    "## Map Partitions Test - Update Completeness\n",
    "* https://github.com/cal-itp/data-analyses/blob/main/rt_segment_speeds/scripts/nearest_vp_to_stop.py\n",
    "* The functions should all start from `vp_usable`\n",
    "* cd rt_segment_speeds && pip install -r requirements.txt && cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf04cc28-1b03-4f92-b6b7-86da90399871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import dask.dataframe as dd\n",
    "import dask_geopandas as dg\n",
    "import dask\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from scripts import vp_spatial_accuracy\n",
    "from segment_speed_utils import helpers\n",
    "from calitp_data_analysis.geography_utils import WGS84\n",
    "from segment_speed_utils.project_vars import (\n",
    "    PROJECT_CRS,\n",
    "    SEGMENT_GCS,\n",
    "    analysis_date,\n",
    "    GCS_FILE_PATH,\n",
    "    COMPILED_CACHED_VIEWS,\n",
    "    RT_SCHED_GCS,\n",
    "    CONFIG_PATH\n",
    ")\n",
    "\n",
    "from typing import Literal\n",
    "import numpy as np\n",
    "\n",
    "from shared_utils.rt_utils import MPH_PER_MPS\n",
    "from calitp_data_analysis import utils\n",
    "\n",
    "# cd rt_segment_speeds && pip install -r requirements.txt && cd\n",
    "from shared_utils import portfolio_utils, schedule_rt_utils\n",
    "from segment_speed_utils import helpers, sched_rt_utils, wrangle_shapes, segment_calcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a98ea50-2a6d-4dd8-a0d9-ecd57df6d032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Times\n",
    "import datetime\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "887862bc-178d-46ec-b3ae-f7ab4ea81a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97acad11-81a7-4e2b-b924-801b36325232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14,514,960 rows\n",
    "vp_usable= dd.read_parquet(\n",
    "      f\"{SEGMENT_GCS}vp_usable_{analysis_date}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7568383-364a-465b-ac07-3d5efba68b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtfs_keys = [\"7cc0cb1871dfd558f11a2885c145d144\",\n",
    "             \"d2b09fbd392b28d767c28ea26529b0cd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ada956-b491-4f13-a0d1-df2888631dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a subset\n",
    "# vp_usable_subset = vp_usable.loc[vp_usable.schedule_gtfs_dataset_key.isin(gtfs_keys)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ccd234-97b2-46b7-84d8-f594166e615f",
   "metadata": {},
   "source": [
    "### % of total trip time with 2 pings per minute\n",
    "* Takes 1:23 secs\n",
    "* Counting how many rows appear per minute by `trip instance key` to figure out how many gtfs pings occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0203ba3-2b59-4707-a861-ef2cb6e5cd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_pings_per_min(vp_usable_df:pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    # Find number of pings each minute\n",
    "    df = (\n",
    "        vp_usable_df.groupby(\n",
    "            [\"trip_instance_key\",\n",
    "                pd.Grouper(key=\"location_timestamp_local\", freq=\"1Min\"),\n",
    "            ]\n",
    "        )\n",
    "        .vp_idx.count()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"vp_idx\": \"number_of_pings_per_minute\"})\n",
    "    )\n",
    "    \n",
    "    # Determine which rows have 2+ pings per minute\n",
    "    df = df.assign(\n",
    "        minutes_w_atleast2_trip_updates= df.apply(\n",
    "            lambda x: 1 if x.number_of_pings_per_minute >= 2 else 0, axis=1\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Create max time col\n",
    "    df[\"max_time\"] = df.location_timestamp_local\n",
    "    \n",
    "    # Find the min time for each trip and sum up total min with at least 2 pings per min\n",
    "    df = (\n",
    "        df.groupby([\"trip_instance_key\"])\n",
    "        .agg(\n",
    "            {\n",
    "                \"location_timestamp_local\": \"min\",\n",
    "                \"max_time\": \"max\",\n",
    "                \"minutes_w_atleast2_trip_updates\": \"sum\",\n",
    "                \"number_of_pings_per_minute\":\"count\"\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "        .rename(columns={\"location_timestamp_local\": \"min_time\",\n",
    "                         \"number_of_pings_per_minute\":\"total_minute_w_gtfs\"})\n",
    "    )\n",
    "    \n",
    "    # Find total trip time and add an extra minute\n",
    "    df[\"total_trip_time\"] = (df.max_time - df.min_time) / pd.Timedelta(minutes=1) + 1\n",
    "    \n",
    "    df = df.drop(columns = ['min_time','max_time'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d321b79-57ba-4978-8d0f-7b75fe330b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = two_pings_per_min(vp_usable_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e94477-ea57-43fe-8f56-aaceb03cc945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5ffa95-0fcc-472a-a4eb-84c9284a0fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vp_usable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9198729e-5fb1-46ca-8c3e-8321fa8a7c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "print(start)\n",
    "partitions_test1 = vp_usable.map_partitions(\n",
    "       two_pings_per_min,\n",
    "        meta = {'trip_instance_key':'object', \n",
    "                'minutes_w_atleast2_trip_updates':'int64', \n",
    "                'total_minute_w_gtfs':'int64',\n",
    "                'total_trip_time':'float64',},\n",
    "        align_dataframes = False\n",
    "    ).persist()\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "logger.info(f\"execution time: {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de23210-116c-4ea3-9b11-1846892ac9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(partitions_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62a5322-9e8b-4eba-bb86-1b7e3d2e3be8",
   "metadata": {},
   "source": [
    "#### Look at one trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ab614b-8583-445c-9bbc-3c144a39f16d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df1.loc[df1.trip_instance_key == \"00068c2e2316950af50ffaa9584c7a46\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01667081-4deb-411f-9839-1a59a8218ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.loc[df2.trip_instance_key ==  \"00068c2e2316950af50ffaa9584c7a46\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2410e8-ef87-4b0d-9cc5-560a73a7a04d",
   "metadata": {},
   "source": [
    "### Density: on average, how many pings occur per minute\n",
    "* Takes 34 secs\n",
    "* Double check this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd9f03f-5471-4b14-bb83-068d69f2244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def density_pings_5_min(vp_usable_df:pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    # Count number of pings per 5 minutes\n",
    "    df = (\n",
    "        vp_usable_df.groupby(\n",
    "            [\n",
    "                *[\"trip_instance_key\"],\n",
    "                pd.Grouper(key=\"location_timestamp_local\", freq=\"5Min\"),\n",
    "            ]\n",
    "        )\n",
    "        .vp_idx.count()\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    # Find median of pings per 5 minutes for each trip\n",
    "    df = (\n",
    "        df.groupby([\"trip_instance_key\"])\n",
    "        .agg({\"vp_idx\": \"median\"})\n",
    "        .reset_index()\n",
    "        .rename(columns = {'vp_idx':'median_pings_per_5_min'})\n",
    "    )\n",
    "    \n",
    "    # Divide by 5\n",
    "    # df.median_pings_per_5_min = df.median_pings_per_5_min/5\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f5524f-97d8-48e7-b825-0f9b2f6f8c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = density_pings_5_min(vp_usable_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201daea8-b412-4211-9f1a-b92a2c414155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b64d25-7e22-47a6-8423-fe09f5be8483",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "print(start)\n",
    "partitions_test2 = vp_usable.map_partitions(\n",
    "       density_pings_5_min,\n",
    "        meta = {'trip_instance_key':'object', \n",
    "                'median_pings_per_5_min':'float64'},\n",
    "        align_dataframes = False\n",
    "    ).persist()\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "logger.info(f\"execution time: {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10246459-0137-4855-ba6a-f18cccf8582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(partitions_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a394c3a7-535a-4dc5-b62e-aa8135b98fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(partitions_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7a73e4-c744-487a-b9a3-a06c73f2302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions_test1 = partitions_test1.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dece6d7b-5fb8-4613-af15-2188533e4f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions_test1.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325fbfdf-cbf1-492d-9d8b-1e9d96efea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions_test2 = partitions_test2.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5472586d-1831-4781-a2b1-dfc95cc847a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions_test2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7e7f36-db6d-4d51-83b7-a0afb5e7e4cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b370fc-8071-454f-ba24-f374453d0d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(update_completeness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aebbd3c-f134-4507-9f7d-1a056b2727ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update_completeness.trip_instance_key.nunique().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaf4c47-92b7-470f-a21d-9d5a525e034b",
   "metadata": {},
   "source": [
    "### Spatial Accuracy\n",
    "* Do I use shapes or trips_with_shape?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c773a5-1c1d-425b-b692-6ca8c2f07575",
   "metadata": {},
   "source": [
    "#### Test to see difference between `shapes` and `trips_with_shape`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "778460e1-572f-4752-8e4f-f3e324ebf243",
   "metadata": {},
   "outputs": [],
   "source": [
    " shapes = (\n",
    "        pd.read_parquet(\n",
    "            f\"{COMPILED_CACHED_VIEWS}routelines_{analysis_date}.parquet\",\n",
    "            columns=[\"shape_array_key\"],\n",
    "        )\n",
    "        .dropna()\n",
    "        .drop_duplicates()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65b8953f-781b-4c25-9cb6-132d4d50c351",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_with_shape = (\n",
    "        helpers.import_scheduled_trips(\n",
    "            analysis_date,\n",
    "            columns=[\"trip_instance_key\", \"shape_array_key\"],\n",
    "            get_pandas=True,\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47557e70-abeb-43cd-9e32-7c0bdc8d904f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{None}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips_with_shape_shapes = set(trips_with_shape.shape_array_key.unique().tolist())\n",
    "shapes_shapes = set(shapes.shape_array_key.unique().tolist())\n",
    "trips_with_shape_shapes - shapes_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d7b88af-245b-4338-8483-dd3546092dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapes_shapes - trips_with_shape_shapes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1adcaf83-2b32-486a-97e1-9fb66fd2cb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_shape_keys_in_vp(vp_usable: dd.DataFrame, analysis_date: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Subset raw vp and find unique trip_instance_keys.\n",
    "    Create crosswalk to link trip_instance_key to shape_array_key.\n",
    "    \"\"\"\n",
    "    vp_usable = (vp_usable[['trip_instance_key']]\n",
    "                 .drop_duplicates()\n",
    "                 .reset_index(drop=True)\n",
    "                )\n",
    "\n",
    "    trips_with_shape = (\n",
    "        helpers.import_scheduled_trips(\n",
    "            analysis_date,\n",
    "            columns=[\"trip_instance_key\", \"shape_array_key\"],\n",
    "            get_pandas=False,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Only one row per trip/shape\n",
    "    # trip_instance_key and shape_array_key are the only 2 cols left\n",
    "    m1 = dd.merge(vp_usable, trips_with_shape, on = \"trip_instance_key\", how = \"inner\")\n",
    "    m1 = m1.compute() \n",
    "    \n",
    "    return m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89fa2ba9-346e-4995-9ee3-d4500134fe47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-05 11:01:58.031496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 11:02:52.197 | INFO     | __main__:<module>:5 - execution time: 0:00:54.165745\n"
     ]
    }
   ],
   "source": [
    "# 1 minute\n",
    "start = datetime.datetime.now()\n",
    "print(start)\n",
    "spatial_df1 = grab_shape_keys_in_vp(vp_usable, analysis_date)\n",
    "end = datetime.datetime.now()\n",
    "logger.info(f\"execution time: {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1886301-c774-4261-b717-d2b39445edf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spatial_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "810ca48d-fd81-4087-b36b-02d5682df883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77091"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spatial_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22118bc5-6be0-4f89-a661-9f99a68f3866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial_df1_pd = spatial_df1.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fd7cf25-8a05-47af-a834-692ba003ac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial_df1_pd.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46a8e190-6432-43ba-ad82-b11ba221ddd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(spatial_df1_pd), spatial_df1_pd.trip_instance_key.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdfd97b7-5edd-441a-8dc2-be7a159cf100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buffer_shapes2(\n",
    "    trips_with_shape: pd.DataFrame,\n",
    "    analysis_date: str,\n",
    "    buffer_meters: int = 35,\n",
    "):\n",
    "    \"\"\"\n",
    "    Filter scheduled shapes down to the shapes that appear in vp.\n",
    "    Buffer these.\n",
    "    \n",
    "    Attach the shape geometry for a subset of shapes or trips.\n",
    "    \"\"\"\n",
    "    subset = trips_with_shape.shape_array_key.unique().tolist()\n",
    "    \n",
    "    shapes = helpers.import_scheduled_shapes(\n",
    "        analysis_date,\n",
    "        columns = [\"shape_array_key\", \"geometry\"],\n",
    "        filters = [[(\"shape_array_key\", \"in\", subset)]],\n",
    "        crs = PROJECT_CRS,\n",
    "        get_pandas = True\n",
    "    )\n",
    "    \n",
    "    # to_crs takes awhile, so do a filtering on only shapes we need\n",
    "    shapes = shapes.assign(\n",
    "        geometry = shapes.geometry.buffer(buffer_meters)\n",
    "    )\n",
    "    \n",
    "    trips_with_shape_geom = pd.merge(\n",
    "        shapes,\n",
    "        trips_with_shape,\n",
    "        on = \"shape_array_key\",\n",
    "        how = \"inner\"\n",
    "    )\n",
    "    \n",
    "    return trips_with_shape_geom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80180aa3-1868-484d-8ee2-2cf3ca864eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-05 11:02:52.511491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 11:03:10.236 | INFO     | __main__:<module>:7 - execution time: 0:00:17.724454\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "print(start)\n",
    "spatial_df2 = buffer_shapes2(spatial_df1,\n",
    "       analysis_date,\n",
    "       35) \n",
    "end = datetime.datetime.now()\n",
    "logger.info(f\"execution time: {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "375a7c68-9a29-4dc7-a4bb-bb570f437aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geopandas.geodataframe.GeoDataFrame"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spatial_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6c1ed8c-2a76-47d1-82ab-01dbf882f6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77091"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spatial_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab69b4a2-a85b-4baf-98d0-ee0a137a7961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77091"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial_df2.trip_instance_key.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8ceed2-9c64-4f5e-b025-d0841717d438",
   "metadata": {},
   "source": [
    "#### Redo `merge_vp_with_shape_and_count` because it takes super long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "261cc854-60b0-442a-b031-3787ed40939c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.dataframe.core.DataFrame"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vp_usable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab8d01ce-5e48-41df-bfdb-6e06635ad655",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vp_gdf = gpd.GeoDataFrame(\n",
    "#            vp_usable_subset, geometry=gpd.points_from_xy(vp_usable_subset.x, vp_usable_subset.y), crs=WGS84\n",
    "#    ).to_crs(PROJECT_CRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39aa6670-cb5e-4120-9a8a-de713d5d4fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vp_usable_to_gdf(vp_usable: dd.DataFrame)-> gpd.GeoDataFrame:\n",
    "    \n",
    "    keep = ['trip_instance_key','x','y','location_timestamp_local']\n",
    "    vp_usable = vp_usable[keep]\n",
    "    \n",
    "    vp_gdf = gpd.GeoDataFrame(\n",
    "        vp_usable, geometry=gpd.points_from_xy(vp_usable.x, vp_usable.y), crs=WGS84\n",
    "    ).to_crs(PROJECT_CRS)\n",
    "    \n",
    "    vp_gdf = vp_gdf.rename(\n",
    "        columns={\n",
    "            0: \"trip_instance_key\",\n",
    "            3: \"location_timestamp_local\",\n",
    "          }\n",
    "    )\n",
    "    \n",
    "    vp_gdf = vp_gdf[[\"trip_instance_key\",\"location_timestamp_local\",'geometry']]\n",
    "  \n",
    "    return vp_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a61bca16-81d8-48f7-b6ba-20c65deefe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = vp_usable_to_gdf(vp_usable_subset, spatial_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f32a8266-6796-4bd8-b9ca-63a0cd87f4b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-05 11:03:10.447693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 11:04:04.064 | INFO     | __main__:<module>:11 - execution time: 0:00:53.617093\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "print(start)\n",
    "spatial_df3 = vp_usable.map_partitions(\n",
    "        vp_usable_to_gdf,\n",
    "        meta = {'trip_instance_key':'object', \n",
    "                'location_timestamp_local':'datetime64[ns]', \n",
    "                'geometry':'geometry'},\n",
    "        align_dataframes = False\n",
    "    ).persist()\n",
    "end = datetime.datetime.now()\n",
    "logger.info(f\"execution time: {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f39948f6-28ce-4a41-ab28-8f5f77c22519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.dataframe.core.DataFrame"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spatial_df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d88b951b-f002-4377-b6e0-4855a6092afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geopandas.geodataframe.GeoDataFrame"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spatial_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e32ad0e-cba8-4728-8b42-3717fbce57eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_vp_shapes(vp_gdf:dd.DataFrame, buffered_gdf:gpd.GeoDataFrame):\n",
    "    vp_gdf = vp_gdf.compute()\n",
    "    buffered_gdf = buffered_gdf.set_geometry('geometry')\n",
    "    buffered_gdf = buffered_gdf.set_crs(PROJECT_CRS)\n",
    "    \n",
    "    m1 = pd.merge(\n",
    "        vp_gdf, buffered_gdf, on=\"trip_instance_key\", how=\"inner\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e6b8772-7ddf-44a1-933d-cea2780acc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-05 11:05:35.158774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 11:05:41.275 | INFO     | __main__:<module>:5 - execution time: 0:00:06.117071\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "print(start)\n",
    "spatial_df4 = merge_vp_shapes(spatial_df3, spatial_df2)\n",
    "end = datetime.datetime.now()\n",
    "logger.info(f\"execution time: {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "efb993d9-de0b-44c0-90a0-fe828007f1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geopandas.geodataframe.GeoDataFrame"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spatial_df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2ad23cbe-1b1b-4051-9078-0e10c9670108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_counts(gdf: gpd.GeoDataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    # Count vps in the shape\n",
    "    vp2 = gdf.assign(is_within=gdf.geometry_x.within(gdf.geometry_y)).query(\n",
    "        \"is_within==True\"\n",
    "    )\n",
    "   \n",
    "    vps_in_shape = (\n",
    "        vp2.groupby(\"trip_instance_key\", observed=True, group_keys=False)\n",
    "        .agg({\"location_timestamp_local\": \"count\"})\n",
    "        .reset_index()\n",
    "        .rename(columns={\"location_timestamp_local\": \"vp_in_shape\"})\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Count total vps for the trip \n",
    "    total_vp = vp_spatial_accuracy.total_vp_counts_by_trip(gdf)\n",
    "    \n",
    "    count_df = pd.merge(total_vp, vps_in_shape, on=\"trip_instance_key\", how=\"left\")\n",
    "    \n",
    "    count_df = count_df.assign(\n",
    "        vp_in_shape=count_df.vp_in_shape.fillna(0).astype(\"int32\"),\n",
    "        total_vp=count_df.total_vp.fillna(0).astype(\"int32\"),\n",
    "    )\n",
    "\n",
    "    return vp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3439487c-2f7e-46ee-aa3c-7254170f8c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.dataframe.core.DataFrame"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vp_usable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "78ff7427-f8a1-4b60-8ae3-9d7d68739e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_usable_subset = vp_usable.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70095ff2-1f15-4db6-b561-d73c5bfb0dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_df4_subset = spatial_df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0191af76-61a4-4a3e-ad3e-054c050dff36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 11:42:30.775 | INFO     | __main__:<module>:5 - execution time: 0:00:00.024276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-05 11:42:30.751499\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = datetime.datetime.now()\n",
    "print(start)\n",
    "spatial_df5 = total_counts(spatial_df4_subset)\n",
    "end = datetime.datetime.now()\n",
    "logger.info(f\"execution time: {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "49b7d189-29b2-4e27-b6e9-293db460fb5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_instance_key</th>\n",
       "      <th>location_timestamp_local</th>\n",
       "      <th>geometry_x</th>\n",
       "      <th>shape_array_key</th>\n",
       "      <th>geometry_y</th>\n",
       "      <th>is_within</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty GeoDataFrame\n",
       "Columns: [trip_instance_key, location_timestamp_local, geometry_x, shape_array_key, geometry_y, is_within]\n",
       "Index: []"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial_df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "eda3bb73-2a2b-45f5-aade-9d7faf1a7b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstart = datetime.datetime.now()\\nprint(start)\\nspatial_df5 = vp_usable_subset.map_partitions(\\n        total_counts,\\n        meta = {\\'trip_instance_key\\':\\'object\\', \\n                \\'total_vp\\':\\'int32\\', \\n                \\'vp_in_shape\\':\\'int32\\'},\\n        align_dataframes = False\\n    ).persist()\\nend = datetime.datetime.now()\\nlogger.info(f\"execution time: {end-start}\")\\n'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "start = datetime.datetime.now()\n",
    "print(start)\n",
    "spatial_df5 = vp_usable_subset.map_partitions(\n",
    "        total_counts,\n",
    "        meta = {'trip_instance_key':'object', \n",
    "                'total_vp':'int32', \n",
    "                'vp_in_shape':'int32'},\n",
    "        align_dataframes = False\n",
    "    ).persist()\n",
    "end = datetime.datetime.now()\n",
    "logger.info(f\"execution time: {end-start}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8eee5f37-210b-4306-a347-8af901342bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_df4_dask = dd.from_pandas(spatial_df4, npartitions=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "01b3a4c8-efef-4c49-927d-681a728b7bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13068735"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spatial_df4_dask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5a92fc35-cecf-4888-93fd-5a068ab05d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_usable2 = (vp_usable[['trip_instance_key']]\n",
    "                 .drop_duplicates()\n",
    "                 .reset_index(drop=True)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0e6e4841-44f3-4ce7-9e20-5fe4c92069e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_with_shape = (\n",
    "        helpers.import_scheduled_trips(\n",
    "            analysis_date,\n",
    "            columns=[\"trip_instance_key\", \"shape_array_key\"],\n",
    "            get_pandas=False,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2724f045-8ac0-4dad-9c77-69a2e9b2ed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = dd.merge(vp_usable2, trips_with_shape, on = \"trip_instance_key\", how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a9bc9312-39ee-4f8a-81c5-2723d705a8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.dataframe.core.DataFrame"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7549e080-bcb0-47e6-807e-70ed709f7f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = m1.shape_array_key.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2ebd146e-452f-4a2b-a945-a6001954829d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.dataframe.core.Series"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "055fbf23-a4ec-4210-8242-f1c10ee84a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = subset.compute().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "582b02b2-0800-4964-af60-6b9722311a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = helpers.import_scheduled_shapes(\n",
    "        analysis_date,\n",
    "        columns = [\"shape_array_key\", \"geometry\"],\n",
    "        filters = [[(\"shape_array_key\", \"in\", subset)]],\n",
    "        crs = PROJECT_CRS,\n",
    "        get_pandas = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1db1682d-0775-4a29-bc1d-5b72c338f0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_accuracy_test(vp_usable: dd.DataFrame, analysis_date: str, buffer_meters:int = 35):\n",
    "    vp_usable2 = (vp_usable[['trip_instance_key']]\n",
    "                 .drop_duplicates()\n",
    "                 .reset_index(drop=True)\n",
    "                )\n",
    "\n",
    "    trips_with_shape = (\n",
    "        helpers.import_scheduled_trips(\n",
    "            analysis_date,\n",
    "            columns=[\"trip_instance_key\", \"shape_array_key\"],\n",
    "            get_pandas=False,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Only one row per trip/shape\n",
    "    # trip_instance_key and shape_array_key are the only 2 cols left\n",
    "    m1 = dd.merge(vp_usable2, trips_with_shape, on = \"trip_instance_key\", how = \"inner\")\n",
    "    \n",
    "    subset = m1.shape_array_key.unique()\n",
    "    subset = subset.compute().tolist()\n",
    "    \n",
    "    shapes = helpers.import_scheduled_shapes(\n",
    "        analysis_date,\n",
    "        columns = [\"shape_array_key\", \"geometry\"],\n",
    "        filters = [[(\"shape_array_key\", \"in\", subset)]],\n",
    "        crs = PROJECT_CRS,\n",
    "        get_pandas = True\n",
    "    )\n",
    "    \n",
    "    # to_crs takes awhile, so do a filtering on only shapes we need\n",
    "    shapes = shapes.assign(\n",
    "        geometry = shapes.geometry.buffer(buffer_meters)\n",
    "    )\n",
    "    \n",
    "    trips_with_shape_geom = pd.merge(\n",
    "        shapes,\n",
    "        m1,\n",
    "        on = \"shape_array_key\",\n",
    "        how = \"inner\"\n",
    "    )\n",
    "    \n",
    "    keep = ['trip_instance_key','x','y','location_timestamp_local']\n",
    "    vp_usable3 = vp_usable[keep]\n",
    "    \n",
    "    vp_gdf = gpd.GeoDataFrame(\n",
    "        vp_usable3, geometry=gpd.points_from_xy(vp_usable3.x, vp_usable3.y), crs=WGS84\n",
    "    ).to_crs(PROJECT_CRS)\n",
    "    \n",
    "    vp_gdf = vp_gdf.rename(\n",
    "        columns={\n",
    "            0: \"trip_instance_key\",\n",
    "            3: \"location_timestamp_local\",\n",
    "          }\n",
    "    )\n",
    "    \n",
    "    vp_gdf = vp_gdf[[\"trip_instance_key\",\"location_timestamp_local\",'geometry']]\n",
    "    \n",
    "    trips_with_shape_geom = trips_with_shape_geom.set_geometry('geometry')\n",
    "    trips_with_shape_geom = trips_with_shape_geom.set_crs(PROJECT_CRS)\n",
    "    \n",
    "    m2 = pd.merge(\n",
    "        vp_gdf, buffered_gdf, on=\"trip_instance_key\", how=\"inner\"\n",
    "    )\n",
    "    \n",
    "    vp2 = m2.assign(is_within=m2.geometry_x.within(m2.geometry_y)).query(\n",
    "        \"is_within==True\"\n",
    "    )\n",
    "    \n",
    "    vps_in_shape = (\n",
    "        vp2.groupby(\"trip_instance_key\", observed=True, group_keys=False)\n",
    "        .agg({\"location_timestamp_local\": \"count\"})\n",
    "        .reset_index()\n",
    "        .rename(columns={\"location_timestamp_local\": \"vp_in_shape\"})\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Count total vps for the trip \n",
    "    total_vp = vp_spatial_accuracy.total_vp_counts_by_trip(m2)\n",
    "    \n",
    "    count_df = pd.merge(total_vp, vps_in_shape, on=\"trip_instance_key\", how=\"left\")\n",
    "    \n",
    "    count_df = count_df.assign(\n",
    "        vp_in_shape=count_df.vp_in_shape.fillna(0).astype(\"int32\"),\n",
    "        total_vp=count_df.total_vp.fillna(0).astype(\"int32\"),\n",
    "    )\n",
    "\n",
    "    return count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c9cbdb52-4610-4a42-828b-1f57584fd67e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-05 12:02:12.920052\n"
     ]
    },
    {
     "ename": "ArrowTypeError",
     "evalue": "Array type doesn't match type of values set: string vs null",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m start \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(start)\n\u001b[0;32m----> 3\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mvp_usable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_partitions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspatial_accuracy_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43manalysis_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m35\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrip_instance_key\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mobject\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtotal_vp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mint32\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvp_in_shape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mint32\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43malign_dataframes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpersist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m end \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m     13\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;241m-\u001b[39mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/dask/base.py:288\u001b[0m, in \u001b[0;36mDaskMethodsMixin.persist\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpersist\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    250\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Persist this dask collection into memory\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \n\u001b[1;32m    252\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into a Dask collection with the same\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;124;03m    dask.base.persist\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 288\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mpersist\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/dask/base.py:901\u001b[0m, in \u001b[0;36mpersist\u001b[0;34m(traverse, optimize_graph, scheduler, *args, **kwargs)\u001b[0m\n\u001b[1;32m    898\u001b[0m     keys\u001b[38;5;241m.\u001b[39mextend(a_keys)\n\u001b[1;32m    899\u001b[0m     postpersists\u001b[38;5;241m.\u001b[39mappend((rebuild, a_keys, state))\n\u001b[0;32m--> 901\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(keys, results))\n\u001b[1;32m    903\u001b[0m results2 \u001b[38;5;241m=\u001b[39m [r({k: d[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m ks}, \u001b[38;5;241m*\u001b[39ms) \u001b[38;5;28;01mfor\u001b[39;00m r, ks, s \u001b[38;5;129;01min\u001b[39;00m postpersists]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/dask/threaded.py:89\u001b[0m, in \u001b[0;36mget\u001b[0;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pool, multiprocessing\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mPool):\n\u001b[1;32m     87\u001b[0m         pool \u001b[38;5;241m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[0;32m---> 89\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mget_async\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_thread_get_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpack_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpack_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/dask/local.py:511\u001b[0m, in \u001b[0;36mget_async\u001b[0;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m         _execute_task(task, data)  \u001b[38;5;66;03m# Re-execute locally\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         \u001b[43mraise_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    512\u001b[0m res, worker_id \u001b[38;5;241m=\u001b[39m loads(res_info)\n\u001b[1;32m    513\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache\u001b[39m\u001b[38;5;124m\"\u001b[39m][key] \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/dask/local.py:319\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(exc, tb)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m--> 319\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/dask/local.py:224\u001b[0m, in \u001b[0;36mexecute_task\u001b[0;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     task, data \u001b[38;5;241m=\u001b[39m loads(task_info)\n\u001b[0;32m--> 224\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m get_id()\n\u001b[1;32m    226\u001b[0m     result \u001b[38;5;241m=\u001b[39m dumps((result, \u001b[38;5;28mid\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/dask/optimization.py:990\u001b[0m, in \u001b[0;36mSubgraphCallable.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minkeys):\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m args, got \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minkeys), \u001b[38;5;28mlen\u001b[39m(args)))\n\u001b[0;32m--> 990\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/dask/core.py:149\u001b[0m, in \u001b[0;36mget\u001b[0;34m(dsk, out, cache)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m toposort(dsk):\n\u001b[1;32m    148\u001b[0m     task \u001b[38;5;241m=\u001b[39m dsk[key]\n\u001b[0;32m--> 149\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m     cache[key] \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m    151\u001b[0m result \u001b[38;5;241m=\u001b[39m _execute_task(out, cache)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/dask/utils.py:71\u001b[0m, in \u001b[0;36mapply\u001b[0;34m(func, args, kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Apply a function given its positional and keyword arguments.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03mEquivalent to ``func(*args, **kwargs)``\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m>>> dsk = {'task-name': task}  # adds the task to a low level Dask task graph\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/dask/dataframe/core.py:6663\u001b[0m, in \u001b[0;36mapply_and_enforce\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   6661\u001b[0m func \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_func\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6662\u001b[0m meta \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_meta\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 6663\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dataframe_like(df) \u001b[38;5;129;01mor\u001b[39;00m is_series_like(df) \u001b[38;5;129;01mor\u001b[39;00m is_index_like(df):\n\u001b[1;32m   6665\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(df):\n",
      "Cell \u001b[0;32mIn[113], line 22\u001b[0m, in \u001b[0;36mspatial_accuracy_test\u001b[0;34m(vp_usable, analysis_date, buffer_meters)\u001b[0m\n\u001b[1;32m     19\u001b[0m subset \u001b[38;5;241m=\u001b[39m m1\u001b[38;5;241m.\u001b[39mshape_array_key\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m     20\u001b[0m subset \u001b[38;5;241m=\u001b[39m subset\u001b[38;5;241m.\u001b[39mcompute()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m---> 22\u001b[0m shapes \u001b[38;5;241m=\u001b[39m \u001b[43mhelpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_scheduled_shapes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43manalysis_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshape_array_key\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgeometry\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshape_array_key\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43min\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcrs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mPROJECT_CRS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_pandas\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     28\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# to_crs takes awhile, so do a filtering on only shapes we need\u001b[39;00m\n\u001b[1;32m     31\u001b[0m shapes \u001b[38;5;241m=\u001b[39m shapes\u001b[38;5;241m.\u001b[39massign(\n\u001b[1;32m     32\u001b[0m     geometry \u001b[38;5;241m=\u001b[39m shapes\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39mbuffer(buffer_meters)\n\u001b[1;32m     33\u001b[0m )\n",
      "File \u001b[0;32m~/data-analyses/rt_segment_speeds/segment_speed_utils/helpers.py:149\u001b[0m, in \u001b[0;36mimport_scheduled_shapes\u001b[0;34m(analysis_date, filters, columns, get_pandas, crs)\u001b[0m\n\u001b[1;32m    146\u001b[0m FILE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCOMPILED_CACHED_VIEWS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mroutelines_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00manalysis_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m get_pandas: \n\u001b[0;32m--> 149\u001b[0m     shapes \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFILE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     shapes \u001b[38;5;241m=\u001b[39m dg\u001b[38;5;241m.\u001b[39mread_parquet(FILE, filters \u001b[38;5;241m=\u001b[39m filters,\n\u001b[1;32m    153\u001b[0m                              columns \u001b[38;5;241m=\u001b[39m columns)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/geopandas/io/arrow.py:599\u001b[0m, in \u001b[0;36m_read_parquet\u001b[0;34m(path, columns, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    597\u001b[0m path \u001b[38;5;241m=\u001b[39m _expand_user(path)\n\u001b[1;32m    598\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_pandas_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 599\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[43mparquet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;66;03m# read metadata separately to get the raw Parquet FileMetaData metadata\u001b[39;00m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;66;03m# (pyarrow doesn't properly exposes those in schema.metadata for files\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;66;03m# created by GDAL - https://issues.apache.org/jira/browse/ARROW-16688)\u001b[39;00m\n\u001b[1;32m    604\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pyarrow/parquet/core.py:3003\u001b[0m, in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, metadata, schema, use_pandas_metadata, read_dictionary, memory_map, buffer_size, partitioning, filesystem, filters, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit)\u001b[0m\n\u001b[1;32m   2992\u001b[0m         \u001b[38;5;66;03m# TODO test that source is not a directory or a list\u001b[39;00m\n\u001b[1;32m   2993\u001b[0m         dataset \u001b[38;5;241m=\u001b[39m ParquetFile(\n\u001b[1;32m   2994\u001b[0m             source, metadata\u001b[38;5;241m=\u001b[39mmetadata, read_dictionary\u001b[38;5;241m=\u001b[39mread_dictionary,\n\u001b[1;32m   2995\u001b[0m             memory_map\u001b[38;5;241m=\u001b[39mmemory_map, buffer_size\u001b[38;5;241m=\u001b[39mbuffer_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3000\u001b[0m             thrift_container_size_limit\u001b[38;5;241m=\u001b[39mthrift_container_size_limit,\n\u001b[1;32m   3001\u001b[0m         )\n\u001b[0;32m-> 3003\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3004\u001b[0m \u001b[43m                        \u001b[49m\u001b[43muse_pandas_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_pandas_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3006\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   3007\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_legacy_dataset=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to get the legacy behaviour is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3008\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated as of pyarrow 8.0.0, and the legacy implementation will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3009\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbe removed in a future version.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3010\u001b[0m     \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   3012\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_prefixes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pyarrow/parquet/core.py:2631\u001b[0m, in \u001b[0;36m_ParquetDatasetV2.read\u001b[0;34m(self, columns, use_threads, use_pandas_metadata)\u001b[0m\n\u001b[1;32m   2623\u001b[0m         index_columns \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   2624\u001b[0m             col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m _get_pandas_index_columns(metadata)\n\u001b[1;32m   2625\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m   2626\u001b[0m         ]\n\u001b[1;32m   2627\u001b[0m         columns \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2628\u001b[0m             \u001b[38;5;28mlist\u001b[39m(columns) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(index_columns) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(columns))\n\u001b[1;32m   2629\u001b[0m         )\n\u001b[0;32m-> 2631\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filter_expression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2633\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_threads\u001b[49m\n\u001b[1;32m   2634\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2636\u001b[0m \u001b[38;5;66;03m# if use_pandas_metadata, restore the pandas metadata (which gets\u001b[39;00m\n\u001b[1;32m   2637\u001b[0m \u001b[38;5;66;03m# lost if doing a specific `columns` selection in to_table)\u001b[39;00m\n\u001b[1;32m   2638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_pandas_metadata:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pyarrow/_dataset.pyx:547\u001b[0m, in \u001b[0;36mpyarrow._dataset.Dataset.to_table\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pyarrow/_dataset.pyx:393\u001b[0m, in \u001b[0;36mpyarrow._dataset.Dataset.scanner\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pyarrow/_dataset.pyx:3466\u001b[0m, in \u001b[0;36mpyarrow._dataset.Scanner.from_dataset\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pyarrow/_dataset.pyx:3384\u001b[0m, in \u001b[0;36mpyarrow._dataset.Scanner._make_scan_options\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pyarrow/_dataset.pyx:3318\u001b[0m, in \u001b[0;36mpyarrow._dataset._populate_builder\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pyarrow/_compute.pyx:2697\u001b[0m, in \u001b[0;36mpyarrow._compute._bind\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pyarrow/error.pxi:154\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pyarrow/error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowTypeError\u001b[0m: Array type doesn't match type of values set: string vs null"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "print(start)\n",
    "test = vp_usable.map_partitions(\n",
    "        spatial_accuracy_test,\n",
    "        analysis_date, \n",
    "        35,\n",
    "        meta = {'trip_instance_key':'object', \n",
    "                'total_vp':'int32', \n",
    "                'vp_in_shape':'int32'},\n",
    "        align_dataframes = False\n",
    "    ).persist()\n",
    "end = datetime.datetime.now()\n",
    "logger.info(f\"execution time: {end-start}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
