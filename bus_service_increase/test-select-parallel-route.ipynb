{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ad91875-a780-443a-a367-6410ee504463",
   "metadata": {},
   "source": [
    "# Use existing warehouse queries?\n",
    "\n",
    "* Grab trips for selected date.\n",
    "* Let's test with a parquet already stored in GCS for `bus-service-increase` exercise.\n",
    "* Filter down to 1 trip for `route_id`...pick for relatively free-flowing traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77e6937b-3105-446a-897d-6f4356d2b972",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/geopandas/_compat.py:111: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "E0321 20:16:36.142038405     972 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0321 20:16:45.778818294     972 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "os.environ[\"CALITP_BQ_MAX_BYTES\"] = str(130_000_000_000)\n",
    "\n",
    "from calitp.tables import tbl\n",
    "from calitp import query_sql\n",
    "from siuba import *\n",
    "\n",
    "import utils\n",
    "import shared_utils\n",
    "\n",
    "DATA_PATH = f\"{utils.GCS_FILE_PATH}2022_Jan/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8e2ff3b-0487-4dcb-8f50-9863c37a0785",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = pd.read_parquet(f\"{DATA_PATH}trips_joined_thurs.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "660d0de4-8f20-43f3-b6e8-e21ba1bca24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_DATE = '2022-1-6'\n",
    "#SELECTED_DATE = warehouse_queries.dates['thurs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b7fe3ff-af14-490e-9585-ae8a38011926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_service_hours(df, SELECTED_DATE):\n",
    "    daily_trip_info = (\n",
    "        tbl.views.gtfs_schedule_fact_daily_trips()\n",
    "        >> filter(_.service_date == SELECTED_DATE)\n",
    "        >> select(_.calitp_itp_id, \n",
    "               _.trip_key, _.service_hours, \n",
    "               _.trip_first_departure_ts, _.trip_last_arrival_ts\n",
    "              ) \n",
    "        >> collect()\n",
    "    )\n",
    "    \n",
    "    df2 = pd.merge(df, \n",
    "                   daily_trip_info,\n",
    "                   on = [\"calitp_itp_id\", \"trip_key\"],\n",
    "                   how = \"inner\",\n",
    "                   # m:1 because trips has stop_level data by trips\n",
    "                   # 1 is on the right beause service_hours is trip-level\n",
    "                   validate = \"m:1\"\n",
    "                  )\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e249ced-9644-4942-8091-4b328fadc1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_one_trip(df):\n",
    "    drop_cols = [\"stop_sequence\", \"stop_id\", \"departure_time\", \n",
    "                 \"trip_first_departure_ts\", \"trip_last_arrival_ts\", \n",
    "                ]\n",
    "    \n",
    "\n",
    "    df = df.assign(\n",
    "        departure_hr = pd.to_datetime(df.trip_first_departure_ts, unit='s').dt.hour                                        \n",
    "    ).drop(columns = drop_cols).drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    # Across trip_ids, for the same route_id, there are differing max_stop_sequence\n",
    "    # Can't use max_stop_sequence to find longest route_length\n",
    "    # Use service hours instead to find faster trip during free-flowing traffic\n",
    "    group_cols = [\"calitp_itp_id\", \"route_id\"]\n",
    "    \n",
    "    # Should there be a check that there are mid-day trips for that route_id?\n",
    "    # Select trip by departure_hr\n",
    "    hour_order = [\n",
    "        12, 11, 13, 10, 14, # ideally we want mid-day\n",
    "        15, 7, 20, 6, 21, # but, can move into earlier PM or early AM\n",
    "        0, 1, 2, 3, 4, 5, 22, 23, # owl service\n",
    "        8, 9, # AM peak \n",
    "        16, 17, 18, 19, # PM peak\n",
    "    ]\n",
    "    for i in range(0, 24):\n",
    "        if i == 0:\n",
    "            df['selection_rank'] = df.apply(\n",
    "                lambda x: hour_order[i] if x.departure_hr == i \n",
    "                else 0, axis=1) \n",
    "        else:\n",
    "            df['selection_rank'] = df.apply(\n",
    "                lambda x: hour_order[i] if x.departure_hr == i \n",
    "                else x.selection_rank, axis=1) \n",
    "    \n",
    "    # Select a trip that closest to 25th percentile (lower means faster!)\n",
    "    # This groupby ruins the index, throws an error, so just merge in as separate df\n",
    "    quantile = (df.groupby(group_cols)[\"service_hours\"]\n",
    "                .quantile(0.25).reset_index()\n",
    "                .rename(columns = {\"service_hours\": \"p25\"})\n",
    "               )\n",
    "    \n",
    "    df = pd.merge(df, quantile, \n",
    "                  on = group_cols,\n",
    "                  how = \"inner\",\n",
    "                  validate = \"m:1\"\n",
    "            )\n",
    "    \n",
    "    # Select trip that is closest to 25th percentile (min_diff)\n",
    "    df[\"difference\"] = df.service_hours - df.p25\n",
    "    df[\"min_diff\"] = df.groupby(group_cols)[\"difference\"].transform(\"min\")\n",
    "\n",
    "    df['faster_trip'] = df.apply(lambda x: \n",
    "                                 1 if x.difference == x.min_diff else 0, axis=1)\n",
    "    \n",
    "    # If there are multiple trips selected for a route, do a sort/drop duplicates\n",
    "    # This df is trip-level (no stop_id, becuase that was dropped at beginning)\n",
    "    df2 = (df[df.faster_trip==1]\n",
    "           .sort_values(group_cols + [\"departure_hr\"], \n",
    "                        # If there are multiple trips with same service hours, \n",
    "                        # pick one with later departure hr (closer to mid-day)\n",
    "                        ascending=[True, True, False])\n",
    "           .drop_duplicates(subset=group_cols)\n",
    "           .drop(columns = [\"faster_trip\", \"difference\", \"min_diff\", \n",
    "                            \"p25\", \"selection_rank\"])\n",
    "           .reset_index(drop=True)\n",
    "          )\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6ec5ebc-c935-45a1-953c-feeaa66a839d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/siuba/sql/utils.py:52: SAWarning: Dialect bigquery:bigquery will not make use of SQL compilation caching as it does not set the 'supports_statement_cache' attribute to ``True``.  This can have significant performance implications including some performance degradations in comparison to prior SQLAlchemy versions.  Dialect maintainers should seek to set this attribute to True after appropriate development and testing for SQLAlchemy 1.4 caching support.   Alternatively, this attribute may be set to False which will disable this warning. (Background on this error at: https://sqlalche.me/e/14/cprf)\n"
     ]
    }
   ],
   "source": [
    "trips2 = grab_service_hours(trips, SELECTED_DATE)\n",
    "trips2.to_parquet(\"./data/trips_with_hours.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f49ddf91-b865-475a-9253-fc46b59e2f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips2 = pd.read_parquet(\"./data/trips_with_hours.parquet\")\n",
    "\n",
    "trips3 = select_one_trip(trips2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46e27f10-df4f-42ae-ad1d-82fcb7dd9d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_to_parallel_routes(df):\n",
    "    # Just use route_id to flag parallel, not shape_id\n",
    "    # It won't matter anyway, because we will use stop's point geom\n",
    "    #parallel_routes = shared_utils.utils.download_geoparquet(utils.GCS_FILE_PATH, \n",
    "    #                                         \"parallel_or_intersecting\")\n",
    "    parallel_routes = gpd.read_parquet(\"./data/parallel_or_intersecting.parquet\")\n",
    "    \n",
    "    keep_cols = [\"calitp_itp_id\", \"route_id\", \"geometry\"]\n",
    "\n",
    "    parallel_routes2 = (parallel_routes[parallel_routes.parallel==1]\n",
    "           .reset_index(drop=True)\n",
    "           .rename(columns = {\"itp_id\": \"calitp_itp_id\"})\n",
    "           [keep_cols]\n",
    "           .drop_duplicates()\n",
    "           .reset_index(drop=True)\n",
    "          )\n",
    "    \n",
    "    # Put parallel routes on the left because it has line geometry already\n",
    "    gdf = pd.merge(\n",
    "        parallel_routes2,\n",
    "        df,\n",
    "        on = [\"calitp_itp_id\", \"route_id\"],\n",
    "        how = \"inner\",\n",
    "        validate = \"1:m\",\n",
    "    )\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f645a07-fc83-4a27-9176-f1ccd2993665",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips4 = subset_to_parallel_routes(trips3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f301143-07b9-4518-ab0c-f747453402ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# rows in trips3: 3314\n",
      "# rows in trips4: 2242\n",
      "# LA Metro rows in trips3: 113\n",
      "# LA Metro rows in trips4: 73\n"
     ]
    }
   ],
   "source": [
    "print(f\"# rows in trips3: {len(trips3)}\")\n",
    "print(f\"# rows in trips4: {len(trips4)}\")\n",
    "print(f\"# LA Metro rows in trips3: {len(trips3[trips3.calitp_itp_id==182])}\")\n",
    "print(f\"# LA Metro rows in trips4: {len(trips4[trips4.calitp_itp_id==182])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875980e6-48f0-4f36-bdb0-c78061d33cff",
   "metadata": {},
   "source": [
    "Decide if stop's point geometry should be used or route's line geometry.\n",
    "\n",
    "If going with every 3rd or 5th bus stop, it's easier to take point geometry and have the car travel from point to point. The line geometry contains much more points in between stops and is not exactly the bus stop, but on the road.\n",
    "\n",
    "For this calculation, distance traveled, speed, etc, it probably won't matter too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2661f152-0478-4e0a-853e-bfdf16bebd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_stop_geom(df):\n",
    "    stop_info = (tbl.views.gtfs_schedule_dim_stops()\n",
    "                 >> select(_.calitp_itp_id,\n",
    "                       _.stop_id, _.stop_lon, _.stop_lat,\n",
    "                      )\n",
    "             >> distinct()\n",
    "             >> collect()\n",
    "    )\n",
    "    \n",
    "    df2 = pd.merge(\n",
    "        df,\n",
    "        (stop_info.sort_values([\"calitp_itp_id\", \"stop_id\", \"stop_lon\"])\n",
    "         .drop_duplicates(subset=[\"calitp_itp_id\", \"stop_id\"])\n",
    "        ),\n",
    "        on = [\"calitp_itp_id\", \"stop_id\"],\n",
    "        how = \"inner\", \n",
    "        validate = \"m:1\"\n",
    "    )\n",
    "    \n",
    "    gdf = (shared_utils.geography_utils.create_point_geometry(df2)\n",
    "           .sort_values([\"calitp_itp_id\", \"route_id\", \n",
    "                         \"trip_id\", \"stop_sequence\"])\n",
    "           .reset_index(drop=True)\n",
    "           .drop(columns = [\"stop_lon\", \"stop_lat\", \n",
    "                            \"trip_first_departure_ts\", \"trip_last_arrival_ts\"])\n",
    "          )\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4e6bcb3-716d-4969-9bff-f679e25d538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall: trips2 contains stop_id\n",
    "# trips4 is trip-level\n",
    "# Pare down trips2 with isin\n",
    "trips5 = trips2[trips2.trip_key.isin(trips4.trip_key)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1b317a2-2b6d-4997-b211-b648eadb92bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips6 = grab_stop_geom(trips5)\n",
    "trips6.to_parquet(\"./data/cleaned_trips_with_stops.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33c69e2b-300f-4c21-8910-f363564137b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_972/541236954.py:1: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n"
     ]
    }
   ],
   "source": [
    "# Can use trips6 to select every 3rd or every 5th stop, calculate distance traveled, etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94a703e3-b668-41b2-b473-21ad331db78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['calitp_itp_id', 'date', 'trip_key', 'trip_id', 'is_in_service',\n",
       "       'day_name', 'stop_sequence', 'stop_id', 'departure_time', 'shape_id',\n",
       "       'route_id', 'service_hours', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips6.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c06a656b-072c-4b94-a45f-a871652c0ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calitp_itp_id</th>\n",
       "      <th>date</th>\n",
       "      <th>trip_key</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>is_in_service</th>\n",
       "      <th>day_name</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>shape_id</th>\n",
       "      <th>route_id</th>\n",
       "      <th>service_hours</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20313</th>\n",
       "      <td>182</td>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>-4877570458680265374</td>\n",
       "      <td>10901000570527-DEC21</td>\n",
       "      <td>True</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>1</td>\n",
       "      <td>15684</td>\n",
       "      <td>05:27:00</td>\n",
       "      <td>9010057_DEC21</td>\n",
       "      <td>901-13153</td>\n",
       "      <td>0.6</td>\n",
       "      <td>POINT (-118.37799 34.16846)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20314</th>\n",
       "      <td>182</td>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>-4877570458680265374</td>\n",
       "      <td>10901000570527-DEC21</td>\n",
       "      <td>True</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>2</td>\n",
       "      <td>15611</td>\n",
       "      <td>05:30:00</td>\n",
       "      <td>9010057_DEC21</td>\n",
       "      <td>901-13153</td>\n",
       "      <td>0.6</td>\n",
       "      <td>POINT (-118.39730 34.16857)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20315</th>\n",
       "      <td>182</td>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>-4877570458680265374</td>\n",
       "      <td>10901000570527-DEC21</td>\n",
       "      <td>True</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>3</td>\n",
       "      <td>15661</td>\n",
       "      <td>05:35:00</td>\n",
       "      <td>9010057_DEC21</td>\n",
       "      <td>901-13153</td>\n",
       "      <td>0.6</td>\n",
       "      <td>POINT (-118.42292 34.17288)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20316</th>\n",
       "      <td>182</td>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>-4877570458680265374</td>\n",
       "      <td>10901000570527-DEC21</td>\n",
       "      <td>True</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>4</td>\n",
       "      <td>15583</td>\n",
       "      <td>05:37:00</td>\n",
       "      <td>9010057_DEC21</td>\n",
       "      <td>901-13153</td>\n",
       "      <td>0.6</td>\n",
       "      <td>POINT (-118.42960 34.17916)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20317</th>\n",
       "      <td>182</td>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>-4877570458680265374</td>\n",
       "      <td>10901000570527-DEC21</td>\n",
       "      <td>True</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>5</td>\n",
       "      <td>15546</td>\n",
       "      <td>05:40:00</td>\n",
       "      <td>9010057_DEC21</td>\n",
       "      <td>901-13153</td>\n",
       "      <td>0.6</td>\n",
       "      <td>POINT (-118.44826 34.18064)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20318</th>\n",
       "      <td>182</td>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>-4877570458680265374</td>\n",
       "      <td>10901000570527-DEC21</td>\n",
       "      <td>True</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>6</td>\n",
       "      <td>15535</td>\n",
       "      <td>05:43:00</td>\n",
       "      <td>9010057_DEC21</td>\n",
       "      <td>901-13153</td>\n",
       "      <td>0.6</td>\n",
       "      <td>POINT (-118.46903 34.18090)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20319</th>\n",
       "      <td>182</td>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>-4877570458680265374</td>\n",
       "      <td>10901000570527-DEC21</td>\n",
       "      <td>True</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>7</td>\n",
       "      <td>15588</td>\n",
       "      <td>05:46:00</td>\n",
       "      <td>9010057_DEC21</td>\n",
       "      <td>901-13153</td>\n",
       "      <td>0.6</td>\n",
       "      <td>POINT (-118.48443 34.18629)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20320</th>\n",
       "      <td>182</td>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>-4877570458680265374</td>\n",
       "      <td>10901000570527-DEC21</td>\n",
       "      <td>True</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>8</td>\n",
       "      <td>15515</td>\n",
       "      <td>05:48:00</td>\n",
       "      <td>9010057_DEC21</td>\n",
       "      <td>901-13153</td>\n",
       "      <td>0.6</td>\n",
       "      <td>POINT (-118.50072 34.18597)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20321</th>\n",
       "      <td>182</td>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>-4877570458680265374</td>\n",
       "      <td>10901000570527-DEC21</td>\n",
       "      <td>True</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>9</td>\n",
       "      <td>15415</td>\n",
       "      <td>05:54:00</td>\n",
       "      <td>9010057_DEC21</td>\n",
       "      <td>901-13153</td>\n",
       "      <td>0.6</td>\n",
       "      <td>POINT (-118.53680 34.18044)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20322</th>\n",
       "      <td>182</td>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>-4877570458680265374</td>\n",
       "      <td>10901000570527-DEC21</td>\n",
       "      <td>True</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>10</td>\n",
       "      <td>15435</td>\n",
       "      <td>05:56:00</td>\n",
       "      <td>9010057_DEC21</td>\n",
       "      <td>901-13153</td>\n",
       "      <td>0.6</td>\n",
       "      <td>POINT (-118.55419 34.18156)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20323</th>\n",
       "      <td>182</td>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>-4877570458680265374</td>\n",
       "      <td>10901000570527-DEC21</td>\n",
       "      <td>True</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>11</td>\n",
       "      <td>15312</td>\n",
       "      <td>05:59:00</td>\n",
       "      <td>9010057_DEC21</td>\n",
       "      <td>901-13153</td>\n",
       "      <td>0.6</td>\n",
       "      <td>POINT (-118.57166 34.18747)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20324</th>\n",
       "      <td>182</td>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>-4877570458680265374</td>\n",
       "      <td>10901000570527-DEC21</td>\n",
       "      <td>True</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>12</td>\n",
       "      <td>15438</td>\n",
       "      <td>06:02:00</td>\n",
       "      <td>9010057_DEC21</td>\n",
       "      <td>901-13153</td>\n",
       "      <td>0.6</td>\n",
       "      <td>POINT (-118.58925 34.18874)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20325</th>\n",
       "      <td>182</td>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>-4877570458680265374</td>\n",
       "      <td>10901000570527-DEC21</td>\n",
       "      <td>True</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>13</td>\n",
       "      <td>15458</td>\n",
       "      <td>06:03:00</td>\n",
       "      <td>9010057_DEC21</td>\n",
       "      <td>901-13153</td>\n",
       "      <td>0.6</td>\n",
       "      <td>POINT (-118.59682 34.19060)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       calitp_itp_id        date             trip_key               trip_id  \\\n",
       "20313            182  2022-01-06 -4877570458680265374  10901000570527-DEC21   \n",
       "20314            182  2022-01-06 -4877570458680265374  10901000570527-DEC21   \n",
       "20315            182  2022-01-06 -4877570458680265374  10901000570527-DEC21   \n",
       "20316            182  2022-01-06 -4877570458680265374  10901000570527-DEC21   \n",
       "20317            182  2022-01-06 -4877570458680265374  10901000570527-DEC21   \n",
       "20318            182  2022-01-06 -4877570458680265374  10901000570527-DEC21   \n",
       "20319            182  2022-01-06 -4877570458680265374  10901000570527-DEC21   \n",
       "20320            182  2022-01-06 -4877570458680265374  10901000570527-DEC21   \n",
       "20321            182  2022-01-06 -4877570458680265374  10901000570527-DEC21   \n",
       "20322            182  2022-01-06 -4877570458680265374  10901000570527-DEC21   \n",
       "20323            182  2022-01-06 -4877570458680265374  10901000570527-DEC21   \n",
       "20324            182  2022-01-06 -4877570458680265374  10901000570527-DEC21   \n",
       "20325            182  2022-01-06 -4877570458680265374  10901000570527-DEC21   \n",
       "\n",
       "       is_in_service  day_name  stop_sequence stop_id departure_time  \\\n",
       "20313           True  Thursday              1   15684       05:27:00   \n",
       "20314           True  Thursday              2   15611       05:30:00   \n",
       "20315           True  Thursday              3   15661       05:35:00   \n",
       "20316           True  Thursday              4   15583       05:37:00   \n",
       "20317           True  Thursday              5   15546       05:40:00   \n",
       "20318           True  Thursday              6   15535       05:43:00   \n",
       "20319           True  Thursday              7   15588       05:46:00   \n",
       "20320           True  Thursday              8   15515       05:48:00   \n",
       "20321           True  Thursday              9   15415       05:54:00   \n",
       "20322           True  Thursday             10   15435       05:56:00   \n",
       "20323           True  Thursday             11   15312       05:59:00   \n",
       "20324           True  Thursday             12   15438       06:02:00   \n",
       "20325           True  Thursday             13   15458       06:03:00   \n",
       "\n",
       "            shape_id   route_id  service_hours                     geometry  \n",
       "20313  9010057_DEC21  901-13153            0.6  POINT (-118.37799 34.16846)  \n",
       "20314  9010057_DEC21  901-13153            0.6  POINT (-118.39730 34.16857)  \n",
       "20315  9010057_DEC21  901-13153            0.6  POINT (-118.42292 34.17288)  \n",
       "20316  9010057_DEC21  901-13153            0.6  POINT (-118.42960 34.17916)  \n",
       "20317  9010057_DEC21  901-13153            0.6  POINT (-118.44826 34.18064)  \n",
       "20318  9010057_DEC21  901-13153            0.6  POINT (-118.46903 34.18090)  \n",
       "20319  9010057_DEC21  901-13153            0.6  POINT (-118.48443 34.18629)  \n",
       "20320  9010057_DEC21  901-13153            0.6  POINT (-118.50072 34.18597)  \n",
       "20321  9010057_DEC21  901-13153            0.6  POINT (-118.53680 34.18044)  \n",
       "20322  9010057_DEC21  901-13153            0.6  POINT (-118.55419 34.18156)  \n",
       "20323  9010057_DEC21  901-13153            0.6  POINT (-118.57166 34.18747)  \n",
       "20324  9010057_DEC21  901-13153            0.6  POINT (-118.58925 34.18874)  \n",
       "20325  9010057_DEC21  901-13153            0.6  POINT (-118.59682 34.19060)  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips6[(trips6.calitp_itp_id==182) & (trips6.route_id==\"901-13153\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cad6953-1f6c-4a16-bd9a-15ddbf926d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
