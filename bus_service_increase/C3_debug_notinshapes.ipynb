{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3b363cf-fb13-42a3-b073-2b28f7fb94bd",
   "metadata": {},
   "source": [
    "# Debug transit routes on SHN\n",
    "\n",
    "There are some routes that aren't in `shapes.txt`, or, they don't get picked up when we merge `trips` and `dim_trips`.\n",
    "\n",
    "Foothill Transit is one example (id 112).\n",
    "\n",
    "It has routes that run on SHN, but don't show up in the service increase estimator, because it probably doesn't have `shapes` info.\n",
    "\n",
    "Bigger question is: `create_routes_data` creates it from `gtfs_schedule`, which is the latest, which is what Hunter wants, esp if it's going to be pushed to open data portal.\n",
    "\n",
    "But, sometimes we want to assemble the routes shapefile for a selected date, should we allow for that? If it's not a date in the past, then just proceed with `gtfs_schedule.trips`. \n",
    "\n",
    "Issue is: `trips` allows us to select for a service date, but Foothill Transit doesn't appear there with `trip_key`, but `dim_trips`, which doesn't allow for `service_date` selection, does have `trip_key` for Foothill Transit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3899f1b3-47c3-409a-8925-49b7f9078dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/geopandas/_compat.py:111: UserWarning: The Shapely GEOS version (3.9.1-CAPI-1.14.2) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import branca\n",
    "import datetime as dt\n",
    "import geopandas as gpd\n",
    "import intake\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "os.environ[\"CALITP_BQ_MAX_BYTES\"] = str(100_000_000_000)\n",
    "\n",
    "from calitp.tables import tbl\n",
    "from calitp import query_sql\n",
    "from siuba import *\n",
    "\n",
    "import create_parallel_corridors\n",
    "import utils\n",
    "from shared_utils import map_utils, geography_utils\n",
    "from shared_utils import calitp_color_palette as cp\n",
    "\n",
    "IMG_PATH = create_parallel_corridors.IMG_PATH\n",
    "DATA_PATH = create_parallel_corridors.DATA_PATH\n",
    "\n",
    "catalog = intake.open_catalog(\"*.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4ba5307-0496-47a7-9aef-0b40e19e2158",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_DATE = dt.date(2022, 1, 6)\n",
    "ITP_ID = 112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bad8a32-18e5-4228-9d79-2378d8ebf4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/siuba/sql/utils.py:52: SAWarning: Dialect bigquery:bigquery will not make use of SQL compilation caching as it does not set the 'supports_statement_cache' attribute to ``True``.  This can have significant performance implications including some performance degradations in comparison to prior SQLAlchemy versions.  Dialect maintainers should seek to set this attribute to True after appropriate development and testing for SQLAlchemy 1.4 caching support.   Alternatively, this attribute may be set to False which will disable this warning. (Background on this error at: https://sqlalche.me/e/14/cprf)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nshapes = (trips \\n      >> inner_join(_, dim_trips, \\n                    on = [\"calitp_itp_id\", \"trip_key\", \"route_id\", \"trip_id\"]\\n                   )\\n      >> select(_.calitp_itp_id, _.route_id, _.shape_id, _.trip_id)\\n      >> distinct()\\n      >> collect()\\n     )\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips = (tbl.views.gtfs_schedule_fact_daily_trips()\n",
    "     >> filter(_.service_date == SELECTED_DATE)\n",
    "    >> filter(_.calitp_itp_id == ITP_ID)\n",
    "     #>> select(_.calitp_itp_id, _.service_date, \n",
    "     #          _.route_id, _.trip_key, _.trip_id)\n",
    "         >> collect()\n",
    "        )\n",
    "\n",
    "#dim_trips = (tbl.views.gtfs_schedule_dim_trips()\n",
    "#             >> filter(_.calitp_itp_id==ITP_ID)\n",
    "         #>> select(_.calitp_itp_id, _.route_id, \n",
    "         #          _.shape_id, _.trip_key, _.trip_id)\n",
    "#             >> collect()\n",
    "#            )\n",
    "'''\n",
    "shapes = (trips \n",
    "      >> inner_join(_, dim_trips, \n",
    "                    on = [\"calitp_itp_id\", \"trip_key\", \"route_id\", \"trip_id\"]\n",
    "                   )\n",
    "      >> select(_.calitp_itp_id, _.route_id, _.shape_id, _.trip_id)\n",
    "      >> distinct()\n",
    "      >> collect()\n",
    "     )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f0c3d84-c5c9-4ec2-a8c6-47cffb8ab927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feed_key</th>\n",
       "      <th>trip_key</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>route_id</th>\n",
       "      <th>calitp_itp_id</th>\n",
       "      <th>calitp_url_number</th>\n",
       "      <th>service_id</th>\n",
       "      <th>service_date</th>\n",
       "      <th>service_indicator</th>\n",
       "      <th>service_start_date</th>\n",
       "      <th>...</th>\n",
       "      <th>service_inclusion</th>\n",
       "      <th>service_exclusion</th>\n",
       "      <th>is_in_service</th>\n",
       "      <th>calitp_extracted_at</th>\n",
       "      <th>calitp_deleted_at</th>\n",
       "      <th>n_stops</th>\n",
       "      <th>n_stop_times</th>\n",
       "      <th>trip_first_departure_ts</th>\n",
       "      <th>trip_last_arrival_ts</th>\n",
       "      <th>service_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [feed_key, trip_key, trip_id, route_id, calitp_itp_id, calitp_url_number, service_id, service_date, service_indicator, service_start_date, service_end_date, service_inclusion, service_exclusion, is_in_service, calitp_extracted_at, calitp_deleted_at, n_stops, n_stop_times, trip_first_departure_ts, trip_last_arrival_ts, service_hours]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c663032c-7ba8-40d5-ba46-ab0994f33dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips.service_date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce17dded-4116-4cb6-b01a-52d9c48b42df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_trips.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4da2a5-7bef-432f-a871-93c35595f904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796a1b1e-811f-4b9d-b87f-8f3e1173b225",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_routes = gpd.read_parquet(\"../traffic_ops/data/routes_assembled.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0814a9a8-47ac-4545-99a4-8ed16f01948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "foothill = full_routes[full_routes.itp_id==112][[\"itp_id\", \"shape_id\", \"route_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b171147f-33aa-4434-a992-10623c81f003",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.service_date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ecbc67-6b6b-45dc-b28e-3c7289a2f5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(t1, foothill, \n",
    "         left_on = [\"calitp_itp_id\", \"route_id\"],\n",
    "         right_on = [\"itp_id\", \"route_id\"]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26b311a-2b47-44e5-881b-fe10114c4b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = trips >> collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87677fbf-ac74-4b8c-b3cd-d81e33c26ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.service_date.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252633f2-8327-4050-bea6-5a63615631a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = dim_trips >> collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04437451-036a-4768-89fc-4c30923725b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(t1, t2, \n",
    "         on = [\"calitp_itp_id\", \"route_id\", \"trip_key\", \"trip_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d844b3cc-a093-4a00-9d35-b13495de7f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Need route_ids for parallel corridors\n",
    "# Add this info on and use alternate_df in make_analysis_data()\n",
    "SELECTED_DATE = dt.date(2022, 1, 6)\n",
    "\n",
    "trips = (tbl.views.gtfs_schedule_fact_daily_trips()\n",
    "         >> filter(_.service_date == SELECTED_DATE, _.is_in_service == True)\n",
    "         >> select(_.calitp_itp_id, _.service_date, \n",
    "                   _.route_id, _.trip_key)\n",
    ")\n",
    "\n",
    "dim_trips = (tbl.views.gtfs_schedule_dim_trips()\n",
    "             >> select(_.calitp_itp_id, _.route_id, \n",
    "                       _.shape_id, _.trip_key)\n",
    ")\n",
    "\n",
    "shapes = (trips \n",
    "          >> inner_join(_, dim_trips, \n",
    "                        on = [\"calitp_itp_id\", \"trip_key\", \"route_id\"]\n",
    "                       )\n",
    "          >> select(_.calitp_itp_id, _.route_id, _.shape_id)\n",
    "          >> distinct()\n",
    "          >> collect()\n",
    "         )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba59a42a-b15b-4fa4-b008-ba5936dd75be",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "transit_routes = catalog.transit_routes.read()\n",
    "\n",
    "df = pd.merge(transit_routes,\n",
    "              shapes,\n",
    "              on = [\"calitp_itp_id\", \"shape_id\"],\n",
    "              # Outer join shows there are left_only and right_only obs\n",
    "              # But, can only do stuff with full info\n",
    "              how = \"inner\",\n",
    "              # There are some obs where same shape_id is linked to multiple route_id\n",
    "              # Allow for 1:m\n",
    "              validate = \"1:m\",\n",
    ").rename(columns = {\"calitp_itp_id\": \"itp_id\"})\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94727d7-7a8e-4939-9578-3b330d799069",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "create_parallel_corridors.make_analysis_data(\n",
    "    hwy_buffer_feet=50, alternate_df = df,\n",
    "    pct_route_threshold = 0.3, pct_highway_threshold = 0.1,\n",
    "    DATA_PATH = DATA_PATH, FILE_NAME = \"routes_on_shn\"\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f5b318-7515-4c5f-ac5e-03925d7d12c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transit_routes = catalog.transit_routes.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7999c1a0-5c45-4cd6-888c-9ab92dad6533",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_parquet(\"./data/transit_routes.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf950f0a-27c5-4663-855a-8fa9f12c2d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.GCS_FILE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1421611c-42eb-42ee-89b4-87fd6e4467db",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[gdf.itp_id==112]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcb5607-e52a-4738-946c-4922be97073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gpd.read_parquet(f\"{DATA_PATH}routes_on_shn.parquet\")\n",
    "\n",
    "# Only keep parallel routes\n",
    "df = df[df.parallel == 1].reset_index(drop=True)\n",
    "\n",
    "# Draw highways with 250 ft buffer\n",
    "highways = gpd.read_parquet(f\"{DATA_PATH}highways.parquet\")\n",
    "\n",
    "# Bring in service hours increase data\n",
    "service = (pd.read_parquet(f\"{utils.GCS_FILE_PATH}2022_Jan/service_increase.parquet\")\n",
    "           .rename(columns = {\"calitp_itp_id\": \"itp_id\"})\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4780ee37-b859-4d01-abda-ec6f9fcbf8c3",
   "metadata": {},
   "source": [
    "Address duplicates.\n",
    "\n",
    "Duplicates mean same `shape_id`, but multiple `route_id` values.\n",
    "\n",
    "It's allowed up until now...but should it be allowed for aggregation?\n",
    "Will it be double-counting? Leave for now...but might need to get rid of duplicates..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6512f2-2980-4a23-b7d8-34e8b5a9134a",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_shapes = [\"107\"]\n",
    "check_ids = [194]\n",
    "\n",
    "df[(df.itp_id.isin(check_ids)) & (df.shape_id.isin(check_shapes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07537af4-e179-40a1-9d81-314bb0960bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "service[(service.itp_id.isin(check_ids)) & (service.shape_id.isin(check_shapes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e89a4c2-07a5-40ac-8bd5-23d2485603a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_increase = pd.merge(service, \n",
    "                            df, \n",
    "                            on = [\"itp_id\", \"shape_id\"],\n",
    "                            how = \"outer\",\n",
    "                            validate = \"m:m\",\n",
    "                            indicator=True\n",
    "                           )\n",
    "\n",
    "service_increase._merge.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa178c5-60c2-4b1d-9596-75f4be974e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_increase = pd.merge(service, \n",
    "                            df, \n",
    "                            on = [\"itp_id\", \"shape_id\"],\n",
    "                            how = \"inner\",\n",
    "                            validate = \"m:m\",\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eeb409-76d2-42cd-84c8-2ba6f87f9609",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"# unique route ids originally: {df.route_id.nunique()}\")\n",
    "print(f\"# unique route ids with service hrs info: {service_increase.route_id.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f8a6e2-2058-4f96-8c77-90bbf07ac1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_increase.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9bdace-bf84-4a24-b3ea-b451a4e921ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_cols = [\"additional_trips\", \"service_hrs\", \n",
    "            \"addl_service_hrs\", \"service_hours_annual\", \n",
    "            \"addl_service_hrs_annual\"\n",
    "           ]\n",
    "a1 = geography_utils.aggregate_by_geography(service_increase,\n",
    "                                       group_cols = [\"itp_id\", \"day_name\", \"tract_type\"],\n",
    "                                       sum_cols = sum_cols,\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16791478-ad17-44fe-82f7-cd3e68ef49e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can't find FootHill Transit (itp_id 112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0139935-12ac-4e96-880d-59834339bbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_increase[(service_increase.itp_id==182)].route_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40f1c3b-f7c0-4959-a920-0c942e91a70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_increase[(service_increase.itp_id==182) & \n",
    "                 (service_increase.route_id.str.contains(\"910\")) & \n",
    "                 (service_increase.day_name==\"Thursday\")\n",
    "                ][[\"itp_id\", \"day_name\", \"tract_type\", \"departure_hour\"] + sum_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5a8160-a756-4ca6-9539-1ae04d6cafea",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_ME = {\n",
    "    182: \"LA Metro\", \n",
    "    294: \"SJ Valley Transportation Authority\", \n",
    "    279: \"BART\", \n",
    "    282: \"SF Muni\",\n",
    "    278: \"SD Metropolitan Transit System\", \n",
    "    112: \"Foothill Transit\",\n",
    "}\n",
    "\n",
    "for itp_id, operator in MAP_ME.items():\n",
    "    subset = df[df.itp_id==itp_id]\n",
    "    print(f\"{itp_id}: {operator}\")\n",
    "    print(\"**************************************************\")\n",
    "    cols = [\"route_id\", \"total_routes\", \"Route\", \"RouteType\",\n",
    "            \"County\", \"District\", \n",
    "            \"pct_route\", \"pct_highway\"\n",
    "           ]\n",
    "    display(subset[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49d427c-90e2-437b-a596-03838d3a1ceb",
   "metadata": {},
   "source": [
    "## Make map of these parallel routes for CA\n",
    "\n",
    "Double check that these are as expected before calculating additional trips, buses, capital expenditures, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89abaa4-1569-47a2-a728-233182c40ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_plot(df):\n",
    "    keep_cols = [\"itp_id\", \"route_id\", \n",
    "                 \"Route\", \"County\", \"District\", \"RouteType\",\n",
    "                 \"pct_route\", \"pct_highway\", \"parallel\",\n",
    "                 \"geometry\"\n",
    "                ]\n",
    "    df = df[keep_cols].reset_index(drop=True)\n",
    "    df = df.assign(\n",
    "        geometry = df.geometry.buffer(200).simplify(tolerance=100),\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "to_map = data_to_plot(df)\n",
    "hwy_df = highways\n",
    "\n",
    "# Set various components for map\n",
    "hwys_popup_dict = {\n",
    "    \"Route\": \"Highway Route\",\n",
    "    \"RouteType\": \"Route Type\",\n",
    "    \"County\": \"County\"   \n",
    "}\n",
    "\n",
    "transit_popup_dict = {\n",
    "    \"itp_id\": \"Operator ITP ID\",\n",
    "    \"route_id\": \"Route ID\",\n",
    "    \"pct_route\": \"% overlapping route\",\n",
    "    \"pct_highway\": \"% overlapping highway\",\n",
    "}\n",
    "\n",
    "hwys_color = branca.colormap.StepColormap(\n",
    "    colors=[\"black\", \"gray\"],\n",
    ")\n",
    "\n",
    "colorscale = branca.colormap.StepColormap(\n",
    "    colors=[\n",
    "        cp.CALITP_CATEGORY_BRIGHT_COLORS[0], #blue\n",
    "        cp.CALITP_CATEGORY_BRIGHT_COLORS[1] # orange\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "LAYERS_DICT = {\n",
    "    \"Highways\": {\"df\": hwy_df,\n",
    "        \"plot_col\": \"Route\",\n",
    "        \"popup_dict\": hwys_popup_dict, \n",
    "        \"tooltip_dict\": hwys_popup_dict,\n",
    "        \"colorscale\": hwys_color,\n",
    "    },\n",
    "    \"Transit Routes\": {\"df\": to_map,\n",
    "        \"plot_col\": \"parallel\",\n",
    "        \"popup_dict\": transit_popup_dict, \n",
    "        \"tooltip_dict\": transit_popup_dict,\n",
    "        \"colorscale\": colorscale,\n",
    "    },\n",
    "}\n",
    "    \n",
    "LEGEND_URL = (\n",
    "    \"https://raw.githubusercontent.com/cal-itp/data-analyses/\"\n",
    "    \"main/bus_service_increase/\"\n",
    "    \"img/legend_intersecting_parallel.png\"\n",
    ")\n",
    "\n",
    "LEGEND_DICT = {\n",
    "    \"legend_url\": LEGEND_URL,\n",
    "    \"legend_bottom\": 85,\n",
    "    \"legend_left\": 5,\n",
    "}\n",
    "\n",
    "\n",
    "fig = map_utils.make_folium_multiple_layers_map(\n",
    "    LAYERS_DICT,\n",
    "    fig_width = 700, fig_height = 700, \n",
    "    zoom = map_utils.REGION_CENTROIDS[\"CA\"][\"zoom\"], \n",
    "    centroid = map_utils.REGION_CENTROIDS[\"CA\"][\"centroid\"], \n",
    "    title=f\"Parallel Transit Routes to SHN\",\n",
    "    legend_dict = LEGEND_DICT\n",
    ")\n",
    "    \n",
    "#display(fig)\n",
    "#fig.save(f\"{IMG_PATH}parallel_{operator_name}.html\")\n",
    "#print(f\"{operator_name} map saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fb9f41-c11c-4dd4-b6b5-f6060ce6dfb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
