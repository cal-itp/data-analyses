{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "328ec3c9-6f51-44b5-9227-80eb4711912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CALITP_BQ_MAX_BYTES\"] = str(100_000_000_000)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "import datetime as dt\n",
    "\n",
    "#import utils\n",
    "\n",
    "import calitp\n",
    "from calitp.tables import tbl\n",
    "from siuba import *\n",
    "\n",
    "# Replace get_recent_dates()\n",
    "# Explicitly set dates\n",
    "\n",
    "dates = {\n",
    "    'thurs': dt.date(2021, 10, 7),\n",
    "    'sat': dt.date(2021, 10, 9),\n",
    "    'sun': dt.date(2021, 10, 10)\n",
    "}\n",
    "\n",
    "min_date = min(dates.values())\n",
    "max_date = max(dates.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9055e8f5-3429-4b6c-bda7-911fd93f7332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store temporarily here\n",
    "DATA_PATH = \"gs://calitp-analytics-data/data-analyses/bus_service_increase/test/\"\n",
    "#thurs = pd.read_parquet(f\"{DATA_PATH}trips_thurs.parquet\")\n",
    "#sat = pd.read_parquet(f\"{DATA_PATH}trips_sat.parquet\")\n",
    "#sun = pd.read_parquet(f\"{DATA_PATH}trips_sun.parquet\")\n",
    "\n",
    "#df = pd.concat([thurs, sat, sun], axis=0, ignore_index=True)\n",
    "#df.to_parquet(f\"{DATA_PATH}all_days_st2.parquet\")\n",
    "\n",
    "df = pd.read_parquet(f\"{DATA_PATH}all_days_st2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4296e56e-940d-46fd-974d-4f80035b9622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_calculations(df):\n",
    "    ## time calculations\n",
    "    df = df.assign(\n",
    "        date = pd.to_datetime(df.date),\n",
    "        departure_time = df.departure_time.dropna().apply(utils.fix_gtfs_time),\n",
    "    )\n",
    "\n",
    "    # Something weird comes up trying to generate departure_dt\n",
    "    # pd.to_datetime() gives today's date\n",
    "    # datetime.strptime gives year 1900\n",
    "    # Either way, we have the service date, and later subsetting between 5am-9pm will address this\n",
    "    df = df.assign(\n",
    "        departure_time = pd.to_datetime(df.departure_time),\n",
    "        departure_hour = pd.to_datetime(df.departure_time).dt.hour,\n",
    "    )\n",
    "    \n",
    "    # Any observation with NaTs for departure time get dropped\n",
    "    # Will create issue later when grouping is done with departure hour\n",
    "    df = df[df.departure_time.notna()].reset_index(drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_runtime_hourlytrips(df):\n",
    "    # Calculate run time for a trip\n",
    "    # Find the median stop (keep that observation)\n",
    "    group_cols = ['trip_key', 'day_name']\n",
    "    df = df.assign(\n",
    "        mindt = df.groupby(group_cols)[\"departure_time\"].transform(\"min\"),\n",
    "        maxdt = df.groupby(group_cols)[\"departure_time\"].transform(\"max\"),\n",
    "        middle_stop = df.groupby([\"trip_key\", \"day_name\"])[\"stop_sequence\"].transform(\"median\"),\n",
    "    ).astype({\"middle_stop\": \"int64\"})\n",
    "\n",
    "    df = df.assign(\n",
    "        runtime_seconds = (df.maxdt - df.mindt).dt.seconds\n",
    "    ).drop(columns = [\"mindt\", \"maxdt\"])\n",
    "    \n",
    "    # Drop any trips with runtime of NaN calculated\n",
    "    df = df[df.runtime_seconds.notna()].reset_index(drop=True)\n",
    "\n",
    "    # Still want to use this to merge on the mean runtime info\n",
    "    middle_stops = df >> filter(_.stop_sequence == _.middle_stop)\n",
    "    \n",
    "    middle_stops = middle_stops.assign(\n",
    "        mean_runtime_min = (middle_stops.groupby([\"calitp_itp_id\", \n",
    "                                                  \"route_id\", \"shape_id\", \n",
    "                                                  \"departure_hour\", \"day_name\"])\n",
    "                            [\"runtime_seconds\"].transform(\"mean\")\n",
    "                           )\n",
    "    )\n",
    "    \n",
    "    debug_me = middle_stops[middle_stops.mean_runtime_min.isna()][\n",
    "        [\"calitp_itp_id\", \"shape_id\", \"trip_key\"]]\n",
    "    print(\"Debug errors for NaN mean runtimes\")\n",
    "    print(debug_me.head())\n",
    "    # Why are there some NaNs from this, when NaNs were dropped before?\n",
    "    # Some are due to no departure_time (handle it above by dropping NaTs)\n",
    "    \n",
    "    middle_stops = middle_stops.assign(\n",
    "        mean_runtime_min = (middle_stops.mean_runtime_min.dropna()     \n",
    "                            .apply(lambda x: int(round(x) / 60))\n",
    "                           )\n",
    "    )   \n",
    "    \n",
    "    # Add trips per hour column\n",
    "    shape_frequency = (\n",
    "        middle_stops\n",
    "        >> count(_.calitp_itp_id, _.route_id,\n",
    "                 _.shape_id, _.departure_hour, _.day_name, sort = True)\n",
    "        >> rename(trips_per_hour = \"n\")\n",
    "        >> inner_join(_, middle_stops, \n",
    "                      on = [\"calitp_itp_id\", \"day_name\", \n",
    "                            \"shape_id\", \"departure_hour\", \"route_id\"])\n",
    "    )\n",
    "    \n",
    "    # Now, data is at the trip-level (trip_key) still present\n",
    "    # Drop duplicates, but no aggregation because trips_per_hour and mean_runtime \n",
    "    # are already correctly generated at the route-level, across trips in that departure hour\n",
    "    shape_frequency = shape_frequency.drop_duplicates(subset=[\n",
    "        \"calitp_itp_id\", \"shape_id\", \"departure_hour\",\n",
    "        \"day_name\", \"route_id\"])\n",
    "    \n",
    "    # There's an aggregation to deal with multiple route_ids that share same shape_id\n",
    "    # If there are still multiple route_ids, then aggregate and sum / mean\n",
    "    # Modify this to include itp_id into the groupby\n",
    "    shape_frequency2 = (shape_frequency.groupby(\n",
    "        [\"calitp_itp_id\", \"shape_id\", \"departure_hour\", \"day_name\"])\n",
    "                        .agg({\"route_id\": \"max\", \n",
    "                              \"trips_per_hour\": \"sum\", \n",
    "                              \"mean_runtime_min\": \"mean\"\n",
    "                             }).reset_index()\n",
    "                       )\n",
    "    \n",
    "    # Now, drop ITP_ID==200 to use individual operator feeds\n",
    "    shape_frequency3 = shape_frequency2 >> filter(_.calitp_itp_id != 200)\n",
    "    \n",
    "    return shape_frequency3\n",
    "\n",
    "\n",
    "def attach_funding(all_operators_df):\n",
    "    # This is a small query, can leave it here\n",
    "    with_funding = (tbl.views.transitstacks()\n",
    "                    >> select(_.calitp_itp_id == _.itp_id, _.ntd_id, \n",
    "                              _.transit_provider, _._5307_funds, _._5311_funds,\n",
    "                              _.operating_expenses_total_2019)\n",
    "                    >> collect()\n",
    "                    >> right_join(_, all_operators_df, on = 'calitp_itp_id')\n",
    "                   )\n",
    "    \n",
    "    def fix_funds(value):\n",
    "        if type(value) != str:\n",
    "            return None\n",
    "        else:\n",
    "            return int(value.replace('$', '').replace(',', ''))\n",
    "        \n",
    "    funding_cols = [\"_5307_funds\", \"_5311_funds\", \"operating_expenses_total_2019\"] \n",
    "    for c in funding_cols:\n",
    "        with_funding[c] = with_funding[c].apply(fix_funds)\n",
    "    \n",
    "    return with_funding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d55a28-db84-4332-aaff-f5cd086949f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dfdd35-c443-41b8-9a53-e1fd4fb95070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e6e976-eb50-4902-be0d-2c504e896fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Debug and check some of the cases \n",
    "# Just look at LA Metro for now\n",
    "# See if the 30 trips per hour comes up again\n",
    "df = pd.read_parquet(f\"{DATA_PATH}all_days_st2.parquet\")\n",
    "df = df[df.calitp_itp_id==182]\n",
    "\n",
    "df = get_time_calculations(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea07bee-ab9f-4e6c-a5d6-47a6c2d65499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_debug(df):\n",
    "    group_cols = ['trip_key', 'day_name']\n",
    "    df = df.assign(\n",
    "        mindt = df.groupby(group_cols)[\"departure_time\"].transform(\"min\"),\n",
    "        maxdt = df.groupby(group_cols)[\"departure_time\"].transform(\"max\"),\n",
    "        middle_stop = df.groupby([\"trip_key\", \"day_name\"])[\"stop_sequence\"].transform(\"median\"),\n",
    "    ).astype({\"middle_stop\": \"int64\"})\n",
    "\n",
    "    df = df.assign(\n",
    "        runtime_seconds = (df.maxdt - df.mindt).dt.seconds\n",
    "    ).drop(columns = [\"mindt\", \"maxdt\"])\n",
    "\n",
    "    # Still want to use this to merge on the mean runtime info\n",
    "    middle_stops = df >> filter(_.stop_sequence == _.middle_stop)\n",
    "    \n",
    "    middle_stops = middle_stops.assign(\n",
    "        mean_runtime_min = (middle_stops.groupby([\"calitp_itp_id\", \n",
    "                                                  \"route_id\", \"shape_id\", \n",
    "                                                  \"departure_hour\", \"day_name\"])\n",
    "                            [\"runtime_seconds\"].transform(\"mean\")\n",
    "                            .apply(lambda x: int(round(x) / 60)))\n",
    "    )\n",
    "    \n",
    "    # Add trips per hour column\n",
    "    shape_frequency = (\n",
    "        middle_stops\n",
    "        >> count(_.calitp_itp_id, _.route_id,\n",
    "                 _.shape_id, _.departure_hour, _.day_name, sort = True)\n",
    "        >> rename(trips_per_hour = \"n\")\n",
    "        >> inner_join(_, middle_stops, \n",
    "                      on = [\"calitp_itp_id\", \"day_name\", \n",
    "                            \"shape_id\", \"departure_hour\", \"route_id\"])\n",
    "    )\n",
    "    '''\n",
    "    # Now, data is at the trip-level (trip_key) still present\n",
    "    # Drop duplicates, but no aggregation because trips_per_hour and mean_runtime \n",
    "    # are already correctly generated at the route-level, across trips in that departure hour\n",
    "    shape_frequency = shape_frequency.drop_duplicates(subset=[\n",
    "        \"calitp_itp_id\", \"shape_id\", \"departure_hour\",\n",
    "        \"day_name\", \"route_id\"])\n",
    "    \n",
    "    # There's an aggregation to deal with multiple route_ids that share same shape_id\n",
    "    # If there are still multiple route_ids, then aggregate and sum / mean\n",
    "    # Modify this to include itp_id into the groupby\n",
    "    shape_frequency2 = (shape_frequency.groupby(\n",
    "        [\"calitp_itp_id\", \"shape_id\", \"departure_hour\", \"day_name\"])\n",
    "                        .agg({\"route_id\": \"max\", \n",
    "                              \"trips_per_hour\": \"sum\", \n",
    "                              \"mean_runtime_min\": \"mean\"\n",
    "                             }).reset_index()\n",
    "                       )\n",
    "    '''\n",
    "    return shape_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf68fd5-3e69-448b-ba0e-83c10ddc6a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = to_debug(df)\n",
    "\n",
    "group_cols = [\"calitp_itp_id\", \"shape_id\", \"departure_hour\", \"day_name\", \"route_id\"]\n",
    "df2 = df2.assign(\n",
    "    obs = df2.groupby(group_cols)[\"trip_key\"].cumcount() + 1,\n",
    ")\n",
    "\n",
    "df2 = df2.assign(\n",
    "    max_obs = df2.groupby(group_cols)[\"obs\"].transform(\"max\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280fa72b-3549-4891-9e92-e67aa80c77bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.max_obs.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67be7b9a-ddf6-439a-bb75-5b21dd71aba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2.max_obs==19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b420fc4-3e80-4ab4-b38b-29ac4a2e9fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, to deal with duplicates, because there are multiple trips\n",
    "# with same departure hour, but that trips_per_hour is already generated correctly\n",
    "# Just drop duplicates, don't need to sum it up trips_per_hour\n",
    "# The mean runtime is already derived across all these trips\n",
    "df3 = df2.drop_duplicates(subset=[\"calitp_itp_id\", \"shape_id\", \"departure_hour\",\n",
    "                                  \"day_name\", \"route_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4521fe1d-c784-41b7-8575-b566b204d878",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregation to deal with multiple route_ids that share same shape_id\n",
    "# It makes 3 trips per hour, same \n",
    "df3[df3.shape_id==\"964395_shp\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b1b490-c886-4280-bf4d-1baa4b1f2242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5a2931-2532-46a4-bfbf-a2f550415219",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_trips = [-7711476650844868921,\n",
    "              -6084928573786923571]\n",
    "silver = df2[(df2.route_id.str.contains(\"910\")) & \n",
    "            (df2.departure_hour == 9) & (df2.trip_key.isin(keep_trips))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6430e457-3a82-44eb-8aed-c22d6a8f0749",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver.runtime_seconds.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78031617-7ef9-491c-9529-93bad8d9eb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79efcb4e-8981-437d-8a51-57d33cddfa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "(3450 +5100)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb46ae0b-5015-4411-bb57-22d5fb4e07d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still want to use this to merge on the mean runtime info\n",
    "middle_stops = df >> filter(_.stop_sequence == _.middle_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a1a1c2-92df-410c-9ba4-25cb88626abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "middle_stops[middle_stops.trip_key.isin(keep_trips)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1b7668-c605-47f1-9b0c-edf8917aa0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "middle_stops = middle_stops.assign(\n",
    "    mean_runtime_min = (middle_stops.groupby([\"calitp_itp_id\", \"route_id\", \"shape_id\", \n",
    "                          \"departure_hour\", \"day_name\"])\n",
    "                        [\"runtime_seconds\"].transform(\"mean\")\n",
    "                        .apply(lambda x: int(round(x) / 60)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5061c835-fabf-4a9f-b687-6313d2d8c493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With these 2 trips, it's because the starting stop has departure hour = 9, but by \n",
    "# middle stop, it's departure hour = 10. \n",
    "# Allow departure hour to differ for trip_keys then, since we want to stick with middle stop\n",
    "middle_stops[middle_stops.trip_key.isin(keep_trips)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d097033d-f9c2-4a93-a85c-12bd182826ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_frequency = (\n",
    "    middle_stops\n",
    "    >> count(_.calitp_itp_id, _.route_id,\n",
    "             _.shape_id, _.departure_hour, _.day_name, sort = True)\n",
    "    >> rename(trips_per_hour = \"n\")\n",
    "    >> inner_join(_, middle_stops, \n",
    "                  on = [\"calitp_itp_id\", \"day_name\", \n",
    "                        \"shape_id\", \"departure_hour\", \"route_id\"])\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b616d8-30f6-446f-8644-f3ea2a55801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_frequency[shape_frequency.trip_key.isin(keep_trips)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a32bca6-9c5f-4f3e-a156-e0a8e76e2763",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_shapes = (shape_frequency.groupby([\"shape_id\", \"day_name\", \"departure_hour\"])\n",
    "                   .agg({\"route_id\": \"nunique\"})\n",
    "                   .reset_index()\n",
    "                  )\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11969e8-46ed-410a-a08e-ead38483a62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_operators_shape_frequency = pd.read_parquet(f\"{utils.GCS_FILE_PATH}shape_frequency.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e921afe2-9228-4990-9e2c-65c33ca0cfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "single = all_operators_shape_frequency[all_operators_shape_frequency.calitp_itp_id==279]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10569aeb-bea5-4c0c-92b4-998233c0e529",
   "metadata": {},
   "outputs": [],
   "source": [
    "(single >> filter(_.shape_id == '964395_shp')).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2914a935-aa88-4b85-bd52-8f1391441148",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = pd.read_parquet(\"./data/test/timecalc_thurs.parquet\")\n",
    "\n",
    "error_trips = [\n",
    "    #thurs\n",
    "    4561616254186924304,\n",
    "    -3573784532994111184,\n",
    "    -5890052631007121734,\n",
    "    # sat\n",
    "    #8542179829811914215,\n",
    "    #4330243390808932084,\n",
    "    #-5417826296843621461\n",
    "]\n",
    "\n",
    "debug = debug[debug.trip_key.isin(error_trips)]\n",
    "debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1ec4b4-0702-4169-b7a4-59144741a4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_operators_shape_frequency = pd.read_parquet(f\"{utils.GCS_FILE_PATH}shape_frequency.parquet\")\n",
    "all_operators_shape_frequency[\n",
    "    (all_operators_shape_frequency.calitp_itp_id.isin(debug.calitp_itp_id)) & \n",
    "    (all_operators_shape_frequency.route_id.isin(debug.route_id)) & \n",
    "    (all_operators_shape_frequency.mean_runtime_min.isna())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a906af16-e592-421a-ac93-74aaca8c7144",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_shape_frequency = pd.read_parquet(\"./data/test/shape_frequency.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6265ec88-53d7-4843-b626-7117503fdb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_shape_frequency[(my_shape_frequency.calitp_itp_id.isin(debug.calitp_itp_id)) &\n",
    "                   (my_shape_frequency.route_id.isin(debug.route_id) & \n",
    "                    (my_shape_frequency.mean_runtime_min.isna())\n",
    "                   )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa075158-7725-4740-856a-4331b3a81819",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "my_shape_frequency.trips_per_hour.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d9dd5e-1998-4496-b985-1fac0849954c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
