{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d0621f-b673-4ed6-8900-cf7f7c7a448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"%%sh\n",
    "cd ~/data-analyses/rt_segment_speeds\n",
    "pip install -r requirements.txt\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be78daf2-2cde-4a47-89b3-5d5fbee75354",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from shared_utils import catalog_utils, rt_dates, gtfs_utils_v2\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import google.auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16567d79-a9e8-4fb7-810a-feb0b49dc9d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from retrospective_feed_generation import *\n",
    "from warehouse_utils import *\n",
    "from gtfs_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e0bb63-1d90-42ef-bacf-6b7662f35cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials, _ = google.auth.default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a02acd-e961-42f5-93bf-d590a11a856a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TARGET_DATE = rt_dates.DATES[\"apr2025\"]\n",
    "EXAMPLE_FEED_SCHEDULE_NAME = \"LA Metro Bus Schedule\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214222e9-d217-424e-ad65-b125673531bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feed_lookup_response = (\n",
    "    gtfs_utils_v2.schedule_daily_feed_to_gtfs_dataset_name(\n",
    "        selected_date=TARGET_DATE, keep_cols=[\"name\", \"gtfs_dataset_key\", \"feed_key\"]\n",
    "    )\n",
    "    .set_index(\"name\")\n",
    "    .loc[EXAMPLE_FEED_SCHEDULE_NAME]\n",
    ")\n",
    "gtfs_dataset_key = feed_lookup_response[\"gtfs_dataset_key\"]\n",
    "feed_key = feed_lookup_response[\"feed_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe66024b-d45a-4cf5-9f8a-a4d7c783f39c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rt_vs_schedule_stop_times_table = schedule_rt_stop_times_single_agency = get_schedule_rt_stop_times_table(\n",
    "    gtfs_dataset_key,\n",
    "    TARGET_DATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad951790-197f-4531-a129-d57aff935cb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rt_vs_schedule_stop_times_table_sorted = rt_vs_schedule_stop_times_table.sort_values(\n",
    "    [\"schedule_gtfs_dataset_key\", \"trip_instance_key\", \"stop_sequence\"], kind=\"stable\"\n",
    ")\n",
    "grouped_by_trip = rt_vs_schedule_stop_times_table_sorted.groupby(\n",
    "    [\"schedule_gtfs_dataset_key\", \"trip_instance_key\"]\n",
    ")\n",
    "shifted_grouped = grouped_by_trip[[\"scheduled_arrival_sec\", \"rt_arrival_sec\"]].shift(1)\n",
    "rt_vs_schedule_stop_times_table_sorted[\"non_sequential_rt_arrival\"] = (\n",
    "    shifted_grouped[\"rt_arrival_sec\"] > rt_vs_schedule_stop_times_table_sorted[\"rt_arrival_sec\"]\n",
    ")\n",
    "rt_vs_schedule_stop_times_table_sorted[\"non_sequential_scheduled_arrival\"] = (\n",
    "    shifted_grouped[\"scheduled_arrival_sec\"] > rt_vs_schedule_stop_times_table_sorted[\"scheduled_arrival_sec\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beca5728-fc0a-4be1-a085-3bbdbc538429",
   "metadata": {},
   "source": [
    "## Exploring non-sequential stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15730f0-f5c0-416c-a4fd-2f49d68293cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Are there any non sequential schedule stop-times\n",
    "rt_vs_schedule_stop_times_table_sorted.non_sequential_scheduled_arrival.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a370763b-b116-45fa-88ad-2639f1aa9352",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Looks like there are non sequential rt stop times\n",
    "non_sequential_rt_subset = rt_vs_schedule_stop_times_table_sorted.loc[\n",
    "    rt_vs_schedule_stop_times_table_sorted.non_sequential_rt_arrival\n",
    "].copy()\n",
    "non_sequential_rt_subset.trip_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4ae77e-162c-4610-8f41-160da2db826a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Map stops by the number of nonsequential, to see if they're random or if there's a pattern\n",
    "gtfs_data_dict = catalog_utils.get_catalog(\"gtfs_analytics_data\")\n",
    "read_parquet_kwargs = {\n",
    "    \"storage_options\": {\"token\": credentials.token},\n",
    "    \"filters\": [(\"feed_key\", \"=\", feed_key)],\n",
    "}\n",
    "stops_uri = (\n",
    "    f\"{gtfs_data_dict.schedule_downloads.dir}{gtfs_data_dict.schedule_downloads.stops}_{TARGET_DATE}.parquet\"\n",
    ")\n",
    "stops_response = gpd.read_parquet(stops_uri, **read_parquet_kwargs)\n",
    "stops_merged = stops_response.merge(\n",
    "    non_sequential_rt_subset.stop_id.value_counts().rename(\"nonsequential_counts\"),\n",
    "    left_on=\"stop_id\",\n",
    "    right_index=True,\n",
    "    validate=\"one_to_one\",\n",
    "    how=\"left\"\n",
    ")\n",
    "stops_merged[\"nonsequential_counts\"] = stops_merged[\"nonsequential_counts\"].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29226d4-3c13-4132-8994-d681b86bd2d2",
   "metadata": {},
   "source": [
    "### Map nonsequential stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddf88c6-ff38-445f-8082-2b40a599bca0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stops_merged[[\"stop_id\", \"stop_name\", \"nonsequential_counts\", \"geometry\"]].explore(column=\"nonsequential_counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706d089f-f8b9-4e82-8478-402d0260c989",
   "metadata": {},
   "source": [
    "### Do any routes have a large number of non-sequential stops?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51d5d55-638c-4f70-9389-ba689205da32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trips_uri = (\n",
    "    f\"{gtfs_data_dict.schedule_downloads.dir}{gtfs_data_dict.schedule_downloads.trips}_{TARGET_DATE}.parquet\"\n",
    ")\n",
    "trips_response = pd.read_parquet(\n",
    "    trips_uri, \n",
    "    columns=[\"trip_id\", \"route_id\", \"shape_id\"],\n",
    "    **read_parquet_kwargs\n",
    ")\n",
    "trips_with_nonsequential_stops = trips_response.merge(\n",
    "    non_sequential_rt_subset.trip_id.value_counts().rename(\"nonsequential_counts\"),\n",
    "    left_on=\"trip_id\",\n",
    "    right_index=True,\n",
    "    how=\"inner\",\n",
    "    validate=\"one_to_one\"\n",
    ")\n",
    "stop_times_with_route = rt_vs_schedule_stop_times_table_sorted.merge(\n",
    "    trips_response,\n",
    "    on=\"trip_id\",\n",
    "    how=\"left\",\n",
    "    validate=\"many_to_one\"\n",
    ")\n",
    "route_total_stop_times = stop_times_with_route.route_id.value_counts()\n",
    "route_total_nonsequential_stops = trips_with_nonsequential_stops.route_id.value_counts()\n",
    "non_sequential_stop_proportion = (route_total_nonsequential_stops / route_total_stop_times).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18045600-4de5-4a8e-9c3a-a0f009b221f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "non_sequential_stop_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eaf65f-7ba9-4b87-a8fa-e446a3d78705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"example_17_trip_id = trips_with_nonsequential_stops.loc[\n",
    "    (trips_with_nonsequential_stops.route_id == \"720\"),\n",
    "    \"trip_id\"\n",
    "].iloc[0]\n",
    "example_trip = rt_vs_schedule_stop_times_table_sorted.loc[\n",
    "    rt_vs_schedule_stop_times_table_sorted.trip_id == example_17_trip_id\n",
    "]\n",
    "gdf_one_trip_stops = gpd.GeoDataFrame(\n",
    "    example_trip.merge(\n",
    "        stops_response[[\"stop_id\", stops_response.geometry.name]],\n",
    "        how=\"left\",\n",
    "        on=\"stop_id\"\n",
    "    )\n",
    ")\n",
    "gdf_one_trip_stops.explore(column=\"non_sequential_rt_arrival\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aaa855-46af-4c55-819a-e9526f912d10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gdf_one_trip_stops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467b3182-ec99-429c-b380-7c536805827d",
   "metadata": {},
   "source": [
    "### Exploring skipped stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627e2a0d-4697-4b3e-a227-e8800a333361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from segment_speed_utils import helpers, segment_calcs\n",
    "\n",
    "SEGMENT_GCS = GTFS_DATA_DICT.gcs_paths.SEGMENT_GCS\n",
    "RT_SCHED_GCS = GTFS_DATA_DICT.gcs_paths.RT_SCHED_GCS\n",
    "\n",
    "# Unchanged from rt_scheduled_v_ran, but isn't in a package so we have to copy paste for now\n",
    "def prep_scheduled_stop_times(\n",
    "    analysis_date: str\n",
    ") -> pd.DataFrame: \n",
    "    \"\"\"\n",
    "    Import scheduled stop times and merge in \n",
    "    gtfs_dataset_key and trip_instance_key.\n",
    "    \"\"\"\n",
    "    trips = helpers.import_scheduled_trips(\n",
    "        analysis_date,\n",
    "        columns = [\"feed_key\", \"gtfs_dataset_key\",\n",
    "                   \"trip_id\", \"trip_instance_key\"],\n",
    "        get_pandas = True\n",
    "    )\n",
    "\n",
    "    stop_times = helpers.import_scheduled_stop_times(\n",
    "        analysis_date,\n",
    "        columns = [\"feed_key\", \"trip_id\", \n",
    "                   \"stop_id\", \"stop_sequence\",\n",
    "                   \"arrival_sec\",\n",
    "                  ],\n",
    "        get_pandas = True,\n",
    "        with_direction = False\n",
    "    ).merge(\n",
    "        trips,\n",
    "        on = [\"feed_key\", \"trip_id\"],\n",
    "        how = \"inner\"\n",
    "    ).drop(\n",
    "        columns = [\"feed_key\"]\n",
    "    ).rename(\n",
    "        columns = {\"arrival_sec\": \"scheduled_arrival_sec\"}\n",
    "    )\n",
    "    \n",
    "    return stop_times\n",
    "\n",
    "# Unchanged from rt_scheduled_v_ran, but isn't in a package so we have to copy paste for now\n",
    "def prep_rt_stop_times(\n",
    "    analysis_date: str,\n",
    "    trip_stop_cols: list\n",
    ") -> pd.DataFrame: \n",
    "    \"\"\"\n",
    "    For RT stop arrivals, drop duplicates based on interpolated\n",
    "    arrival times. Keep the first arrival time,\n",
    "    the rest would violate a monotonically increasing condition.\n",
    "    \"\"\"\n",
    "    STOP_ARRIVALS = GTFS_DATA_DICT.rt_stop_times.stage3\n",
    "    \n",
    "    df = pd.read_parquet(\n",
    "        f\"{SEGMENT_GCS}{STOP_ARRIVALS}_{analysis_date}.parquet\",\n",
    "        columns = trip_stop_cols + [\"arrival_time\"]\n",
    "    ).rename(columns = {\"arrival_time\": \"rt_arrival\"})\n",
    "\n",
    "    df2 = df.sort_values(\n",
    "        trip_stop_cols\n",
    "    ).drop_duplicates(\n",
    "        subset=[\"trip_instance_key\", \"rt_arrival\"]\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    df2 = segment_calcs.convert_timestamp_to_seconds(\n",
    "        df2, [\"rt_arrival\"]\n",
    "    ).drop(columns = \"rt_arrival\")\n",
    "    \n",
    "    return df2\n",
    "\n",
    "def assemble_scheduled_rt_stop_times_outer_merge(\n",
    "    analysis_date: str,\n",
    "    trip_stop_cols: list\n",
    ") -> pd.DataFrame: \n",
    "    \"\"\"\n",
    "    Merge scheduled and rt stop times so we can compare\n",
    "    scheduled arrival (seconds) and RT arrival (seconds).\n",
    "    \"\"\"\n",
    "    sched_stop_times = prep_scheduled_stop_times(analysis_date)\n",
    "    rt_stop_times = prep_rt_stop_times(analysis_date, trip_stop_cols)\n",
    "    \n",
    "    df = pd.merge(\n",
    "        sched_stop_times,\n",
    "        rt_stop_times,\n",
    "        on = trip_stop_cols,\n",
    "        how = \"outer\"\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def shortcut_assemble_scheduled_rt_stop_times_outer_merge(analysis_date: str) -> pd.DataFrame:\n",
    "    return assemble_scheduled_rt_stop_times_outer_merge(analysis_date, [*gtfs_data_dict.rt_stop_times.trip_stop_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6648462-2f69-4e0d-ae23-cf6211d7599b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outer_merged_stop_times = shortcut_assemble_scheduled_rt_stop_times_outer_merge(TARGET_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f51014-c794-45ac-9b85-f233a6ec865c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outer_merged_stop_times_filtered = outer_merged_stop_times.loc[\n",
    "    outer_merged_stop_times.schedule_gtfs_dataset_key == gtfs_dataset_key\n",
    "].copy()\n",
    "outer_merged_stop_times_filtered[\"rt_skipped\"] = (\n",
    "    outer_merged_stop_times_filtered.rt_arrival_sec.isna()\n",
    "    & ~outer_merged_stop_times.scheduled_arrival_sec.isna()\n",
    ")\n",
    "outer_merged_stop_times_no_rt_time = outer_merged_stop_times_filtered.loc[\n",
    "    outer_merged_stop_times_filtered.rt_skipped\n",
    "]\n",
    "n_skipped_stops_by_trip = outer_merged_stop_times_no_rt_time.trip_instance_key.value_counts()\n",
    "rt_trips_with_skipped_stops = n_skipped_stops_by_trip.loc[\n",
    "    n_skipped_stops_by_trip != outer_merged_stop_times_filtered.trip_instance_key.value_counts().loc[n_skipped_stops_by_trip.index]\n",
    "]\n",
    "outer_merged_stop_times_no_rt_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3fecb7-c582-400d-a637-512ca0c3a5de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_trip = outer_merged_stop_times_filtered.loc[\n",
    "    outer_merged_stop_times_filtered.trip_instance_key == rt_trips_with_skipped_stops.index[500]\n",
    "]\n",
    "gpd.GeoDataFrame(\n",
    "    example_trip.merge(\n",
    "        stops_response,\n",
    "        how=\"left\",\n",
    "        on=\"stop_id\"\n",
    "    )[[\"geometry\", \"stop_id\", \"rt_arrival_sec\", \"rt_skipped\"]]\n",
    ").explore(column=\"rt_skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fba572-5250-44d0-bc8c-17bc3136b663",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### stops_response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
